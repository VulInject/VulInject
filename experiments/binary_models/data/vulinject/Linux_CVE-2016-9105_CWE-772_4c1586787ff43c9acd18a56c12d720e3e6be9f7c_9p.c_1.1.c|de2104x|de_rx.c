static void de_rx (struct de_private *de)
{
	unsigned rx_tail = de->rx_tail;
	unsigned rx_work = DE_RX_RING_SIZE;
	unsigned drop = 0;
	int rc;
	while (--rx_work) {
		unsigned int status, len;
		dma_addr_t mapping;
		struct sk_buff *skb, *copy_skb;
		unsigned copying_skb, buflen;
		skb = de->rx_skb[rx_tail].skb;
		BUG_ON(!skb);
		rmb();
		status = le32_to_cpu(de->rx_ring[rx_tail].opts1);
		if (status & DescOwn)
			break;
		len = ((status >> 16) & 0x7fff) - 4;
		mapping = de->rx_skb[rx_tail].mapping;
		if (unlikely(drop)) {
			de->dev->stats.rx_dropped++;
			goto rx_next;
		}
		if (unlikely((status & 0x38008300) != 0x0300)) {
			de_rx_err_acct(de, rx_tail, status, len);
			goto rx_next;
		}
		copying_skb = (len <= rx_copybreak);
		netif_dbg(de, rx_status, de->dev,
			  "rx slot %d status 0x%x len %d copying? %d\n",
			  rx_tail, status, len, copying_skb);
		buflen = copying_skb ? (len + RX_OFFSET) : de->rx_buf_sz;
		copy_skb = netdev_alloc_skb(de->dev, buflen);
		if (unlikely(!copy_skb)) {
			de->dev->stats.rx_dropped++;
			drop = 1;
			rx_work = 100;
			goto rx_next;
		}
		if (!copying_skb) {
			dma_unmap_single(&de->pdev->dev, mapping, buflen,
					 DMA_FROM_DEVICE);
			mapping =
			de->rx_skb[rx_tail].mapping =
				dma_map_single(&de->pdev->dev, copy_skb->data,
					       buflen, DMA_FROM_DEVICE);
			de->rx_skb[rx_tail].skb = copy_skb;
		} else {
			dma_sync_single_for_cpu(&de->pdev->dev, mapping, len,
						DMA_FROM_DEVICE);
			skb_reserve(copy_skb, RX_OFFSET);
			skb_copy_from_linear_data(skb, skb_put(copy_skb, len),
						  len);
			dma_sync_single_for_device(&de->pdev->dev, mapping,
						   len, DMA_FROM_DEVICE);
			skb = copy_skb;
		}
		skb->protocol = eth_type_trans (skb, de->dev);
		de->dev->stats.rx_packets++;
		de->dev->stats.rx_bytes += skb->len;
		rc = netif_rx (skb);
		if (rc == NET_RX_DROP)
			drop = 1;
rx_next:
		if (rx_tail == (DE_RX_RING_SIZE - 1))
			de->rx_ring[rx_tail].opts2 =
				cpu_to_le32(RingEnd | de->rx_buf_sz);
		else
			de->rx_ring[rx_tail].opts2 = cpu_to_le32(de->rx_buf_sz);
		de->rx_ring[rx_tail].addr1 = cpu_to_le32(mapping);
		wmb();
		de->rx_ring[rx_tail].opts1 = cpu_to_le32(DescOwn);
		rx_tail = NEXT_RX(rx_tail);
	}
	if (!rx_work)
		netdev_warn(de->dev, "rx work limit reached\n");
	de->rx_tail = rx_tail;
}
