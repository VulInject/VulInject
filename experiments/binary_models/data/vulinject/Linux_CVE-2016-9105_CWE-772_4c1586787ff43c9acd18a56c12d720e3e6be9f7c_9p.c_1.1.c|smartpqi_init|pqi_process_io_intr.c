static int pqi_process_io_intr(struct pqi_ctrl_info *ctrl_info, struct pqi_queue_group *queue_group)
{
	int num_responses;
	pqi_index_t oq_pi;
	pqi_index_t oq_ci;
	struct pqi_io_request *io_request;
	struct pqi_io_response *response;
	unsigned short request_id;
	num_responses = 0;
	oq_ci = queue_group->oq_ci_copy;
	while (1) {
		oq_pi = readl(queue_group->oq_pi);
		if (oq_pi >= ctrl_info->num_elements_per_oq) {
			dev_err(&ctrl_info->pci_dev->dev,
				"I/O interrupt: producer index (%u) out of range (0-%u): consumer index: %u\n",
				oq_pi, ctrl_info->num_elements_per_oq - 1, oq_ci);
			return -1;
		}
		if (oq_pi == oq_ci)
			break;
		num_responses++;
		response = queue_group->oq_element_array +
			(oq_ci * PQI_OPERATIONAL_OQ_ELEMENT_LENGTH);
		request_id = get_unaligned_le16(&response->request_id);
		if (request_id >= ctrl_info->max_io_slots) {
			pqi_invalid_response(ctrl_info, PQI_INVALID_REQ_ID);
			dev_err(&ctrl_info->pci_dev->dev,
				"request ID in response (%u) out of range (0-%u): producer index: %u  consumer index: %u\n",
				request_id, ctrl_info->max_io_slots - 1, oq_pi, oq_ci);
			return -1;
		}
		io_request = &ctrl_info->io_request_pool[request_id];
		if (atomic_read(&io_request->refcount) == 0) {
			pqi_invalid_response(ctrl_info, PQI_UNMATCHED_REQ_ID);
			dev_err(&ctrl_info->pci_dev->dev,
				"request ID in response (%u) does not match an outstanding I/O request: producer index: %u  consumer index: %u\n",
				request_id, oq_pi, oq_ci);
			return -1;
		}
		switch (response->header.iu_type) {
		case PQI_RESPONSE_IU_RAID_PATH_IO_SUCCESS:
		case PQI_RESPONSE_IU_AIO_PATH_IO_SUCCESS:
			if (io_request->scmd)
				io_request->scmd->result = 0;
			fallthrough;
		case PQI_RESPONSE_IU_GENERAL_MANAGEMENT:
			break;
		case PQI_RESPONSE_IU_VENDOR_GENERAL:
			io_request->status =
				get_unaligned_le16(
				&((struct pqi_vendor_general_response *)response)->status);
			break;
		case PQI_RESPONSE_IU_TASK_MANAGEMENT:
			io_request->status = pqi_interpret_task_management_response(ctrl_info,
				(void *)response);
			break;
		case PQI_RESPONSE_IU_AIO_PATH_DISABLED:
			pqi_aio_path_disabled(io_request);
			io_request->status = -EAGAIN;
			break;
		case PQI_RESPONSE_IU_RAID_PATH_IO_ERROR:
		case PQI_RESPONSE_IU_AIO_PATH_IO_ERROR:
			io_request->error_info = ctrl_info->error_buffer +
				(get_unaligned_le16(&response->error_index) *
				PQI_ERROR_BUFFER_ELEMENT_LENGTH);
			pqi_process_io_error(response->header.iu_type, io_request);
			break;
		default:
			pqi_invalid_response(ctrl_info, PQI_UNEXPECTED_IU_TYPE);
			dev_err(&ctrl_info->pci_dev->dev,
				"unexpected IU type: 0x%x: producer index: %u  consumer index: %u\n",
				response->header.iu_type, oq_pi, oq_ci);
			return -1;
		}
		io_request->io_complete_callback(io_request, io_request->context);
		oq_ci = (oq_ci + 1) % ctrl_info->num_elements_per_oq;
	}
	if (num_responses) {
		queue_group->oq_ci_copy = oq_ci;
		writel(oq_ci, queue_group->oq_ci);
	}
	return num_responses;
}
