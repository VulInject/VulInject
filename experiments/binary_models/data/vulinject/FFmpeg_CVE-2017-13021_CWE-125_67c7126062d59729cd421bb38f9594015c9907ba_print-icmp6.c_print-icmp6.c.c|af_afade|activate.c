static int activate(AVFilterContext *ctx)
{
    AudioFadeContext *s   = ctx->priv;
    AVFilterLink *outlink = ctx->outputs[0];
    AVFrame *in = NULL, *out, *cf[2] = { NULL };
    int ret = 0, nb_samples, status;
    int64_t pts;
    FF_FILTER_FORWARD_STATUS_BACK_ALL(outlink, ctx);
    if (s->passthrough && s->status[0]) {
        ret = ff_inlink_consume_frame(ctx->inputs[1], &in);
        if (ret > 0) {
            in->pts = s->pts;
            s->pts += av_rescale_q(in->nb_samples,
                      (AVRational){ 1, outlink->sample_rate }, outlink->time_base);
            return ff_filter_frame(outlink, in);
        } else if (ret < 0) {
            return ret;
        } else if (ff_inlink_acknowledge_status(ctx->inputs[1], &status, &pts)) {
            ff_outlink_set_status(outlink, status, pts);
            return 0;
        } else if (!ret) {
            if (ff_outlink_frame_wanted(outlink)) {
                return 0;
            }
        }
    }
    nb_samples = ff_inlink_queued_samples(ctx->inputs[0]);
    if (nb_samples  > s->nb_samples) {
        nb_samples -= s->nb_samples;
        s->passthrough = 1;
        ret = ff_inlink_consume_samples(ctx->inputs[0], nb_samples, nb_samples, &in);
        if (ret < 0)
            return ret;
        in->pts = s->pts;
        s->pts += av_rescale_q(in->nb_samples,
            (AVRational){ 1, outlink->sample_rate }, outlink->time_base);
        return ff_filter_frame(outlink, in);
    } else if (s->status[0] && nb_samples >= s->nb_samples &&
               ff_inlink_queued_samples(ctx->inputs[1]) >= s->nb_samples) {
        if (s->overlap) {
            out = ff_get_audio_buffer(outlink, s->nb_samples);
            if (!out)
                return AVERROR(ENOMEM);
            ret = ff_inlink_consume_samples(ctx->inputs[0], s->nb_samples, s->nb_samples, &cf[0]);
            if (ret < 0) {
                av_frame_free(&out);
                return ret;
            }
            ret = ff_inlink_consume_samples(ctx->inputs[1], s->nb_samples, s->nb_samples, &cf[1]);
            if (ret < 0) {
                av_frame_free(&out);
                return ret;
            }
            s->crossfade_samples(out->extended_data, cf[0]->extended_data,
                                 cf[1]->extended_data,
                                 s->nb_samples, out->ch_layout.nb_channels,
                                 s->curve, s->curve2);
            out->pts = s->pts;
            s->pts += av_rescale_q(s->nb_samples,
                (AVRational){ 1, outlink->sample_rate }, outlink->time_base);
            s->passthrough = 1;
            av_frame_free(&cf[0]);
            av_frame_free(&cf[1]);
            return ff_filter_frame(outlink, out);
        } else {
            out = ff_get_audio_buffer(outlink, s->nb_samples);
            if (!out)
                return AVERROR(ENOMEM);
            ret = ff_inlink_consume_samples(ctx->inputs[0], s->nb_samples, s->nb_samples, &cf[0]);
            if (ret < 0) {
                av_frame_free(&out);
                return ret;
            }
            s->fade_samples(out->extended_data, cf[0]->extended_data, s->nb_samples,
                            outlink->ch_layout.nb_channels, -1, s->nb_samples - 1, s->nb_samples, s->curve, 0., 1.);
            out->pts = s->pts;
            s->pts += av_rescale_q(s->nb_samples,
                (AVRational){ 1, outlink->sample_rate }, outlink->time_base);
            av_frame_free(&cf[0]);
            ret = ff_filter_frame(outlink, out);
            if (ret < 0)
                return ret;
            out = ff_get_audio_buffer(outlink, s->nb_samples);
            if (!out)
                return AVERROR(ENOMEM);
            ret = ff_inlink_consume_samples(ctx->inputs[1], s->nb_samples, s->nb_samples, &cf[1]);
            if (ret < 0) {
                av_frame_free(&out);
                return ret;
            }
            s->fade_samples(out->extended_data, cf[1]->extended_data, s->nb_samples,
                            outlink->ch_layout.nb_channels, 1, 0, s->nb_samples, s->curve2, 0., 1.);
            out->pts = s->pts;
            s->pts += av_rescale_q(s->nb_samples,
                (AVRational){ 1, outlink->sample_rate }, outlink->time_base);
            s->passthrough = 1;
            av_frame_free(&cf[1]);
            return ff_filter_frame(outlink, out);
        }
    } else if (ff_outlink_frame_wanted(outlink)) {
        if (!s->status[0] && check_input(ctx->inputs[0]))
            s->status[0] = AVERROR_EOF;
        s->passthrough = !s->status[0];
        if (check_input(ctx->inputs[1])) {
            s->status[1] = AVERROR_EOF;
            ff_outlink_set_status(outlink, AVERROR_EOF, AV_NOPTS_VALUE);
            return 0;
        }
        if (!s->status[0])
            ff_inlink_request_frame(ctx->inputs[0]);
        else
            ff_inlink_request_frame(ctx->inputs[1]);
        return 0;
    }
    return ret;
}
