int tegra_drm_ioctl_channel_submit(struct drm_device *drm, void *data,
				   struct drm_file *file)
{
	struct tegra_drm_file *fpriv = file->driver_priv;
	struct drm_tegra_channel_submit *args = data;
	struct tegra_drm_submit_data *job_data;
	struct drm_syncobj *syncobj = NULL;
	struct tegra_drm_context *context;
	struct host1x_job *job;
	struct gather_bo *bo;
	unsigned int i;
	int err;
	mutex_lock(&fpriv->lock);
	context = xa_load(&fpriv->contexts, args->context);
	if (!context) {
		mutex_unlock(&fpriv->lock);
		pr_err_ratelimited("%s: %s: invalid channel context '%#x'", __func__,
				   current->comm, args->context);
		return -EINVAL;
	}
	if (args->syncobj_in) {
		struct dma_fence *fence;
		err = drm_syncobj_find_fence(file, args->syncobj_in, 0, 0, &fence);
		if (err) {
			SUBMIT_ERR(context, "invalid syncobj_in '%#x'", args->syncobj_in);
			goto unlock;
		}
		err = dma_fence_wait_timeout(fence, true, msecs_to_jiffies(10000));
		dma_fence_put(fence);
		if (err) {
			SUBMIT_ERR(context, "wait for syncobj_in timed out");
			goto unlock;
		}
	}
	if (args->syncobj_out) {
		syncobj = drm_syncobj_find(file, args->syncobj_out);
		if (!syncobj) {
			SUBMIT_ERR(context, "invalid syncobj_out '%#x'", args->syncobj_out);
			err = -ENOENT;
			goto unlock;
		}
	}
	err = submit_copy_gather_data(&bo, drm->dev, context, args);
	if (err)
		goto unlock;
	job_data = kzalloc(sizeof(*job_data), GFP_KERNEL);
	if (!job_data) {
		SUBMIT_ERR(context, "failed to allocate memory for job data");
		err = -ENOMEM;
		goto put_bo;
	}
	err = submit_process_bufs(context, bo, args, job_data);
	if (err)
		goto free_job_data;
	job = submit_create_job(context, bo, args, job_data, &fpriv->syncpoints);
	if (IS_ERR(job)) {
		err = PTR_ERR(job);
		goto free_job_data;
	}
	err = host1x_job_pin(job, context->client->base.dev);
	if (err) {
		SUBMIT_ERR(context, "failed to pin job: %d", err);
		goto put_job;
	}
	if (context->client->ops->get_streamid_offset) {
		err = context->client->ops->get_streamid_offset(
			context->client, &job->engine_streamid_offset);
		if (err) {
			SUBMIT_ERR(context, "failed to get streamid offset: %d", err);
			goto unpin_job;
		}
	}
	if (context->memory_context && context->client->ops->can_use_memory_ctx) {
		bool supported;
		err = context->client->ops->can_use_memory_ctx(context->client, &supported);
		if (err) {
			SUBMIT_ERR(context, "failed to detect if engine can use memory context: %d", err);
			goto unpin_job;
		}
		if (supported) {
			job->memory_context = context->memory_context;
		}
	} else if (context->client->ops->get_streamid_offset) {
		if (!tegra_dev_iommu_get_stream_id(context->client->base.dev,
						   &job->engine_fallback_streamid))
			job->engine_fallback_streamid = TEGRA_STREAM_ID_BYPASS;
	}
	err = pm_runtime_resume_and_get(context->client->base.dev);
	if (err < 0) {
		SUBMIT_ERR(context, "could not power up engine: %d", err);
		goto put_memory_context;
	}
	job->user_data = job_data;
	job->release = release_job;
	job->timeout = 10000;
	job_data = NULL;
	err = host1x_job_submit(job);
	if (err) {
		SUBMIT_ERR(context, "host1x job submission failed: %d", err);
		goto unpin_job;
	}
	args->syncpt.value = job->syncpt_end;
	if (syncobj) {
		struct dma_fence *fence = host1x_fence_create(job->syncpt, job->syncpt_end, true);
		if (IS_ERR(fence)) {
			err = PTR_ERR(fence);
			SUBMIT_ERR(context, "failed to create postfence: %d", err);
		}
		drm_syncobj_replace_fence(syncobj, fence);
	}
	goto put_job;
put_memory_context:
	if (job->memory_context)
		host1x_memory_context_put(job->memory_context);
unpin_job:
	host1x_job_unpin(job);
put_job:
	host1x_job_put(job);
free_job_data:
	if (job_data && job_data->used_mappings) {
		for (i = 0; i < job_data->num_used_mappings; i++)
			tegra_drm_mapping_put(job_data->used_mappings[i].mapping);
		kfree(job_data->used_mappings);
	}
	kfree(job_data);
put_bo:
	gather_bo_put(&bo->base);
unlock:
	if (syncobj)
		drm_syncobj_put(syncobj);
	mutex_unlock(&fpriv->lock);
	return err;
}
