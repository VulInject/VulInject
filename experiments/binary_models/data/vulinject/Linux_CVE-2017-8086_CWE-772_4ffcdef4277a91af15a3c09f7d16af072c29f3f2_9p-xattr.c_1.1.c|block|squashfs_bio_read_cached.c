static int squashfs_bio_read_cached(struct bio *fullbio,
		struct address_space *cache_mapping, unsigned int int index, int length,
		unsigned int int read_start, unsigned int int read_end, int page_count)
{
	struct page *head_to_cache = NULL, *tail_to_cache = NULL;
	struct block_device *bdev = fullbio->bi_bdev;
	int start_idx = 0, end_idx = 0;
	struct bvec_iter_all iter_all;
	struct bio *bio = NULL;
	struct bio_vec *bv;
	int idx = 0;
	int err = 0;
	bio_for_each_segment_all(bv, fullbio, iter_all) {
		struct page *page = bv->bv_page;
		if (page->mapping == cache_mapping) {
			idx++;
			continue;
		}
		if (idx == 0 && index != read_start)
			head_to_cache = page;
		else if (idx == page_count - 1 && index + length != read_end)
			tail_to_cache = page;
		if (!bio || idx != end_idx) {
			struct bio *new = bio_alloc_clone(bdev, fullbio,
							  GFP_NOIO, &fs_bio_set);
			if (bio) {
				bio_trim(bio, start_idx * PAGE_SECTORS,
					 (end_idx - start_idx) * PAGE_SECTORS);
				submit_bio(bio);
			}
			bio = new;
			start_idx = idx;
		}
		idx++;
		end_idx = idx;
	}
	if (bio) {
		bio_trim(bio, start_idx * PAGE_SECTORS,
			 (end_idx - start_idx) * PAGE_SECTORS);
		err = submit_bio_wait(bio);
		bio_put(bio);
	}
	if (err)
		return err;
	if (head_to_cache) {
		int ret = add_to_page_cache_lru(head_to_cache, cache_mapping,
						read_start >> PAGE_SHIFT,
						GFP_NOIO);
		if (!ret) {
			SetPageUptodate(head_to_cache);
			unlock_page(head_to_cache);
		}
	}
	if (tail_to_cache) {
		int ret = add_to_page_cache_lru(tail_to_cache, cache_mapping,
						(read_end >> PAGE_SHIFT) - 1,
						GFP_NOIO);
		if (!ret) {
			SetPageUptodate(tail_to_cache);
			unlock_page(tail_to_cache);
		}
	}
	return 0;
}
