static int nvmet_try_send_ddgst(struct nvmet_tcp_cmd *cmd, bool last_in_batch)
{
	struct nvmet_tcp_queue *queue = cmd->queue;
	int left = NVME_TCP_DIGEST_LENGTH - cmd->offset;
	struct msghdr msg = { .msg_flags = MSG_DONTWAIT };
	struct kvec iov = {
		.iov_base = (unsigned char *)&cmd->exp_ddgst + cmd->offset,
		.iov_len = left
	};
	int ret;
	if (!last_in_batch && cmd->queue->send_list_len)
		msg.msg_flags |= MSG_MORE;
	else
		msg.msg_flags |= MSG_EOR;
	ret = kernel_sendmsg(queue->sock, &msg, &iov, 1, iov.iov_len);
	if (unlikely(ret <= 0))
		return ret;
	cmd->offset += ret;
	left -= ret;
	if (left)
		return -EAGAIN;
	if (queue->nvme_sq.sqhd_disabled) {
		cmd->queue->snd_cmd = NULL;
	} else {
		nvmet_setup_response_pdu(cmd);
	}
	return 1;
}
