static unsigned int __bnxt_rx_agg_pages(struct bnxt *bp,
			       struct bnxt_cp_ring_info *cpr,
			       struct skb_shared_info *shinfo,
			       unsigned short idx, unsigned int agg_bufs, bool tpa,
			       struct xdp_buff *xdp)
{
	struct bnxt_napi *bnapi = cpr->bnapi;
	struct pci_dev *pdev = bp->pdev;
	struct bnxt_rx_ring_info *rxr = bnapi->rx_ring;
	unsigned short prod = rxr->rx_agg_prod;
	unsigned int i, total_frag_len = 0;
	bool p5_tpa = false;
	if ((bp->flags & BNXT_FLAG_CHIP_P5_PLUS) && tpa)
		p5_tpa = true;
	for (i = 0; i < agg_bufs; i++) {
		skb_frag_t *frag = &shinfo->frags[i];
		unsigned short cons, frag_len;
		struct rx_agg_cmp *agg;
		struct bnxt_sw_rx_agg_bd *cons_rx_buf;
		struct page *page;
		dma_addr_t mapping;
		if (p5_tpa)
			agg = bnxt_get_tpa_agg_p5(bp, rxr, idx, i);
		else
			agg = bnxt_get_agg(bp, cpr, idx, i);
		cons = agg->rx_agg_cmp_opaque;
		frag_len = (le32_to_cpu(agg->rx_agg_cmp_len_flags_type) &
			    RX_AGG_CMP_LEN) >> RX_AGG_CMP_LEN_SHIFT;
		cons_rx_buf = &rxr->rx_agg_ring[cons];
		skb_frag_fill_page_desc(frag, cons_rx_buf->page,
					cons_rx_buf->offset, frag_len);
		shinfo->nr_frags = i + 1;
		__clear_bit(cons, rxr->rx_agg_bmap);
		mapping = cons_rx_buf->mapping;
		page = cons_rx_buf->page;
		cons_rx_buf->page = NULL;
		if (xdp && page_is_pfmemalloc(page))
			xdp_buff_set_frag_pfmemalloc(xdp);
		if (bnxt_alloc_rx_page(bp, rxr, prod, GFP_ATOMIC) != 0) {
			--shinfo->nr_frags;
			cons_rx_buf->page = page;
			rxr->rx_agg_prod = prod;
			bnxt_reuse_rx_agg_bufs(cpr, idx, i, agg_bufs - i, tpa);
			return 0;
		}
		dma_sync_single_for_cpu(&pdev->dev, mapping, BNXT_RX_PAGE_SIZE,
					bp->rx_dir);
		total_frag_len += frag_len;
	}
	rxr->rx_agg_prod = prod;
	return total_frag_len;
}
