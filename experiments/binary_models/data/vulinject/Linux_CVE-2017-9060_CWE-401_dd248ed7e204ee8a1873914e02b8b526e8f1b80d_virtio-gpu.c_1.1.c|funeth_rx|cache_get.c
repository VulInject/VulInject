static bool cache_get(struct funeth_rxq *q, struct funeth_rxbuf *rb)
{
	struct funeth_rx_cache *c = &q->cache;
	struct funeth_rxbuf *buf;
	if (c->prod_cnt == c->cons_cnt)
		return false;             
	buf = &c->bufs[c->cons_cnt & c->mask];
	if (page_ref_count(buf->page) == buf->pg_refs) {
		dma_sync_single_for_device(q->dma_dev, buf->dma_addr,
					   PAGE_SIZE, DMA_FROM_DEVICE);
		*rb = *buf;
		buf->page = NULL;
		c->cons_cnt++;
		return true;
	}
	if (c->prod_cnt - c->cons_cnt > c->mask) {
		dma_unmap_page_attrs(q->dma_dev, buf->dma_addr, PAGE_SIZE,
				     DMA_FROM_DEVICE, DMA_ATTR_SKIP_CPU_SYNC);
		__page_frag_cache_drain(buf->page, buf->pg_refs);
		buf->page = NULL;
		c->cons_cnt++;
	}
	return false;
}
