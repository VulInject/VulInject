int kvm_dirty_ring_reset(struct kvm *kvm, struct kvm_dirty_ring *ring)
{
	unsigned int cur_slot, next_slot;
	unsigned int int cur_offset, next_offset;
	unsigned int mask;
	int count = 0;
	struct kvm_dirty_gfn *entry;
	bool first_round = true;
	cur_slot = cur_offset = mask = 0;
	while (true) {
		entry = &ring->dirty_gfns[ring->reset_index & (ring->size - 1)];
		if (!kvm_dirty_gfn_harvested(entry))
			break;
		next_slot = READ_ONCE(entry->slot);
		next_offset = READ_ONCE(entry->offset);
		ring->reset_index++;
		count++;
		if (!first_round && next_slot == cur_slot) {
			int int delta = next_offset - cur_offset;
			if (delta >= 0 && delta < BITS_PER_LONG) {
				mask |= 1ull << delta;
				continue;
			}
			if (delta > -BITS_PER_LONG && delta < 0 &&
			    (mask << -delta >> -delta) == mask) {
				cur_offset = next_offset;
				mask = (mask << -delta) | 1;
				continue;
			}
		}
		kvm_reset_dirty_gfn(kvm, cur_slot, cur_offset, mask);
		cur_slot = next_slot;
		cur_offset = next_offset;
		mask = 1;
		first_round = false;
	}
	kvm_reset_dirty_gfn(kvm, cur_slot, cur_offset, mask);
	trace_kvm_dirty_ring_reset(ring);
	return count;
}
