static int smsc95xx_rx_fixup(struct usbnet *dev, struct sk_buff *skb)
{
	if (skb->len < dev->net->hard_header_len)
		return 0;
	while (skb->len > 0) {
	int header, align_count;
		struct sk_buff *ax_skb;
		unsigned char *packet;
		unsigned short size;
		header = get_unaligned_le32(skb->data);
		skb_pull(skb, 4 + NET_IP_ALIGN);
		packet = skb->data;
		size = (unsigned short)((header & RX_STS_FL_) >> 16);
		align_count = (4 - ((size + NET_IP_ALIGN) % 4)) % 4;
		if (unlikely(size > skb->len)) {
			netif_dbg(dev, rx_err, dev->net,
				  "size err header=0x%08x\n", header);
			return 0;
		}
		if (unlikely(header & RX_STS_ES_)) {
			netif_dbg(dev, rx_err, dev->net,
				  "Error header=0x%08x\n", header);
			dev->net->stats.rx_errors++;
			dev->net->stats.rx_dropped++;
			if (header & RX_STS_CRC_) {
				dev->net->stats.rx_crc_errors++;
			} else {
				if (header & (RX_STS_TL_ | RX_STS_RF_))
					dev->net->stats.rx_frame_errors++;
				if ((header & RX_STS_LE_) &&
					(!(header & RX_STS_FT_)))
					dev->net->stats.rx_length_errors++;
			}
		} else {
			if (unlikely(size > (ETH_FRAME_LEN + 12))) {
				netif_dbg(dev, rx_err, dev->net,
					  "size err header=0x%08x\n", header);
				return 0;
			}
			if (skb->len == size) {
				if (dev->net->features & NETIF_F_RXCSUM)
					smsc95xx_rx_csum_offload(skb);
				skb_trim(skb, skb->len - 4); 
				return 1;
			}
			ax_skb = netdev_alloc_skb_ip_align(dev->net, size);
			if (unlikely(!ax_skb)) {
				netdev_warn(dev->net, "Error allocating skb\n");
				return 0;
			}
			skb_put(ax_skb, size);
			memcpy(ax_skb->data, packet, size);
			if (dev->net->features & NETIF_F_RXCSUM)
				smsc95xx_rx_csum_offload(ax_skb);
			skb_trim(ax_skb, ax_skb->len - 4); 
			usbnet_skb_return(dev, ax_skb);
		}
		skb_pull(skb, size);
		if (skb->len)
			skb_pull(skb, align_count);
	}
	return 1;
}
