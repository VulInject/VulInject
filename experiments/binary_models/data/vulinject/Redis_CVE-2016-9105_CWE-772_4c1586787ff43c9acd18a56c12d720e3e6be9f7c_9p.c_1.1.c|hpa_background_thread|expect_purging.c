expect_purging(unsigned arena_ind, bool expect_deferred) {
	size_t empty_ndirty;
	empty_ndirty = get_empty_ndirty(arena_ind);
	expect_zu_eq(0, empty_ndirty, "Expected arena to start unused.");
	/*
	 * It's possible that we get unlucky with our stats collection timing,
	 * and the background thread runs in between the deallocation and the
	 * stats collection.  So we retry 10 times, and see if we *ever* see
	 * deferred reclamation.
	 */
	bool observed_dirty_page = false;
	for (int i = 0; i < 10; i++) {
		void *ptr = mallocx(PAGE,
		    MALLOCX_TCACHE_NONE | MALLOCX_ARENA(arena_ind));
		empty_ndirty = get_empty_ndirty(arena_ind);
		expect_zu_eq(0, empty_ndirty, "All pages should be active");
		empty_ndirty = get_empty_ndirty(arena_ind);
		if (expect_deferred) {
			expect_true(empty_ndirty == 0 || empty_ndirty == 1 ||
			    opt_prof, "Unexpected extra dirty page count: %zu",
			    empty_ndirty);
		} else {
			assert_zu_eq(0, empty_ndirty,
			    "Saw dirty pages without deferred purging");
		}
		if (empty_ndirty > 0) {
			observed_dirty_page = true;
			break;
		}
	}
	expect_b_eq(expect_deferred, observed_dirty_page, "");
	/*
	 * Under high concurrency / heavy test load (e.g. using run_test.sh),
	 * the background thread may not get scheduled for a longer period of
	 * time.  Retry 100 times max before bailing out.
	 */
	unsigned retry = 0;
	while ((empty_ndirty = get_empty_ndirty(arena_ind)) > 0 &&
	    expect_deferred && (retry++ < 100)) {
		sleep_for_background_thread_interval();
	}
	expect_zu_eq(0, empty_ndirty, "Should have seen a background purge");
}
