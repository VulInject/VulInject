extent_grow_retained(tsdn_t *tsdn, pac_t *pac, ehooks_t *ehooks,
    size_t size, size_t alignment, bool zero, bool *commit) {
	malloc_mutex_assert_owner(tsdn, &pac->grow_mtx);
	size_t alloc_size_min = size + PAGE_CEILING(alignment) - PAGE;
	/* Beware size_t wrap-around. */
	size_t alloc_size;
	pszind_t exp_grow_skip;
	bool err = exp_grow_size_prepare(&pac->exp_grow, alloc_size_min,
	    &alloc_size, &exp_grow_skip);
	if (err) {
		goto label_err;
	}
	edata_t *edata = edata_cache_get(tsdn, pac->edata_cache);
	if (edata == NULL) {
		goto label_err;
	}
	bool zeroed = false;
	bool committed = false;
	void *ptr = ehooks_alloc(tsdn, ehooks, NULL, alloc_size, PAGE, &zeroed,
	    &committed);
	if (ptr == NULL) {
		edata_cache_put(tsdn, pac->edata_cache, edata);
		goto label_err;
	}
	edata_init(edata, ecache_ind_get(&pac->ecache_retained), ptr,
	    alloc_size, false, SC_NSIZES, extent_sn_next(pac),
	    extent_state_active, zeroed, committed, EXTENT_PAI_PAC,
	    EXTENT_IS_HEAD);
	if (extent_register_no_gdump_add(tsdn, pac, edata)) {
		edata_cache_put(tsdn, pac->edata_cache, edata);
		goto label_err;
	}
	if (edata_committed_get(edata)) {
		*commit = true;
	}
	edata_t *lead;
	edata_t *trail;
	edata_t *to_leak JEMALLOC_CC_SILENCE_INIT(NULL);
	edata_t *to_salvage JEMALLOC_CC_SILENCE_INIT(NULL);
	extent_split_interior_result_t result = extent_split_interior(tsdn,
	    pac, ehooks, &edata, &lead, &trail, &to_leak, &to_salvage, NULL,
	    size, alignment);
	if (result == extent_split_interior_ok) {
		if (lead != NULL) {
			extent_record(tsdn, pac, ehooks, &pac->ecache_retained,
			    lead);
		}
		if (trail != NULL) {
			extent_record(tsdn, pac, ehooks, &pac->ecache_retained,
			    trail);
		}
	} else {
		/*
		 * We should have allocated a sufficiently large extent; the
		 * cant_alloc case should not occur.
		 */
		assert(result == extent_split_interior_error);
		if (to_salvage != NULL) {
			if (config_prof) {
				extent_gdump_add(tsdn, to_salvage);
			}
			extent_record(tsdn, pac, ehooks, &pac->ecache_retained,
			    to_salvage);
		}
		if (to_leak != NULL) {
			extent_deregister_no_gdump_sub(tsdn, pac, to_leak);
			extents_abandon_vm(tsdn, pac, ehooks,
			    &pac->ecache_retained, to_leak, true);
		}
		goto label_err;
	}
	if (*commit && !edata_committed_get(edata)) {
		if (extent_commit_impl(tsdn, ehooks, edata, 0,
		    edata_size_get(edata), true)) {
			extent_record(tsdn, pac, ehooks,
			    &pac->ecache_retained, edata);
			goto label_err;
		}
		/* A successful commit should return zeroed memory. */
		if (config_debug) {
			void *addr = edata_addr_get(edata);
			size_t *p = (size_t *)(uintptr_t)addr;
			/* Check the first page only. */
			for (size_t i = 0; i < PAGE / sizeof(size_t); i++) {
				assert(p[i] == 0);
			}
		}
	}
	/*
	 * Increment extent_grow_next if doing so wouldn't exceed the allowed
	 * range.
	 */
	/* All opportunities for failure are past. */
	exp_grow_size_commit(&pac->exp_grow, exp_grow_skip);
	malloc_mutex_unlock(tsdn, &pac->grow_mtx);
	if (config_prof) {
		/* Adjust gdump stats now that extent is final size. */
		extent_gdump_add(tsdn, edata);
	}
	if (zero && !edata_zeroed_get(edata)) {
		ehooks_zero(tsdn, ehooks, edata_base_get(edata),
		    edata_size_get(edata));
	}
	return edata;
label_err:
	malloc_mutex_unlock(tsdn, &pac->grow_mtx);
	return NULL;
}
