static bool __allowed_ingress(const struct net_bridge *br,
			      struct net_bridge_vlan_group *vg,
			      struct sk_buff *skb, unsigned short *vid,
			      unsigned char *state,
			      struct net_bridge_vlan **vlan)
{
	struct pcpu_sw_netstats *stats;
	struct net_bridge_vlan *v;
	bool tagged;
	BR_INPUT_SKB_CB(skb)->vlan_filtered = true;
	if (unlikely(!skb_vlan_tag_present(skb) &&
		     skb->protocol == br->vlan_proto)) {
		if (unlikely(!skb))
			return false;
	}
	if (!br_vlan_get_tag(skb, vid)) {
		if (skb->vlan_proto != br->vlan_proto) {
			skb_push(skb, ETH_HLEN);
			skb = vlan_insert_tag_set_proto(skb, skb->vlan_proto,
							skb_vlan_tag_get(skb));
			if (unlikely(!skb))
				return false;
			skb_pull(skb, ETH_HLEN);
			skb_reset_mac_len(skb);
			*vid = 0;
			tagged = false;
		} else {
			tagged = true;
		}
	} else {
		tagged = false;
	}
	if (!*vid) {
		unsigned short pvid = br_get_pvid(vg);
		if (!pvid)
			goto drop;
		*vid = pvid;
		if (likely(!tagged))
			__vlan_hwaccel_put_tag(skb, br->vlan_proto, pvid);
		else
			skb->vlan_tci |= pvid;
		if (!br_opt_get(br, BROPT_MCAST_VLAN_SNOOPING_ENABLED) &&
		    !br_opt_get(br, BROPT_VLAN_STATS_ENABLED)) {
			if (*state == BR_STATE_FORWARDING) {
				*state = br_vlan_get_pvid_state(vg);
				if (!br_vlan_state_allowed(*state, true))
					goto drop;
			}
			return true;
		}
	}
	v = br_vlan_find(vg, *vid);
	if (!v || !br_vlan_should_use(v))
		goto drop;
	if (*state == BR_STATE_FORWARDING) {
		*state = br_vlan_get_state(v);
		if (!br_vlan_state_allowed(*state, true))
			goto drop;
	}
	if (br_opt_get(br, BROPT_VLAN_STATS_ENABLED)) {
		stats = this_cpu_ptr(v->stats);
		u64_stats_update_begin(&stats->syncp);
		u64_stats_add(&stats->rx_bytes, skb->len);
		u64_stats_inc(&stats->rx_packets);
		u64_stats_update_end(&stats->syncp);
	}
	*vlan = v;
	return true;
drop:
	kfree_skb(skb);
	return false;
}
