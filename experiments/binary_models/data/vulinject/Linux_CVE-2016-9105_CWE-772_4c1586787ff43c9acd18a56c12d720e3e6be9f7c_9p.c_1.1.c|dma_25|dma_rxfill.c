bool dma_rxfill(struct dma_pub *pub)
{
	struct dma_info *di = container_of(pub, struct dma_info, dma);
	struct sk_buff *p;
	unsigned short rxin, rxout;
	unsigned int flags = 0;
	unsigned int n;
	unsigned int i;
	dma_addr_t pa;
	unsigned int extra_offset = 0;
	bool ring_empty;
	ring_empty = false;
	rxin = di->rxin;
	rxout = di->rxout;
	n = di->nrxpost - nrxdactive(di, rxin, rxout);
	brcms_dbg_dma(di->core, "%s: post %d\n", di->name, n);
	if (di->rxbufsize > BCMEXTRAHDROOM)
		extra_offset = di->rxextrahdrroom;
	for (i = 0; i < n; i++) {
		p = brcmu_pkt_buf_get_skb(di->rxbufsize + extra_offset);
		if (p == NULL) {
			brcms_dbg_dma(di->core, "%s: out of rxbufs\n",
				      di->name);
			if (i == 0 && dma64_rxidle(di)) {
				brcms_dbg_dma(di->core, "%s: ring is empty !\n",
					      di->name);
				ring_empty = true;
			}
			di->dma.rxnobuf++;
			break;
		}
		if (extra_offset)
		*(unsigned int *) (p->data) = 0;
		pa = dma_map_single(di->dmadev, p->data, di->rxbufsize,
				    DMA_FROM_DEVICE);
		if (dma_mapping_error(di->dmadev, pa)) {
			brcmu_pkt_buf_free_skb(p);
			return false;
		}
		di->rxp[rxout] = p;
		flags = 0;
		if (rxout == (di->nrxd - 1))
			flags = D64_CTRL1_EOT;
		dma64_dd_upd(di, di->rxd64, pa, rxout, &flags,
			     di->rxbufsize);
		rxout = nextrxd(di, rxout);
	}
	di->rxout = rxout;
	bcma_write32(di->core, DMA64RXREGOFFS(di, ptr),
	      di->rcvptrbase + I2B(rxout, struct dma64desc));
	return ring_empty;
}
