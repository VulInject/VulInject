efct_scsi_io_dispatch(struct efct_io *io, void *cb)
{
	struct efct_hw_io *hio;
	struct efct *efct = io->efct;
	struct efct_xport *xport = efct->xport;
	unsigned int flags = 0;
	io->hw_cb = cb;
	if (io->hio)
		return efct_scsi_io_dispatch_hw_io(io, io->hio);
	spin_lock_irqsave(&xport->io_pending_lock, flags);
	if (!list_empty(&xport->io_pending_list)) {
		if (io->low_latency) {
			list_add(&xport->io_pending_list, &io->io_pending_link);
		} else {
			INIT_LIST_HEAD(&io->io_pending_link);
			list_add_tail(&io->io_pending_link,
				      &xport->io_pending_list);
		}
		spin_unlock_irqrestore(&xport->io_pending_lock, flags);
		atomic_add_return(1, &xport->io_pending_count);
		atomic_add_return(1, &xport->io_total_pending);
		efct_scsi_check_pending(efct);
		return 0;
	}
	spin_unlock_irqrestore(&xport->io_pending_lock, flags);
	hio = efct_hw_io_alloc(&io->efct->hw);
	if (!hio) {
		spin_lock_irqsave(&xport->io_pending_lock, flags);
		INIT_LIST_HEAD(&io->io_pending_link);
		list_add_tail(&io->io_pending_link, &xport->io_pending_list);
		spin_unlock_irqrestore(&xport->io_pending_lock, flags);
		atomic_add_return(1, &xport->io_total_pending);
		atomic_add_return(1, &xport->io_pending_count);
		return 0;
	}
	return efct_scsi_io_dispatch_hw_io(io, hio);
}
