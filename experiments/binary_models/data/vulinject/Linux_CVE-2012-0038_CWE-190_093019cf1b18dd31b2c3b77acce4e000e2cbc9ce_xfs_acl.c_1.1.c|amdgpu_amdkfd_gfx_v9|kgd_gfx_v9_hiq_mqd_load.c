int kgd_gfx_v9_hiq_mqd_load(struct amdgpu_device *adev, void *mqd,
			    unsigned int pipe_id, unsigned int queue_id,
			    unsigned int doorbell_off, unsigned int inst)
{
	struct amdgpu_ring *kiq_ring = &adev->gfx.kiq[inst].ring;
	struct v9_mqd *m;
	int mec, pipe;
	int r;
	m = get_mqd(mqd);
	kgd_gfx_v9_acquire_queue(adev, pipe_id, queue_id, inst);
	mec = (pipe_id / adev->gfx.mec.num_pipe_per_mec) + 1;
	pipe = (pipe_id % adev->gfx.mec.num_pipe_per_mec);
	pr_debug("kfd: set HIQ, mec:%d, pipe:%d, queue:%d.\n",
		 mec, pipe, queue_id);
	spin_lock(&adev->gfx.kiq[inst].ring_lock);
	r = amdgpu_ring_alloc(kiq_ring, 7);
	if (r) {
		pr_err("Failed to alloc KIQ (%d).\n", r);
		goto out_unlock;
	}
	amdgpu_ring_write(kiq_ring, PACKET3(PACKET3_MAP_QUEUES, 5));
	amdgpu_ring_write(kiq_ring,
			  PACKET3_MAP_QUEUES_QUEUE_SEL(0) | 
			  PACKET3_MAP_QUEUES_VMID(m->cp_hqd_vmid) | 
			  PACKET3_MAP_QUEUES_QUEUE(queue_id) |
			  PACKET3_MAP_QUEUES_PIPE(pipe) |
			  PACKET3_MAP_QUEUES_ME((mec - 1)) |
			  PACKET3_MAP_QUEUES_QUEUE_TYPE(0) | 
			  PACKET3_MAP_QUEUES_ALLOC_FORMAT(0) | 
			  PACKET3_MAP_QUEUES_ENGINE_SEL(1) | 
			  PACKET3_MAP_QUEUES_NUM_QUEUES(1)); 
	amdgpu_ring_write(kiq_ring,
			  PACKET3_MAP_QUEUES_DOORBELL_OFFSET(doorbell_off));
	amdgpu_ring_write(kiq_ring, m->cp_mqd_base_addr_lo);
	amdgpu_ring_write(kiq_ring, m->cp_mqd_base_addr_hi);
	amdgpu_ring_write(kiq_ring, m->cp_hqd_pq_wptr_poll_addr_lo);
	amdgpu_ring_write(kiq_ring, m->cp_hqd_pq_wptr_poll_addr_hi);
	amdgpu_ring_commit(kiq_ring);
out_unlock:
	spin_unlock(&adev->gfx.kiq[inst].ring_lock);
	kgd_gfx_v9_release_queue(adev, inst);
	return r;
}
