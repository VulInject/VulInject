int bpf_jit_build_body(struct bpf_prog *fp, unsigned int *image, unsigned int *fimage, struct codegen_context *ctx,
		       unsigned int *addrs, int pass, bool extra_pass)
{
	const struct bpf_insn *insn = fp->insnsi;
	int flen = fp->len;
	int i, ret;
	unsigned int exit_addr = addrs[flen];
	for (i = 0; i < flen; i++) {
		unsigned int code = insn[i].code;
		unsigned int prevcode = i ? insn[i - 1].code : 0;
		unsigned int dst_reg = bpf_to_ppc(insn[i].dst_reg);
		unsigned int dst_reg_h = dst_reg - 1;
		unsigned int src_reg = bpf_to_ppc(insn[i].src_reg);
		unsigned int src_reg_h = src_reg - 1;
		unsigned int src2_reg = dst_reg;
		unsigned int src2_reg_h = dst_reg_h;
		unsigned int ax_reg = bpf_to_ppc(BPF_REG_AX);
		unsigned int tmp_reg = bpf_to_ppc(TMP_REG);
		unsigned int size = BPF_SIZE(code);
	int save_reg, ret_reg;
		short off = insn[i].off;
		int imm = insn[i].imm;
		bool func_addr_fixed;
		unsigned int int func_addr;
		unsigned int true_cond;
		unsigned int tmp_idx;
		int j;
		if (i && (BPF_CLASS(code) == BPF_ALU64 || BPF_CLASS(code) == BPF_ALU) &&
		    (BPF_CLASS(prevcode) == BPF_ALU64 || BPF_CLASS(prevcode) == BPF_ALU) &&
		    BPF_OP(prevcode) == BPF_MOV && BPF_SRC(prevcode) == BPF_X &&
		    insn[i - 1].dst_reg == insn[i].dst_reg && insn[i - 1].imm != 1) {
			src2_reg = bpf_to_ppc(insn[i - 1].src_reg);
			src2_reg_h = src2_reg - 1;
			ctx->idx = addrs[i - 1] / 4;
		}
		addrs[i] = ctx->idx * 4;
		if (dst_reg >= 3 && dst_reg < 32) {
			bpf_set_seen_register(ctx, dst_reg);
			bpf_set_seen_register(ctx, dst_reg_h);
		}
		if (src_reg >= 3 && src_reg < 32) {
			bpf_set_seen_register(ctx, src_reg);
			bpf_set_seen_register(ctx, src_reg_h);
		}
		switch (code) {
		case BPF_ALU | BPF_ADD | BPF_X: 
			EMIT(PPC_RAW_ADD(dst_reg, src2_reg, src_reg));
			break;
		case BPF_ALU64 | BPF_ADD | BPF_X: 
			EMIT(PPC_RAW_ADDC(dst_reg, src2_reg, src_reg));
			EMIT(PPC_RAW_ADDE(dst_reg_h, src2_reg_h, src_reg_h));
			break;
		case BPF_ALU | BPF_SUB | BPF_X: 
			EMIT(PPC_RAW_SUB(dst_reg, src2_reg, src_reg));
			break;
		case BPF_ALU64 | BPF_SUB | BPF_X: 
			EMIT(PPC_RAW_SUBFC(dst_reg, src_reg, src2_reg));
			EMIT(PPC_RAW_SUBFE(dst_reg_h, src_reg_h, src2_reg_h));
			break;
		case BPF_ALU | BPF_SUB | BPF_K: 
			imm = -imm;
			fallthrough;
		case BPF_ALU | BPF_ADD | BPF_K: 
			if (!imm) {
				EMIT(PPC_RAW_MR(dst_reg, src2_reg));
			} else if (IMM_HA(imm) & 0xffff) {
				EMIT(PPC_RAW_ADDIS(dst_reg, src2_reg, IMM_HA(imm)));
				src2_reg = dst_reg;
			}
			if (IMM_L(imm))
				EMIT(PPC_RAW_ADDI(dst_reg, src2_reg, IMM_L(imm)));
			break;
		case BPF_ALU64 | BPF_SUB | BPF_K: 
			imm = -imm;
			fallthrough;
		case BPF_ALU64 | BPF_ADD | BPF_K: 
			if (!imm) {
				EMIT(PPC_RAW_MR(dst_reg, src2_reg));
				EMIT(PPC_RAW_MR(dst_reg_h, src2_reg_h));
				break;
			}
			if (imm >= -32768 && imm < 32768) {
				EMIT(PPC_RAW_ADDIC(dst_reg, src2_reg, imm));
			} else {
				PPC_LI32(_R0, imm);
				EMIT(PPC_RAW_ADDC(dst_reg, src2_reg, _R0));
			}
			if (imm >= 0 || (BPF_OP(code) == BPF_SUB && imm == 0x80000000))
				EMIT(PPC_RAW_ADDZE(dst_reg_h, src2_reg_h));
			else
				EMIT(PPC_RAW_ADDME(dst_reg_h, src2_reg_h));
			break;
		case BPF_ALU64 | BPF_MUL | BPF_X: 
			bpf_set_seen_register(ctx, tmp_reg);
			EMIT(PPC_RAW_MULW(_R0, src2_reg, src_reg_h));
			EMIT(PPC_RAW_MULW(dst_reg_h, src2_reg_h, src_reg));
			EMIT(PPC_RAW_MULHWU(tmp_reg, src2_reg, src_reg));
			EMIT(PPC_RAW_MULW(dst_reg, src2_reg, src_reg));
			EMIT(PPC_RAW_ADD(dst_reg_h, dst_reg_h, _R0));
			EMIT(PPC_RAW_ADD(dst_reg_h, dst_reg_h, tmp_reg));
			break;
		case BPF_ALU | BPF_MUL | BPF_X: 
			EMIT(PPC_RAW_MULW(dst_reg, src2_reg, src_reg));
			break;
		case BPF_ALU | BPF_MUL | BPF_K: 
			if (imm == 1) {
				EMIT(PPC_RAW_MR(dst_reg, src2_reg));
			} else if (imm == -1) {
				EMIT(PPC_RAW_SUBFIC(dst_reg, src2_reg, 0));
			} else if (is_power_of_2((unsigned int)imm)) {
				EMIT(PPC_RAW_SLWI(dst_reg, src2_reg, ilog2(imm)));
			} else if (imm >= -32768 && imm < 32768) {
				EMIT(PPC_RAW_MULI(dst_reg, src2_reg, imm));
			} else {
				PPC_LI32(_R0, imm);
				EMIT(PPC_RAW_MULW(dst_reg, src2_reg, _R0));
			}
			break;
		case BPF_ALU64 | BPF_MUL | BPF_K: 
			if (!imm) {
				PPC_LI32(dst_reg, 0);
				PPC_LI32(dst_reg_h, 0);
			} else if (imm == 1) {
				EMIT(PPC_RAW_MR(dst_reg, src2_reg));
				EMIT(PPC_RAW_MR(dst_reg_h, src2_reg_h));
			} else if (imm == -1) {
				EMIT(PPC_RAW_SUBFIC(dst_reg, src2_reg, 0));
				EMIT(PPC_RAW_SUBFZE(dst_reg_h, src2_reg_h));
			} else if (imm > 0 && is_power_of_2(imm)) {
				imm = ilog2(imm);
				EMIT(PPC_RAW_RLWINM(dst_reg_h, src2_reg_h, imm, 0, 31 - imm));
				EMIT(PPC_RAW_RLWIMI(dst_reg_h, dst_reg, imm, 32 - imm, 31));
				EMIT(PPC_RAW_SLWI(dst_reg, src2_reg, imm));
			} else {
				bpf_set_seen_register(ctx, tmp_reg);
				PPC_LI32(tmp_reg, imm);
				EMIT(PPC_RAW_MULW(dst_reg_h, src2_reg_h, tmp_reg));
				if (imm < 0)
					EMIT(PPC_RAW_SUB(dst_reg_h, dst_reg_h, src2_reg));
				EMIT(PPC_RAW_MULHWU(_R0, src2_reg, tmp_reg));
				EMIT(PPC_RAW_MULW(dst_reg, src2_reg, tmp_reg));
				EMIT(PPC_RAW_ADD(dst_reg_h, dst_reg_h, _R0));
			}
			break;
		case BPF_ALU | BPF_DIV | BPF_X: 
			if (off)
				EMIT(PPC_RAW_DIVW(dst_reg, src2_reg, src_reg));
			else
				EMIT(PPC_RAW_DIVWU(dst_reg, src2_reg, src_reg));
			break;
		case BPF_ALU | BPF_MOD | BPF_X: 
			if (off)
				EMIT(PPC_RAW_DIVW(_R0, src2_reg, src_reg));
			else
				EMIT(PPC_RAW_DIVWU(_R0, src2_reg, src_reg));
			EMIT(PPC_RAW_MULW(_R0, src_reg, _R0));
			EMIT(PPC_RAW_SUB(dst_reg, src2_reg, _R0));
			break;
		case BPF_ALU64 | BPF_DIV | BPF_X: 
			return -EOPNOTSUPP;
		case BPF_ALU64 | BPF_MOD | BPF_X: 
			return -EOPNOTSUPP;
		case BPF_ALU | BPF_DIV | BPF_K: 
			if (!imm)
				return -EINVAL;
			if (imm == 1) {
				EMIT(PPC_RAW_MR(dst_reg, src2_reg));
			} else if (is_power_of_2((unsigned int)imm)) {
				if (off)
					EMIT(PPC_RAW_SRAWI(dst_reg, src2_reg, ilog2(imm)));
				else
					EMIT(PPC_RAW_SRWI(dst_reg, src2_reg, ilog2(imm)));
			} else {
				PPC_LI32(_R0, imm);
				if (off)
					EMIT(PPC_RAW_DIVW(dst_reg, src2_reg, _R0));
				else
					EMIT(PPC_RAW_DIVWU(dst_reg, src2_reg, _R0));
			}
			break;
		case BPF_ALU | BPF_MOD | BPF_K: 
			if (!imm)
				return -EINVAL;
			if (!is_power_of_2((unsigned int)imm)) {
				bpf_set_seen_register(ctx, tmp_reg);
				PPC_LI32(tmp_reg, imm);
				if (off)
					EMIT(PPC_RAW_DIVW(_R0, src2_reg, tmp_reg));
				else
					EMIT(PPC_RAW_DIVWU(_R0, src2_reg, tmp_reg));
				EMIT(PPC_RAW_MULW(_R0, tmp_reg, _R0));
				EMIT(PPC_RAW_SUB(dst_reg, src2_reg, _R0));
			} else if (imm == 1) {
				EMIT(PPC_RAW_LI(dst_reg, 0));
			} else if (off) {
				EMIT(PPC_RAW_SRAWI(_R0, src2_reg, ilog2(imm)));
				EMIT(PPC_RAW_ADDZE(_R0, _R0));
				EMIT(PPC_RAW_SLWI(_R0, _R0, ilog2(imm)));
				EMIT(PPC_RAW_SUB(dst_reg, src2_reg, _R0));
			} else {
				imm = ilog2((unsigned int)imm);
				EMIT(PPC_RAW_RLWINM(dst_reg, src2_reg, 0, 32 - imm, 31));
			}
			break;
		case BPF_ALU64 | BPF_MOD | BPF_K: 
			if (!imm)
				return -EINVAL;
			if (imm < 0)
				imm = -imm;
			if (!is_power_of_2(imm))
				return -EOPNOTSUPP;
			if (imm == 1) {
				EMIT(PPC_RAW_LI(dst_reg, 0));
				EMIT(PPC_RAW_LI(dst_reg_h, 0));
			} else if (off) {
				EMIT(PPC_RAW_SRAWI(dst_reg_h, src2_reg_h, 31));
				EMIT(PPC_RAW_XOR(dst_reg, src2_reg, dst_reg_h));
				EMIT(PPC_RAW_SUBFC(dst_reg, dst_reg_h, dst_reg));
				EMIT(PPC_RAW_RLWINM(dst_reg, dst_reg, 0, 32 - ilog2(imm), 31));
				EMIT(PPC_RAW_XOR(dst_reg, dst_reg, dst_reg_h));
				EMIT(PPC_RAW_SUBFC(dst_reg, dst_reg_h, dst_reg));
				EMIT(PPC_RAW_SUBFE(dst_reg_h, dst_reg_h, dst_reg_h));
			} else {
				EMIT(PPC_RAW_RLWINM(dst_reg, src2_reg, 0, 32 - ilog2(imm), 31));
				EMIT(PPC_RAW_LI(dst_reg_h, 0));
			}
			break;
		case BPF_ALU64 | BPF_DIV | BPF_K: 
			if (!imm)
				return -EINVAL;
			if (!is_power_of_2(abs(imm)))
				return -EOPNOTSUPP;
			if (imm < 0) {
				EMIT(PPC_RAW_SUBFIC(dst_reg, src2_reg, 0));
				EMIT(PPC_RAW_SUBFZE(dst_reg_h, src2_reg_h));
				imm = -imm;
				src2_reg = dst_reg;
			}
			if (imm == 1) {
				EMIT(PPC_RAW_MR(dst_reg, src2_reg));
				EMIT(PPC_RAW_MR(dst_reg_h, src2_reg_h));
			} else {
				imm = ilog2(imm);
				EMIT(PPC_RAW_RLWINM(dst_reg, src2_reg, 32 - imm, imm, 31));
				EMIT(PPC_RAW_RLWIMI(dst_reg, src2_reg_h, 32 - imm, 0, imm - 1));
				EMIT(PPC_RAW_SRAWI(dst_reg_h, src2_reg_h, imm));
			}
			break;
		case BPF_ALU | BPF_NEG: 
			EMIT(PPC_RAW_NEG(dst_reg, src2_reg));
			break;
		case BPF_ALU64 | BPF_NEG: 
			EMIT(PPC_RAW_SUBFIC(dst_reg, src2_reg, 0));
			EMIT(PPC_RAW_SUBFZE(dst_reg_h, src2_reg_h));
			break;
		case BPF_ALU64 | BPF_AND | BPF_X: 
			EMIT(PPC_RAW_AND(dst_reg, src2_reg, src_reg));
			EMIT(PPC_RAW_AND(dst_reg_h, src2_reg_h, src_reg_h));
			break;
		case BPF_ALU | BPF_AND | BPF_X: 
			EMIT(PPC_RAW_AND(dst_reg, src2_reg, src_reg));
			break;
		case BPF_ALU64 | BPF_AND | BPF_K: 
			if (imm >= 0)
				EMIT(PPC_RAW_LI(dst_reg_h, 0));
			fallthrough;
		case BPF_ALU | BPF_AND | BPF_K: 
			if (!IMM_H(imm)) {
				EMIT(PPC_RAW_ANDI(dst_reg, src2_reg, IMM_L(imm)));
			} else if (!IMM_L(imm)) {
				EMIT(PPC_RAW_ANDIS(dst_reg, src2_reg, IMM_H(imm)));
			} else if (imm == (((1 << fls(imm)) - 1) ^ ((1 << (ffs(i) - 1)) - 1))) {
				EMIT(PPC_RAW_RLWINM(dst_reg, src2_reg, 0,
						    32 - fls(imm), 32 - ffs(imm)));
			} else {
				PPC_LI32(_R0, imm);
				EMIT(PPC_RAW_AND(dst_reg, src2_reg, _R0));
			}
			break;
		case BPF_ALU64 | BPF_OR | BPF_X: 
			EMIT(PPC_RAW_OR(dst_reg, src2_reg, src_reg));
			EMIT(PPC_RAW_OR(dst_reg_h, src2_reg_h, src_reg_h));
			break;
		case BPF_ALU | BPF_OR | BPF_X: 
			EMIT(PPC_RAW_OR(dst_reg, src2_reg, src_reg));
			break;
		case BPF_ALU64 | BPF_OR | BPF_K:
			if (imm < 0)
				EMIT(PPC_RAW_LI(dst_reg_h, -1));
			fallthrough;
		case BPF_ALU | BPF_OR | BPF_K:
			if (IMM_L(imm)) {
				EMIT(PPC_RAW_ORI(dst_reg, src2_reg, IMM_L(imm)));
				src2_reg = dst_reg;
			}
			if (IMM_H(imm))
				EMIT(PPC_RAW_ORIS(dst_reg, src2_reg, IMM_H(imm)));
			break;
		case BPF_ALU64 | BPF_XOR | BPF_X: 
			if (dst_reg == src_reg) {
				EMIT(PPC_RAW_LI(dst_reg, 0));
				EMIT(PPC_RAW_LI(dst_reg_h, 0));
			} else {
				EMIT(PPC_RAW_XOR(dst_reg, src2_reg, src_reg));
				EMIT(PPC_RAW_XOR(dst_reg_h, src2_reg_h, src_reg_h));
			}
			break;
		case BPF_ALU | BPF_XOR | BPF_X: 
			if (dst_reg == src_reg)
				EMIT(PPC_RAW_LI(dst_reg, 0));
			else
				EMIT(PPC_RAW_XOR(dst_reg, src2_reg, src_reg));
			break;
		case BPF_ALU64 | BPF_XOR | BPF_K: 
			if (imm < 0)
				EMIT(PPC_RAW_NOR(dst_reg_h, src2_reg_h, src2_reg_h));
			fallthrough;
		case BPF_ALU | BPF_XOR | BPF_K: 
			if (IMM_L(imm)) {
				EMIT(PPC_RAW_XORI(dst_reg, src2_reg, IMM_L(imm)));
				src2_reg = dst_reg;
			}
			if (IMM_H(imm))
				EMIT(PPC_RAW_XORIS(dst_reg, src2_reg, IMM_H(imm)));
			break;
		case BPF_ALU | BPF_LSH | BPF_X: 
			EMIT(PPC_RAW_SLW(dst_reg, src2_reg, src_reg));
			break;
		case BPF_ALU64 | BPF_LSH | BPF_X: 
			bpf_set_seen_register(ctx, tmp_reg);
			EMIT(PPC_RAW_SUBFIC(_R0, src_reg, 32));
			EMIT(PPC_RAW_SLW(dst_reg_h, src2_reg_h, src_reg));
			EMIT(PPC_RAW_ADDI(tmp_reg, src_reg, 32));
			EMIT(PPC_RAW_SRW(_R0, src2_reg, _R0));
			EMIT(PPC_RAW_SLW(tmp_reg, src2_reg, tmp_reg));
			EMIT(PPC_RAW_OR(dst_reg_h, dst_reg_h, _R0));
			EMIT(PPC_RAW_SLW(dst_reg, src2_reg, src_reg));
			EMIT(PPC_RAW_OR(dst_reg_h, dst_reg_h, tmp_reg));
			break;
		case BPF_ALU | BPF_LSH | BPF_K: 
			if (imm)
				EMIT(PPC_RAW_SLWI(dst_reg, src2_reg, imm));
			else
				EMIT(PPC_RAW_MR(dst_reg, src2_reg));
			break;
		case BPF_ALU64 | BPF_LSH | BPF_K: 
			if (imm < 0)
				return -EINVAL;
			if (!imm) {
				EMIT(PPC_RAW_MR(dst_reg, src2_reg));
			} else if (imm < 32) {
				EMIT(PPC_RAW_RLWINM(dst_reg_h, src2_reg_h, imm, 0, 31 - imm));
				EMIT(PPC_RAW_RLWIMI(dst_reg_h, src2_reg, imm, 32 - imm, 31));
				EMIT(PPC_RAW_RLWINM(dst_reg, src2_reg, imm, 0, 31 - imm));
			} else if (imm < 64) {
				EMIT(PPC_RAW_RLWINM(dst_reg_h, src2_reg, imm, 0, 31 - imm));
				EMIT(PPC_RAW_LI(dst_reg, 0));
			} else {
				EMIT(PPC_RAW_LI(dst_reg_h, 0));
				EMIT(PPC_RAW_LI(dst_reg, 0));
			}
			break;
		case BPF_ALU | BPF_RSH | BPF_X: 
			EMIT(PPC_RAW_SRW(dst_reg, src2_reg, src_reg));
			break;
		case BPF_ALU64 | BPF_RSH | BPF_X: 
			bpf_set_seen_register(ctx, tmp_reg);
			EMIT(PPC_RAW_SUBFIC(_R0, src_reg, 32));
			EMIT(PPC_RAW_SRW(dst_reg, src2_reg, src_reg));
			EMIT(PPC_RAW_ADDI(tmp_reg, src_reg, 32));
			EMIT(PPC_RAW_SLW(_R0, src2_reg_h, _R0));
			EMIT(PPC_RAW_SRW(tmp_reg, dst_reg_h, tmp_reg));
			EMIT(PPC_RAW_OR(dst_reg, dst_reg, _R0));
			EMIT(PPC_RAW_SRW(dst_reg_h, src2_reg_h, src_reg));
			EMIT(PPC_RAW_OR(dst_reg, dst_reg, tmp_reg));
			break;
		case BPF_ALU | BPF_RSH | BPF_K: 
			if (imm)
				EMIT(PPC_RAW_SRWI(dst_reg, src2_reg, imm));
			else
				EMIT(PPC_RAW_MR(dst_reg, src2_reg));
			break;
		case BPF_ALU64 | BPF_RSH | BPF_K: 
			if (imm < 0)
				return -EINVAL;
			if (!imm) {
				EMIT(PPC_RAW_MR(dst_reg, src2_reg));
				EMIT(PPC_RAW_MR(dst_reg_h, src2_reg_h));
			} else if (imm < 32) {
				EMIT(PPC_RAW_RLWINM(dst_reg, src2_reg, 32 - imm, imm, 31));
				EMIT(PPC_RAW_RLWIMI(dst_reg, src2_reg_h, 32 - imm, 0, imm - 1));
				EMIT(PPC_RAW_RLWINM(dst_reg_h, src2_reg_h, 32 - imm, imm, 31));
			} else if (imm < 64) {
				EMIT(PPC_RAW_RLWINM(dst_reg, src2_reg_h, 64 - imm, imm - 32, 31));
				EMIT(PPC_RAW_LI(dst_reg_h, 0));
			} else {
				EMIT(PPC_RAW_LI(dst_reg, 0));
				EMIT(PPC_RAW_LI(dst_reg_h, 0));
			}
			break;
		case BPF_ALU | BPF_ARSH | BPF_X: 
			EMIT(PPC_RAW_SRAW(dst_reg, src2_reg, src_reg));
			break;
		case BPF_ALU64 | BPF_ARSH | BPF_X: 
			bpf_set_seen_register(ctx, tmp_reg);
			EMIT(PPC_RAW_SUBFIC(_R0, src_reg, 32));
			EMIT(PPC_RAW_SRW(dst_reg, src2_reg, src_reg));
			EMIT(PPC_RAW_SLW(_R0, src2_reg_h, _R0));
			EMIT(PPC_RAW_ADDI(tmp_reg, src_reg, 32));
			EMIT(PPC_RAW_OR(dst_reg, dst_reg, _R0));
			EMIT(PPC_RAW_RLWINM(_R0, tmp_reg, 0, 26, 26));
			EMIT(PPC_RAW_SRAW(tmp_reg, src2_reg_h, tmp_reg));
			EMIT(PPC_RAW_SRAW(dst_reg_h, src2_reg_h, src_reg));
			EMIT(PPC_RAW_SLW(tmp_reg, tmp_reg, _R0));
			EMIT(PPC_RAW_OR(dst_reg, dst_reg, tmp_reg));
			break;
		case BPF_ALU | BPF_ARSH | BPF_K: 
			if (imm)
				EMIT(PPC_RAW_SRAWI(dst_reg, src2_reg, imm));
			else
				EMIT(PPC_RAW_MR(dst_reg, src2_reg));
			break;
		case BPF_ALU64 | BPF_ARSH | BPF_K: 
			if (imm < 0)
				return -EINVAL;
			if (!imm) {
				EMIT(PPC_RAW_MR(dst_reg, src2_reg));
				EMIT(PPC_RAW_MR(dst_reg_h, src2_reg_h));
			} else if (imm < 32) {
				EMIT(PPC_RAW_RLWINM(dst_reg, src2_reg, 32 - imm, imm, 31));
				EMIT(PPC_RAW_RLWIMI(dst_reg, src2_reg_h, 32 - imm, 0, imm - 1));
				EMIT(PPC_RAW_SRAWI(dst_reg_h, src2_reg_h, imm));
			} else if (imm < 64) {
				EMIT(PPC_RAW_SRAWI(dst_reg, src2_reg_h, imm - 32));
				EMIT(PPC_RAW_SRAWI(dst_reg_h, src2_reg_h, 31));
			} else {
				EMIT(PPC_RAW_SRAWI(dst_reg, src2_reg_h, 31));
				EMIT(PPC_RAW_SRAWI(dst_reg_h, src2_reg_h, 31));
			}
			break;
		case BPF_ALU64 | BPF_MOV | BPF_X: 
			if (off == 8) {
				EMIT(PPC_RAW_EXTSB(dst_reg, src_reg));
				EMIT(PPC_RAW_SRAWI(dst_reg_h, dst_reg, 31));
			} else if (off == 16) {
				EMIT(PPC_RAW_EXTSH(dst_reg, src_reg));
				EMIT(PPC_RAW_SRAWI(dst_reg_h, dst_reg, 31));
			} else if (off == 32 && dst_reg == src_reg) {
				EMIT(PPC_RAW_SRAWI(dst_reg_h, src_reg, 31));
			} else if (off == 32) {
				EMIT(PPC_RAW_MR(dst_reg, src_reg));
				EMIT(PPC_RAW_SRAWI(dst_reg_h, src_reg, 31));
			} else if (dst_reg != src_reg) {
				EMIT(PPC_RAW_MR(dst_reg, src_reg));
				EMIT(PPC_RAW_MR(dst_reg_h, src_reg_h));
			}
			break;
		case BPF_ALU | BPF_MOV | BPF_X: 
			if (imm == 1)
				EMIT(PPC_RAW_LI(dst_reg_h, 0));
			else if (off == 8)
				EMIT(PPC_RAW_EXTSB(dst_reg, src_reg));
			else if (off == 16)
				EMIT(PPC_RAW_EXTSH(dst_reg, src_reg));
			else if (dst_reg != src_reg)
				EMIT(PPC_RAW_MR(dst_reg, src_reg));
			break;
		case BPF_ALU64 | BPF_MOV | BPF_K: 
			PPC_LI32(dst_reg, imm);
			PPC_EX32(dst_reg_h, imm);
			break;
		case BPF_ALU | BPF_MOV | BPF_K: 
			PPC_LI32(dst_reg, imm);
			break;
		case BPF_ALU | BPF_END | BPF_FROM_LE:
		case BPF_ALU64 | BPF_END | BPF_FROM_LE:
			switch (imm) {
			case 16:
				EMIT(PPC_RAW_RLWIMI(dst_reg, src2_reg, 16, 0, 15));
				EMIT(PPC_RAW_RLWINM(dst_reg, dst_reg, 24, 16, 31));
				break;
			case 32:
				EMIT(PPC_RAW_RLWINM(_R0, src2_reg, 8, 0, 31));
				EMIT(PPC_RAW_RLWIMI(_R0, src2_reg, 24, 0, 7));
				EMIT(PPC_RAW_RLWIMI(_R0, src2_reg, 24, 16, 23));
				EMIT(PPC_RAW_MR(dst_reg, _R0));
				break;
			case 64:
				bpf_set_seen_register(ctx, tmp_reg);
				EMIT(PPC_RAW_RLWINM(tmp_reg, src2_reg, 8, 0, 31));
				EMIT(PPC_RAW_RLWINM(_R0, src2_reg_h, 8, 0, 31));
				EMIT(PPC_RAW_RLWIMI(tmp_reg, src2_reg, 24, 0, 7));
				EMIT(PPC_RAW_RLWIMI(_R0, src2_reg_h, 24, 0, 7));
				EMIT(PPC_RAW_RLWIMI(tmp_reg, src2_reg, 24, 16, 23));
				EMIT(PPC_RAW_RLWIMI(_R0, src2_reg_h, 24, 16, 23));
				EMIT(PPC_RAW_MR(dst_reg, _R0));
				EMIT(PPC_RAW_MR(dst_reg_h, tmp_reg));
				break;
			}
			if (BPF_CLASS(code) == BPF_ALU64 && imm != 64)
				EMIT(PPC_RAW_LI(dst_reg_h, 0));
			break;
		case BPF_ALU | BPF_END | BPF_FROM_BE:
			switch (imm) {
			case 16:
				EMIT(PPC_RAW_RLWINM(dst_reg, src2_reg, 0, 16, 31));
				break;
			case 32:
			case 64:
				break;
			}
			break;
		case BPF_ST | BPF_NOSPEC:
			break;
		case BPF_STX | BPF_MEM | BPF_B: 
			EMIT(PPC_RAW_STB(src_reg, dst_reg, off));
			break;
		case BPF_ST | BPF_MEM | BPF_B: 
			PPC_LI32(_R0, imm);
			EMIT(PPC_RAW_STB(_R0, dst_reg, off));
			break;
		case BPF_STX | BPF_MEM | BPF_H: 
			EMIT(PPC_RAW_STH(src_reg, dst_reg, off));
			break;
		case BPF_ST | BPF_MEM | BPF_H: 
			PPC_LI32(_R0, imm);
			EMIT(PPC_RAW_STH(_R0, dst_reg, off));
			break;
		case BPF_STX | BPF_MEM | BPF_W: 
			EMIT(PPC_RAW_STW(src_reg, dst_reg, off));
			break;
		case BPF_ST | BPF_MEM | BPF_W: 
			PPC_LI32(_R0, imm);
			EMIT(PPC_RAW_STW(_R0, dst_reg, off));
			break;
		case BPF_STX | BPF_MEM | BPF_DW: 
			EMIT(PPC_RAW_STW(src_reg_h, dst_reg, off));
			EMIT(PPC_RAW_STW(src_reg, dst_reg, off + 4));
			break;
		case BPF_ST | BPF_MEM | BPF_DW: 
			PPC_LI32(_R0, imm);
			EMIT(PPC_RAW_STW(_R0, dst_reg, off + 4));
			PPC_EX32(_R0, imm);
			EMIT(PPC_RAW_STW(_R0, dst_reg, off));
			break;
		case BPF_STX | BPF_ATOMIC | BPF_W:
			save_reg = _R0;
			ret_reg = src_reg;
			bpf_set_seen_register(ctx, tmp_reg);
			bpf_set_seen_register(ctx, ax_reg);
			EMIT(PPC_RAW_LI(tmp_reg, off));
			tmp_idx = ctx->idx * 4;
			EMIT(PPC_RAW_LWARX(_R0, tmp_reg, dst_reg, 0));
			if (imm & BPF_FETCH)
				EMIT(PPC_RAW_MR(ax_reg, _R0));
			switch (imm) {
			case BPF_ADD:
			case BPF_ADD | BPF_FETCH:
				EMIT(PPC_RAW_ADD(_R0, _R0, src_reg));
				break;
			case BPF_AND:
			case BPF_AND | BPF_FETCH:
				EMIT(PPC_RAW_AND(_R0, _R0, src_reg));
				break;
			case BPF_OR:
			case BPF_OR | BPF_FETCH:
				EMIT(PPC_RAW_OR(_R0, _R0, src_reg));
				break;
			case BPF_XOR:
			case BPF_XOR | BPF_FETCH:
				EMIT(PPC_RAW_XOR(_R0, _R0, src_reg));
				break;
			case BPF_CMPXCHG:
				ret_reg = bpf_to_ppc(BPF_REG_0);
				EMIT(PPC_RAW_CMPW(bpf_to_ppc(BPF_REG_0), _R0));
				PPC_BCC_SHORT(COND_NE, (ctx->idx + 3) * 4);
				fallthrough;
			case BPF_XCHG:
				save_reg = src_reg;
				break;
			default:
				pr_err_ratelimited("eBPF filter atomic op code %02x (@%d) unsupported\n",
						   code, i);
				return -EOPNOTSUPP;
			}
			EMIT(PPC_RAW_STWCX(save_reg, tmp_reg, dst_reg));
			PPC_BCC_SHORT(COND_NE, tmp_idx);
			if (imm & BPF_FETCH) {
				EMIT(PPC_RAW_MR(ret_reg, ax_reg));
				if (!fp->aux->verifier_zext)
					EMIT(PPC_RAW_LI(ret_reg - 1, 0)); 
			}
			break;
		case BPF_STX | BPF_ATOMIC | BPF_DW: 
			return -EOPNOTSUPP;
		case BPF_LDX | BPF_MEM | BPF_B: 
		case BPF_LDX | BPF_MEMSX | BPF_B:
		case BPF_LDX | BPF_PROBE_MEM | BPF_B:
		case BPF_LDX | BPF_PROBE_MEMSX | BPF_B:
		case BPF_LDX | BPF_MEM | BPF_H: 
		case BPF_LDX | BPF_MEMSX | BPF_H:
		case BPF_LDX | BPF_PROBE_MEM | BPF_H:
		case BPF_LDX | BPF_PROBE_MEMSX | BPF_H:
		case BPF_LDX | BPF_MEM | BPF_W: 
		case BPF_LDX | BPF_MEMSX | BPF_W:
		case BPF_LDX | BPF_PROBE_MEM | BPF_W:
		case BPF_LDX | BPF_PROBE_MEMSX | BPF_W:
		case BPF_LDX | BPF_MEM | BPF_DW: 
		case BPF_LDX | BPF_PROBE_MEM | BPF_DW:
			if (BPF_MODE(code) == BPF_PROBE_MEM || BPF_MODE(code) == BPF_PROBE_MEMSX) {
				PPC_LI32(_R0, TASK_SIZE - off);
				EMIT(PPC_RAW_CMPLW(src_reg, _R0));
				PPC_BCC_SHORT(COND_GT, (ctx->idx + 4) * 4);
				EMIT(PPC_RAW_LI(dst_reg, 0));
				if (size == BPF_DW && !fp->aux->verifier_zext)
					EMIT(PPC_RAW_LI(dst_reg_h, 0));
				else
					EMIT(PPC_RAW_NOP());
				if (size == BPF_DW ||
				    (size == BPF_B && BPF_MODE(code) == BPF_PROBE_MEMSX))
					PPC_JMP((ctx->idx + 3) * 4);
				else
					PPC_JMP((ctx->idx + 2) * 4);
			}
			if (BPF_MODE(code) == BPF_MEMSX || BPF_MODE(code) == BPF_PROBE_MEMSX) {
				switch (size) {
				case BPF_B:
					EMIT(PPC_RAW_LBZ(dst_reg, src_reg, off));
					EMIT(PPC_RAW_EXTSB(dst_reg, dst_reg));
					break;
				case BPF_H:
					EMIT(PPC_RAW_LHA(dst_reg, src_reg, off));
					break;
				case BPF_W:
					EMIT(PPC_RAW_LWZ(dst_reg, src_reg, off));
					break;
				}
				if (!fp->aux->verifier_zext)
					EMIT(PPC_RAW_SRAWI(dst_reg_h, dst_reg, 31));
			} else {
				switch (size) {
				case BPF_B:
					EMIT(PPC_RAW_LBZ(dst_reg, src_reg, off));
					break;
				case BPF_H:
					EMIT(PPC_RAW_LHZ(dst_reg, src_reg, off));
					break;
				case BPF_W:
					EMIT(PPC_RAW_LWZ(dst_reg, src_reg, off));
					break;
				case BPF_DW:
					EMIT(PPC_RAW_LWZ(dst_reg_h, src_reg, off));
					EMIT(PPC_RAW_LWZ(dst_reg, src_reg, off + 4));
					break;
				}
				if (size != BPF_DW && !fp->aux->verifier_zext)
					EMIT(PPC_RAW_LI(dst_reg_h, 0));
			}
			if (BPF_MODE(code) == BPF_PROBE_MEM) {
				int insn_idx = ctx->idx - 1;
				int jmp_off = 4;
				if (size == BPF_DW || !fp->aux->verifier_zext) {
					insn_idx -= 1;
					jmp_off += 4;
				}
				ret = bpf_add_extable_entry(fp, image, fimage, pass, ctx, insn_idx,
							    jmp_off, dst_reg);
				if (ret)
					return ret;
			}
			break;
		case BPF_LD | BPF_IMM | BPF_DW: 
			tmp_idx = ctx->idx;
			PPC_LI32(dst_reg_h, (unsigned int)insn[i + 1].imm);
			PPC_LI32(dst_reg, (unsigned int)insn[i].imm);
			if (!image)
				for (j = ctx->idx - tmp_idx; j < 4; j++)
					EMIT(PPC_RAW_NOP());
			addrs[++i] = ctx->idx * 4;
			break;
		case BPF_JMP | BPF_EXIT:
			if (i != flen - 1) {
				ret = bpf_jit_emit_exit_insn(image, ctx, _R0, exit_addr);
				if (ret)
					return ret;
			}
			break;
		case BPF_JMP | BPF_CALL:
			ctx->seen |= SEEN_FUNC;
			ret = bpf_jit_get_func_addr(fp, &insn[i], extra_pass,
						    &func_addr, &func_addr_fixed);
			if (ret < 0)
				return ret;
			if (bpf_is_seen_register(ctx, bpf_to_ppc(BPF_REG_5))) {
				EMIT(PPC_RAW_STW(bpf_to_ppc(BPF_REG_5) - 1, _R1, 8));
				EMIT(PPC_RAW_STW(bpf_to_ppc(BPF_REG_5), _R1, 12));
			}
			ret = bpf_jit_emit_func_call_rel(image, fimage, ctx, func_addr);
			if (ret)
				return ret;
			EMIT(PPC_RAW_MR(bpf_to_ppc(BPF_REG_0) - 1, _R3));
			EMIT(PPC_RAW_MR(bpf_to_ppc(BPF_REG_0), _R4));
			break;
		case BPF_JMP | BPF_JA:
			PPC_JMP(addrs[i + 1 + off]);
			break;
		case BPF_JMP32 | BPF_JA:
			PPC_JMP(addrs[i + 1 + imm]);
			break;
		case BPF_JMP | BPF_JGT | BPF_K:
		case BPF_JMP | BPF_JGT | BPF_X:
		case BPF_JMP | BPF_JSGT | BPF_K:
		case BPF_JMP | BPF_JSGT | BPF_X:
		case BPF_JMP32 | BPF_JGT | BPF_K:
		case BPF_JMP32 | BPF_JGT | BPF_X:
		case BPF_JMP32 | BPF_JSGT | BPF_K:
		case BPF_JMP32 | BPF_JSGT | BPF_X:
			true_cond = COND_GT;
			goto cond_branch;
		case BPF_JMP | BPF_JLT | BPF_K:
		case BPF_JMP | BPF_JLT | BPF_X:
		case BPF_JMP | BPF_JSLT | BPF_K:
		case BPF_JMP | BPF_JSLT | BPF_X:
		case BPF_JMP32 | BPF_JLT | BPF_K:
		case BPF_JMP32 | BPF_JLT | BPF_X:
		case BPF_JMP32 | BPF_JSLT | BPF_K:
		case BPF_JMP32 | BPF_JSLT | BPF_X:
			true_cond = COND_LT;
			goto cond_branch;
		case BPF_JMP | BPF_JGE | BPF_K:
		case BPF_JMP | BPF_JGE | BPF_X:
		case BPF_JMP | BPF_JSGE | BPF_K:
		case BPF_JMP | BPF_JSGE | BPF_X:
		case BPF_JMP32 | BPF_JGE | BPF_K:
		case BPF_JMP32 | BPF_JGE | BPF_X:
		case BPF_JMP32 | BPF_JSGE | BPF_K:
		case BPF_JMP32 | BPF_JSGE | BPF_X:
			true_cond = COND_GE;
			goto cond_branch;
		case BPF_JMP | BPF_JLE | BPF_K:
		case BPF_JMP | BPF_JLE | BPF_X:
		case BPF_JMP | BPF_JSLE | BPF_K:
		case BPF_JMP | BPF_JSLE | BPF_X:
		case BPF_JMP32 | BPF_JLE | BPF_K:
		case BPF_JMP32 | BPF_JLE | BPF_X:
		case BPF_JMP32 | BPF_JSLE | BPF_K:
		case BPF_JMP32 | BPF_JSLE | BPF_X:
			true_cond = COND_LE;
			goto cond_branch;
		case BPF_JMP | BPF_JEQ | BPF_K:
		case BPF_JMP | BPF_JEQ | BPF_X:
		case BPF_JMP32 | BPF_JEQ | BPF_K:
		case BPF_JMP32 | BPF_JEQ | BPF_X:
			true_cond = COND_EQ;
			goto cond_branch;
		case BPF_JMP | BPF_JNE | BPF_K:
		case BPF_JMP | BPF_JNE | BPF_X:
		case BPF_JMP32 | BPF_JNE | BPF_K:
		case BPF_JMP32 | BPF_JNE | BPF_X:
			true_cond = COND_NE;
			goto cond_branch;
		case BPF_JMP | BPF_JSET | BPF_K:
		case BPF_JMP | BPF_JSET | BPF_X:
		case BPF_JMP32 | BPF_JSET | BPF_K:
		case BPF_JMP32 | BPF_JSET | BPF_X:
			true_cond = COND_NE;
cond_branch:
			switch (code) {
			case BPF_JMP | BPF_JGT | BPF_X:
			case BPF_JMP | BPF_JLT | BPF_X:
			case BPF_JMP | BPF_JGE | BPF_X:
			case BPF_JMP | BPF_JLE | BPF_X:
			case BPF_JMP | BPF_JEQ | BPF_X:
			case BPF_JMP | BPF_JNE | BPF_X:
				EMIT(PPC_RAW_CMPLW(dst_reg_h, src_reg_h));
				PPC_BCC_SHORT(COND_NE, (ctx->idx + 2) * 4);
				EMIT(PPC_RAW_CMPLW(dst_reg, src_reg));
				break;
			case BPF_JMP32 | BPF_JGT | BPF_X:
			case BPF_JMP32 | BPF_JLT | BPF_X:
			case BPF_JMP32 | BPF_JGE | BPF_X:
			case BPF_JMP32 | BPF_JLE | BPF_X:
			case BPF_JMP32 | BPF_JEQ | BPF_X:
			case BPF_JMP32 | BPF_JNE | BPF_X:
				EMIT(PPC_RAW_CMPLW(dst_reg, src_reg));
				break;
			case BPF_JMP | BPF_JSGT | BPF_X:
			case BPF_JMP | BPF_JSLT | BPF_X:
			case BPF_JMP | BPF_JSGE | BPF_X:
			case BPF_JMP | BPF_JSLE | BPF_X:
				EMIT(PPC_RAW_CMPW(dst_reg_h, src_reg_h));
				PPC_BCC_SHORT(COND_NE, (ctx->idx + 2) * 4);
				EMIT(PPC_RAW_CMPLW(dst_reg, src_reg));
				break;
			case BPF_JMP32 | BPF_JSGT | BPF_X:
			case BPF_JMP32 | BPF_JSLT | BPF_X:
			case BPF_JMP32 | BPF_JSGE | BPF_X:
			case BPF_JMP32 | BPF_JSLE | BPF_X:
				EMIT(PPC_RAW_CMPW(dst_reg, src_reg));
				break;
			case BPF_JMP | BPF_JSET | BPF_X:
				EMIT(PPC_RAW_AND_DOT(_R0, dst_reg_h, src_reg_h));
				PPC_BCC_SHORT(COND_NE, (ctx->idx + 2) * 4);
				EMIT(PPC_RAW_AND_DOT(_R0, dst_reg, src_reg));
				break;
			case BPF_JMP32 | BPF_JSET | BPF_X: {
				EMIT(PPC_RAW_AND_DOT(_R0, dst_reg, src_reg));
				break;
			case BPF_JMP | BPF_JNE | BPF_K:
			case BPF_JMP | BPF_JEQ | BPF_K:
			case BPF_JMP | BPF_JGT | BPF_K:
			case BPF_JMP | BPF_JLT | BPF_K:
			case BPF_JMP | BPF_JGE | BPF_K:
			case BPF_JMP | BPF_JLE | BPF_K:
				if (imm >= 0 && imm < 32768) {
					EMIT(PPC_RAW_CMPLWI(dst_reg_h, 0));
					PPC_BCC_SHORT(COND_NE, (ctx->idx + 2) * 4);
					EMIT(PPC_RAW_CMPLWI(dst_reg, imm));
				} else {
					PPC_EX32(_R0, imm);
					EMIT(PPC_RAW_CMPLW(dst_reg_h, _R0));
					PPC_LI32(_R0, imm);
					PPC_BCC_SHORT(COND_NE, (ctx->idx + 2) * 4);
					EMIT(PPC_RAW_CMPLW(dst_reg, _R0));
				}
				break;
			case BPF_JMP32 | BPF_JNE | BPF_K:
			case BPF_JMP32 | BPF_JEQ | BPF_K:
			case BPF_JMP32 | BPF_JGT | BPF_K:
			case BPF_JMP32 | BPF_JLT | BPF_K:
			case BPF_JMP32 | BPF_JGE | BPF_K:
			case BPF_JMP32 | BPF_JLE | BPF_K:
				if (imm >= 0 && imm < 65536) {
					EMIT(PPC_RAW_CMPLWI(dst_reg, imm));
				} else {
					PPC_LI32(_R0, imm);
					EMIT(PPC_RAW_CMPLW(dst_reg, _R0));
				}
				break;
			}
			case BPF_JMP | BPF_JSGT | BPF_K:
			case BPF_JMP | BPF_JSLT | BPF_K:
			case BPF_JMP | BPF_JSGE | BPF_K:
			case BPF_JMP | BPF_JSLE | BPF_K:
				if (imm >= 0 && imm < 65536) {
					EMIT(PPC_RAW_CMPWI(dst_reg_h, imm < 0 ? -1 : 0));
					PPC_BCC_SHORT(COND_NE, (ctx->idx + 2) * 4);
					EMIT(PPC_RAW_CMPLWI(dst_reg, imm));
				} else {
					EMIT(PPC_RAW_CMPWI(dst_reg_h, imm < 0 ? -1 : 0));
					PPC_LI32(_R0, imm);
					PPC_BCC_SHORT(COND_NE, (ctx->idx + 2) * 4);
					EMIT(PPC_RAW_CMPLW(dst_reg, _R0));
				}
				break;
			case BPF_JMP32 | BPF_JSGT | BPF_K:
			case BPF_JMP32 | BPF_JSLT | BPF_K:
			case BPF_JMP32 | BPF_JSGE | BPF_K:
			case BPF_JMP32 | BPF_JSLE | BPF_K:
				if (imm >= -32768 && imm < 32768) {
					EMIT(PPC_RAW_CMPWI(dst_reg, imm));
				} else {
					PPC_LI32(_R0, imm);
					EMIT(PPC_RAW_CMPW(dst_reg, _R0));
				}
				break;
			case BPF_JMP | BPF_JSET | BPF_K:
				if (imm >= 0 && imm < 32768) {
					EMIT(PPC_RAW_ANDI(_R0, dst_reg, imm));
				} else {
					PPC_LI32(_R0, imm);
					if (imm < 0) {
						EMIT(PPC_RAW_CMPWI(dst_reg_h, 0));
						PPC_BCC_SHORT(COND_NE, (ctx->idx + 2) * 4);
					}
					EMIT(PPC_RAW_AND_DOT(_R0, dst_reg, _R0));
				}
				break;
			case BPF_JMP32 | BPF_JSET | BPF_K:
				if (imm >= 0 && imm < 32768) {
					EMIT(PPC_RAW_ANDI(_R0, dst_reg, imm));
				} else {
					PPC_LI32(_R0, imm);
					EMIT(PPC_RAW_AND_DOT(_R0, dst_reg, _R0));
				}
				break;
			}
			PPC_BCC(true_cond, addrs[i + 1 + off]);
			break;
		case BPF_JMP | BPF_TAIL_CALL:
			ctx->seen |= SEEN_TAILCALL;
			ret = bpf_jit_emit_tail_call(image, ctx, addrs[i + 1]);
			if (ret < 0)
				return ret;
			break;
		default:
			pr_err_ratelimited("eBPF filter opcode %04x (@%d) unsupported\n", code, i);
			return -EOPNOTSUPP;
		}
		if (BPF_CLASS(code) == BPF_ALU && !fp->aux->verifier_zext &&
		    !insn_is_zext(&insn[i + 1]) && !(BPF_OP(code) == BPF_END && imm == 64))
			EMIT(PPC_RAW_LI(dst_reg_h, 0));
	}
	addrs[i] = ctx->idx * 4;
	return 0;
}
