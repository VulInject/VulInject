void amdgpu_ring_mux_start_ib(struct amdgpu_ring_mux *mux, struct amdgpu_ring *ring)
{
	struct amdgpu_mux_entry *e;
	struct amdgpu_mux_chunk *chunk;
	amdgpu_mux_resubmit_chunks(mux);
	spin_unlock(&mux->lock);
	e = amdgpu_ring_mux_sw_entry(mux, ring);
	if (!e) {
		DRM_ERROR("cannot find entry!\n");
		return;
	}
	chunk = kmem_cache_alloc(amdgpu_mux_chunk_slab, GFP_KERNEL);
	if (!chunk) {
		DRM_ERROR("alloc amdgpu_mux_chunk_slab failed\n");
		return;
	}
	chunk->start = ring->wptr;
	chunk->cntl_offset = ring->buf_mask + 1;
	chunk->de_offset = ring->buf_mask + 1;
	chunk->ce_offset = ring->buf_mask + 1;
	list_add_tail(&chunk->entry, &e->list);
}
