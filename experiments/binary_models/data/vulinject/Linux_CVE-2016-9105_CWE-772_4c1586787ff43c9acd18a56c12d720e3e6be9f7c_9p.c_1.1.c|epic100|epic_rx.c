static int epic_rx(struct net_device *dev, int budget)
{
	struct epic_private *ep = netdev_priv(dev);
	int entry = ep->cur_rx % RX_RING_SIZE;
	int rx_work_limit = ep->dirty_rx + RX_RING_SIZE - ep->cur_rx;
	int work_done = 0;
	if (debug > 4)
		netdev_dbg(dev, " In epic_rx(), entry %d %8.8x.\n", entry,
			   ep->rx_ring[entry].rxstatus);
	if (rx_work_limit > budget)
		rx_work_limit = budget;
	while ((ep->rx_ring[entry].rxstatus & DescOwn) == 0) {
		int status = ep->rx_ring[entry].rxstatus;
		if (debug > 4)
			netdev_dbg(dev, "  epic_rx() status was %8.8x.\n",
				   status);
		if (--rx_work_limit < 0)
			break;
		if (status & 0x2006) {
			if (debug > 2)
				netdev_dbg(dev, "epic_rx() error status was %8.8x.\n",
					   status);
			if (status & 0x2000) {
				netdev_warn(dev, "Oversized Ethernet frame spanned multiple buffers, status %4.4x!\n",
					    status);
				dev->stats.rx_length_errors++;
			} else if (status & 0x0006)
				dev->stats.rx_errors++;
		} else {
			short pkt_len = (status >> 16) - 4;
			struct sk_buff *skb;
			if (pkt_len > PKT_BUF_SZ - 4) {
				netdev_err(dev, "Oversized Ethernet frame, status %x %d bytes.\n",
					   status, pkt_len);
				pkt_len = 1514;
			}
			if (pkt_len < rx_copybreak &&
			    (skb = netdev_alloc_skb(dev, pkt_len + 2)) != NULL) {
				skb_reserve(skb, 2);	
				dma_sync_single_for_cpu(&ep->pci_dev->dev,
							ep->rx_ring[entry].bufaddr,
							ep->rx_buf_sz,
							DMA_FROM_DEVICE);
				skb_copy_to_linear_data(skb, ep->rx_skbuff[entry]->data, pkt_len);
				dma_sync_single_for_device(&ep->pci_dev->dev,
							   ep->rx_ring[entry].bufaddr,
							   ep->rx_buf_sz,
							   DMA_FROM_DEVICE);
			} else {
				dma_unmap_single(&ep->pci_dev->dev,
						 ep->rx_ring[entry].bufaddr,
						 ep->rx_buf_sz,
						 DMA_FROM_DEVICE);
				skb_put(skb = ep->rx_skbuff[entry], pkt_len);
				ep->rx_skbuff[entry] = NULL;
			}
			skb->protocol = eth_type_trans(skb, dev);
			netif_receive_skb(skb);
			dev->stats.rx_packets++;
			dev->stats.rx_bytes += pkt_len;
		}
		work_done++;
		entry = (++ep->cur_rx) % RX_RING_SIZE;
	}
	for (; ep->cur_rx - ep->dirty_rx > 0; ep->dirty_rx++) {
		entry = ep->dirty_rx % RX_RING_SIZE;
		if (ep->rx_skbuff[entry] == NULL) {
			struct sk_buff *skb;
			skb = ep->rx_skbuff[entry] = netdev_alloc_skb(dev, ep->rx_buf_sz + 2);
			if (skb == NULL)
				break;
			skb_reserve(skb, 2);	
			ep->rx_ring[entry].bufaddr = dma_map_single(&ep->pci_dev->dev,
								    skb->data,
								    ep->rx_buf_sz,
								    DMA_FROM_DEVICE);
			work_done++;
		}
		ep->rx_ring[entry].rxstatus = DescOwn;
	}
	return work_done;
}
