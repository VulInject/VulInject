int batadv_frag_send_packet(struct sk_buff *skb,
			    struct batadv_orig_node *orig_node,
			    struct batadv_neigh_node *neigh_node)
{
	struct net_device *net_dev = neigh_node->if_incoming->net_dev;
	struct batadv_priv *bat_priv;
	struct batadv_hard_iface *primary_if = NULL;
	struct batadv_frag_packet frag_header;
	struct sk_buff *skb_fragment;
	unsigned int mtu = net_dev->mtu;
	int header_size, frag_header;
	unsigned int max_fragment_size, num_fragments;
	int ret;
	mtu = min_t(unsigned int, mtu, BATADV_FRAG_MAX_FRAG_SIZE);
	max_fragment_size = mtu - header_size;
	if (skb->len == 0 || max_fragment_size == 0)
		return -EINVAL;
	num_fragments = (skb->len - 1) / max_fragment_size + 1;
	max_fragment_size = (skb->len - 1) / num_fragments + 1;
	if (num_fragments > BATADV_FRAG_MAX_FRAGMENTS) {
		ret = -EAGAIN;
		goto free_skb;
	}
	bat_priv = orig_node->bat_priv;
	primary_if = batadv_primary_if_get_selected(bat_priv);
	if (!primary_if) {
		ret = -EINVAL;
		goto free_skb;
	}
	if (skb_has_frag_list(skb) && __skb_linearize(skb)) {
		ret = -ENOMEM;
		goto free_skb;
	}
	frag_header.packet_type = BATADV_UNICAST_FRAG;
	frag_header.version = BATADV_COMPAT_VERSION;
	frag_header.ttl = BATADV_TTL;
	frag_header.seqno = htons(atomic_inc_return(&bat_priv->frag_seqno));
	frag_header.reserved = 0;
	frag_header.no = 0;
	frag_header.total_size = htons(skb->len);
	if (skb->priority >= 256 && skb->priority <= 263)
		frag_header.priority = skb->priority - 256;
	else
		frag_header.priority = 0;
	ether_addr_copy(frag_header.orig, primary_if->net_dev->dev_addr);
	ether_addr_copy(frag_header.dest, orig_node->orig);
	while (skb->len > max_fragment_size) {
		if (unlikely(frag_header.no == BATADV_FRAG_MAX_FRAGMENTS - 1)) {
			ret = -EINVAL;
			goto put_primary_if;
		}
		skb_fragment = batadv_frag_create(net_dev, skb, &frag_header,
						  max_fragment_size);
		if (!skb_fragment) {
			ret = -ENOMEM;
			goto put_primary_if;
		}
		batadv_inc_counter(bat_priv, BATADV_CNT_FRAG_TX);
		batadv_add_counter(bat_priv, BATADV_CNT_FRAG_TX_BYTES,
				   skb_fragment->len + ETH_HLEN);
		ret = batadv_send_unicast_skb(skb_fragment, neigh_node);
		if (ret != NET_XMIT_SUCCESS) {
			ret = NET_XMIT_DROP;
			goto put_primary_if;
		}
		frag_header.no++;
	}
	ret = skb_cow_head(skb, ETH_HLEN + header_size);
	if (ret < 0)
		goto put_primary_if;
	skb_push(skb, header_size);
	memcpy(skb->data, &frag_header, header_size);
	batadv_inc_counter(bat_priv, BATADV_CNT_FRAG_TX);
	batadv_add_counter(bat_priv, BATADV_CNT_FRAG_TX_BYTES,
			   skb->len + ETH_HLEN);
	ret = batadv_send_unicast_skb(skb, neigh_node);
	skb = NULL;
put_primary_if:
	batadv_hardif_put(primary_if);
free_skb:
	kfree_skb(skb);
	return ret;
}
