asmlinkage void __kprobes do_sparc64_fault(struct pt_regs *regs)
{
	enum ctx_state prev_state = exception_enter();
	struct mm_struct *mm = current->mm;
	struct vm_area_struct *vma;
	unsigned int insn = 0;
	int si_code, fault_code;
	vm_fault_t fault;
	unsigned int address, mm_rss;
	unsigned int flags = FAULT_FLAG_DEFAULT;
	fault_code = get_thread_fault_code();
	if (kprobe_page_fault(regs, 0))
		goto exit_exception;
	si_code = SEGV_MAPERR;
	address = current_thread_info()->fault_address;
	if ((fault_code & FAULT_CODE_ITLB) &&
	    (fault_code & FAULT_CODE_DTLB))
		BUG();
	if (test_thread_flag(TIF_32BIT)) {
		if (!(regs->tstate & TSTATE_PRIV)) {
			if (unlikely((regs->tpc >> 32) != 0)) {
				bogus_32bit_fault_tpc(regs);
				goto intr_or_no_mm;
			}
		}
		if (unlikely((address >> 32) != 0))
			goto intr_or_no_mm;
	}
	if (regs->tstate & TSTATE_PRIV) {
		unsigned int tpc = regs->tpc;
		if ((tpc >= KERNBASE && tpc < (unsigned int) __init_end) ||
		    (tpc >= MODULES_VADDR && tpc < MODULES_END)) {
		} else {
			goto exit_exception;
		}
	} else
		flags |= FAULT_FLAG_USER;
	if (faulthandler_disabled() || !mm)
		goto intr_or_no_mm;
	perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS, 1, regs, address);
	if (!mmap_read_trylock(mm)) {
		if ((regs->tstate & TSTATE_PRIV) &&
		    !search_exception_tables(regs->tpc)) {
			insn = get_fault_insn(regs, insn);
			goto handle_kernel_fault;
		}
retry:
		mmap_read_lock(mm);
	}
	if (fault_code & FAULT_CODE_BAD_RA)
		goto do_sigbus;
	vma = find_vma(mm, address);
	if (!vma)
		goto bad_area;
	if (((fault_code &
	      (FAULT_CODE_DTLB | FAULT_CODE_WRITE | FAULT_CODE_WINFIXUP)) == FAULT_CODE_DTLB) &&
	    (vma->vm_flags & VM_WRITE) != 0) {
		insn = get_fault_insn(regs, 0);
		if (!insn)
			goto continue_fault;
		if ((insn & 0xc0200000) == 0xc0200000 &&
		    (insn & 0x01780000) != 0x01680000) {
			fault_code |= FAULT_CODE_WRITE;
		}
	}
continue_fault:
	if (vma->vm_start <= address)
		goto good_area;
	if (!(vma->vm_flags & VM_GROWSDOWN))
		goto bad_area;
	if (!(fault_code & FAULT_CODE_WRITE)) {
		insn = get_fault_insn(regs, insn);
		if ((insn & 0xc0800000) == 0xc0800000) {
			unsigned char asi;
			if (insn & 0x2000)
				asi = (regs->tstate >> 24);
			else
				asi = (insn >> 5);
			if ((asi & 0xf2) == 0x82)
				goto bad_area;
		}
	}
	vma = expand_stack(mm, address);
	if (!vma)
		goto bad_area_nosemaphore;
good_area:
	si_code = SEGV_ACCERR;
	if ((fault_code & FAULT_CODE_ITLB) && !(vma->vm_flags & VM_EXEC)) {
		WARN(address != regs->tpc,
		     "address (%lx) != regs->tpc (%lx)\n", address, regs->tpc);
		WARN_ON(regs->tstate & TSTATE_PRIV);
		goto bad_area;
	}
	if (fault_code & FAULT_CODE_WRITE) {
		if (!(vma->vm_flags & VM_WRITE))
			goto bad_area;
		if (tlb_type == spitfire &&
		    (vma->vm_flags & VM_EXEC) != 0 &&
		    vma->vm_file != NULL)
			set_thread_fault_code(fault_code |
					      FAULT_CODE_BLKCOMMIT);
		flags |= FAULT_FLAG_WRITE;
	} else {
		if (!(vma->vm_flags & (VM_READ | VM_EXEC)))
			goto bad_area;
	}
	fault = handle_mm_fault(vma, address, flags, regs);
	if (fault_signal_pending(fault, regs)) {
		if (regs->tstate & TSTATE_PRIV) {
			insn = get_fault_insn(regs, insn);
			goto handle_kernel_fault;
		}
		goto exit_exception;
	}
	if (fault & VM_FAULT_COMPLETED)
		goto lock_released;
	if (unlikely(fault & VM_FAULT_ERROR)) {
		if (fault & VM_FAULT_OOM)
			goto out_of_memory;
		else if (fault & VM_FAULT_SIGSEGV)
			goto bad_area;
		else if (fault & VM_FAULT_SIGBUS)
			goto do_sigbus;
		BUG();
	}
	if (fault & VM_FAULT_RETRY) {
		flags |= FAULT_FLAG_TRIED;
		goto retry;
	}
	mmap_read_unlock(mm);
lock_released:
	mm_rss = get_mm_rss(mm);
#if defined(CONFIG_TRANSPARENT_HUGEPAGE)
	mm_rss -= (mm->context.thp_pte_count * (HPAGE_SIZE / PAGE_SIZE));
#endif
	if (unlikely(mm_rss >
		     mm->context.tsb_block[MM_TSB_BASE].tsb_rss_limit))
		tsb_grow(mm, MM_TSB_BASE, mm_rss);
#if defined(CONFIG_HUGETLB_PAGE) || defined(CONFIG_TRANSPARENT_HUGEPAGE)
	mm_rss = mm->context.hugetlb_pte_count + mm->context.thp_pte_count;
	mm_rss *= REAL_HPAGE_PER_HPAGE;
	if (unlikely(mm_rss >
		     mm->context.tsb_block[MM_TSB_HUGE].tsb_rss_limit)) {
		if (mm->context.tsb_block[MM_TSB_HUGE].tsb)
			tsb_grow(mm, MM_TSB_HUGE, mm_rss);
		else
			hugetlb_setup(regs);
	}
#endif
exit_exception:
	exception_exit(prev_state);
	return;
bad_area:
	mmap_read_unlock(mm);
bad_area_nosemaphore:
	insn = get_fault_insn(regs, insn);
handle_kernel_fault:
	do_kernel_fault(regs, si_code, fault_code, insn, address);
	goto exit_exception;
out_of_memory:
	insn = get_fault_insn(regs, insn);
	mmap_read_unlock(mm);
	if (!(regs->tstate & TSTATE_PRIV)) {
		pagefault_out_of_memory();
		goto exit_exception;
	}
	goto handle_kernel_fault;
intr_or_no_mm:
	insn = get_fault_insn(regs, 0);
	goto handle_kernel_fault;
do_sigbus:
	insn = get_fault_insn(regs, insn);
	mmap_read_unlock(mm);
	do_fault_siginfo(BUS_ADRERR, SIGBUS, regs, address, insn, fault_code);
	if (regs->tstate & TSTATE_PRIV)
		goto handle_kernel_fault;
}
