int ath11k_dp_rx_mon_status_bufs_replenish(struct ath11k_base *ab, int mac_id,
					   struct dp_rxdma_ring *rx_ring,
					   int req_entries,
					   enum hal_rx_buf_return_buf_manager mgr)
{
	struct hal_srng *srng;
	unsigned int *desc;
	struct sk_buff *skb;
	int num_free;
	int num_remain;
	int buf_id;
	unsigned int cookie;
	dma_addr_t paddr;
	req_entries = min(req_entries, rx_ring->bufs_max);
	srng = &ab->hal.srng_list[rx_ring->refill_buf_ring.ring_id];
	ath11k_hal_srng_access_begin(ab, srng);
	num_free = ath11k_hal_srng_src_num_free(ab, srng, true);
	req_entries = min(num_free, req_entries);
	num_remain = req_entries;
	while (num_remain > 0) {
		skb = ath11k_dp_rx_alloc_mon_status_buf(ab, rx_ring,
							&buf_id);
		if (!skb)
			break;
		paddr = ATH11K_SKB_RXCB(skb)->paddr;
		desc = ath11k_hal_srng_src_get_next_entry(ab, srng);
		if (!desc)
			goto fail_desc_get;
		cookie = FIELD_PREP(DP_RXDMA_BUF_COOKIE_PDEV_ID, mac_id) |
			 FIELD_PREP(DP_RXDMA_BUF_COOKIE_BUF_ID, buf_id);
		num_remain--;
		ath11k_hal_rx_buf_addr_info_set(desc, paddr, cookie, mgr);
	}
	ath11k_hal_srng_access_end(ab, srng);
	spin_unlock_bh(&srng->lock);
	return req_entries - num_remain;
fail_desc_get:
	spin_lock_bh(&rx_ring->idr_lock);
	idr_remove(&rx_ring->bufs_idr, buf_id);
	spin_unlock_bh(&rx_ring->idr_lock);
	dma_unmap_single(ab->dev, paddr, skb->len + skb_tailroom(skb),
			 DMA_FROM_DEVICE);
	dev_kfree_skb_any(skb);
	ath11k_hal_srng_access_end(ab, srng);
	spin_unlock_bh(&srng->lock);
	return req_entries - num_remain;
}
