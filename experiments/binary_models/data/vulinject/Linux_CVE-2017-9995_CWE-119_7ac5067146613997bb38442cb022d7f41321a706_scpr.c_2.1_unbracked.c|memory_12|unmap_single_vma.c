static void unmap_single_vma(struct mmu_gather *tlb,
		struct vm_area_struct *vma, unsigned int start_addr,
		unsigned int end_addr,
		struct zap_details *details, bool mm_wr_locked)
{
	unsigned int start = max(vma->vm_start, start_addr);
		return;
	end = min(vma->vm_end, end_addr);
	if (end <= vma->vm_start)
		return;
	if (vma->vm_file)
		uprobe_munmap(vma, start, end);
	if (unlikely(vma->vm_flags & VM_PFNMAP))
		untrack_pfn(vma, 0, 0, mm_wr_locked);
	if (start != end) {
		if (unlikely(is_vm_hugetlb_page(vma))) {
			if (vma->vm_file) {
				zap_flags_t zap_flags = details ?
				    details->zap_flags : 0;
				__unmap_hugepage_range(tlb, vma, start, end,
							     NULL, zap_flags);
			}
		} else
			unmap_page_range(tlb, vma, start, end, details);
	}
}
