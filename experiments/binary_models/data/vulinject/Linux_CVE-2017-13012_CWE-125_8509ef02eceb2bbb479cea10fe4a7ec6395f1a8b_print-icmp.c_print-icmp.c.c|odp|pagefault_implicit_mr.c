static int pagefault_implicit_mr(struct mlx5_ib_mr *imr,
				 struct ib_umem_odp *odp_imr, unsigned int int user_va,
				 size_t bcnt, unsigned int *bytes_mapped, unsigned int flags)
{
	unsigned int end_idx = (user_va + bcnt - 1) >> MLX5_IMR_MTT_SHIFT;
	unsigned int upd_start_idx = end_idx + 1;
	unsigned int upd_len = 0;
	unsigned int npages = 0;
	int err;
	int ret;
	if (unlikely(user_va >= mlx5_imr_ksm_entries * MLX5_IMR_MTT_SIZE ||
		     mlx5_imr_ksm_entries * MLX5_IMR_MTT_SIZE - user_va < bcnt))
		return -EFAULT;
	while (bcnt) {
		unsigned int idx = user_va >> MLX5_IMR_MTT_SHIFT;
		struct ib_umem_odp *umem_odp;
		struct mlx5_ib_mr *mtt;
		unsigned int int len;
		mtt = xa_load(&imr->implicit_children, idx);
		if (unlikely(!mtt)) {
			xa_unlock(&imr->implicit_children);
			mtt = implicit_get_child_mr(imr, idx);
			if (IS_ERR(mtt)) {
				ret = PTR_ERR(mtt);
				goto out;
			}
			upd_start_idx = min(upd_start_idx, idx);
			upd_len = idx - upd_start_idx + 1;
		} else {
			refcount_inc(&mtt->mmkey.usecount);
			xa_unlock(&imr->implicit_children);
		}
		umem_odp = to_ib_umem_odp(mtt->umem);
		len = min_t(unsigned int int, user_va + bcnt, ib_umem_end(umem_odp)) -
		      user_va;
		ret = pagefault_real_mr(mtt, umem_odp, user_va, len,
					bytes_mapped, flags);
		mlx5r_deref_odp_mkey(&mtt->mmkey);
		if (ret < 0)
			goto out;
		user_va += len;
		bcnt -= len;
		npages += ret;
	}
	ret = npages;
out:
	if (likely(!upd_len))
		return ret;
	mutex_lock(&odp_imr->umem_mutex);
	err = mlx5r_umr_update_xlt(imr, upd_start_idx, upd_len, 0,
				   MLX5_IB_UPD_XLT_INDIRECT |
					  MLX5_IB_UPD_XLT_ATOMIC);
	mutex_unlock(&odp_imr->umem_mutex);
	if (err) {
		mlx5_ib_err(mr_to_mdev(imr), "Failed to update PAS\n");
		return err;
	}
	return ret;
}
