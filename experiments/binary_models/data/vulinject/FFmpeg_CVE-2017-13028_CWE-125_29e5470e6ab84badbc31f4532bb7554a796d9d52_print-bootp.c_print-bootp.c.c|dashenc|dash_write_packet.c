static int dash_write_packet(AVFormatContext *s, AVPacket *pkt)
{
    DASHContext *c = s->priv_data;
    AVStream *st = s->streams[pkt->stream_index];
    OutputStream *os = &c->streams[pkt->stream_index];
    AdaptationSet *as = &c->as[os->as_idx - 1];
    int64_t seg_end_duration, elapsed_duration;
    int ret;
    ret = update_stream_extradata(s, os, pkt, &st->avg_frame_rate);
    if (ret < 0)
        return ret;
    // Fill in a heuristic guess of the packet duration, if none is available.
    // The mp4 muxer will do something similar (for the last packet in a fragment)
    // if nothing is set (setting it for the other packets doesn't hurt).
    // By setting a nonzero duration here, we can be sure that the mp4 muxer won't
    // invoke its heuristic (this doesn't have to be identical to that algorithm),
    // so that we know the exact timestamps of fragments.
    if (!pkt->duration && os->last_dts != AV_NOPTS_VALUE)
        pkt->duration = pkt->dts - os->last_dts;
    os->last_dts = pkt->dts;
    // If forcing the stream to start at 0, the mp4 muxer will set the start
    // timestamps to 0. Do the same here, to avoid mismatches in duration/timestamps.
    if (os->first_pts == AV_NOPTS_VALUE &&
        s->avoid_negative_ts == AVFMT_AVOID_NEG_TS_MAKE_ZERO) {
        pkt->pts -= pkt->dts;
        pkt->dts  = 0;
    }
    if (c->write_prft) {
        ret = dash_parse_prft(c, pkt);
        if (ret < 0)
            return ret;
    }
    if (os->first_pts == AV_NOPTS_VALUE) {
        os->first_pts = pkt->pts;
    }
    os->last_pts = pkt->pts;
    if (!c->availability_start_time[0]) {
        int64_t start_time_us = av_gettime();
        c->start_time_s = start_time_us / 1000000;
        format_date(c->availability_start_time,
                    sizeof(c->availability_start_time), start_time_us);
    }
    if (!os->packets_written)
        os->availability_time_offset = 0;
    if (!os->availability_time_offset &&
        ((os->frag_type == FRAG_TYPE_DURATION && os->seg_duration != os->frag_duration) ||
         (os->frag_type == FRAG_TYPE_EVERY_FRAME && pkt->duration))) {
        AdaptationSet *as = &c->as[os->as_idx - 1];
        int64_t frame_duration = 0;
        switch (os->frag_type) {
        case FRAG_TYPE_DURATION:
            frame_duration = os->frag_duration;
            break;
        case FRAG_TYPE_EVERY_FRAME:
            frame_duration = av_rescale_q(pkt->duration, st->time_base, AV_TIME_BASE_Q);
            break;
        }
         os->availability_time_offset = ((double) os->seg_duration -
                                         frame_duration) / AV_TIME_BASE;
        as->max_frag_duration = FFMAX(frame_duration, as->max_frag_duration);
    }
    if (c->use_template && !c->use_timeline) {
        elapsed_duration = pkt->pts - os->first_pts;
        seg_end_duration = (int64_t) os->segment_index * os->seg_duration;
    } else {
        elapsed_duration = pkt->pts - os->start_pts;
        seg_end_duration = os->seg_duration;
    }
    if (os->parser &&
        (os->frag_type == FRAG_TYPE_PFRAMES ||
         as->trick_idx >= 0)) {
        // Parse the packets only in scenarios where it's needed
        uint8_t *data;
        int size;
        av_parser_parse2(os->parser, os->parser_avctx,
                         &data, &size, pkt->data, pkt->size,
                         pkt->pts, pkt->dts, pkt->pos);
        os->coding_dependency |= os->parser->pict_type != AV_PICTURE_TYPE_I;
    }
    if (pkt->flags & AV_PKT_FLAG_KEY && os->packets_written &&
        av_compare_ts(elapsed_duration, st->time_base,
                      seg_end_duration, AV_TIME_BASE_Q) >= 0) {
        if (!c->has_video || st->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {
            c->last_duration = av_rescale_q(pkt->pts - os->start_pts,
                    st->time_base,
                    AV_TIME_BASE_Q);
            c->total_duration = av_rescale_q(pkt->pts - os->first_pts,
                    st->time_base,
                    AV_TIME_BASE_Q);
            if ((!c->use_timeline || !c->use_template) && os->last_duration) {
                if (c->last_duration < os->last_duration*9/10 ||
                        c->last_duration > os->last_duration*11/10) {
                    av_log(s, AV_LOG_WARNING,
                            "Segment durations differ too much, enable use_timeline "
                            "and use_template, or keep a stricter keyframe interval\n");
                }
            }
        }
        if (c->write_prft && os->producer_reference_time.wallclock && !os->producer_reference_time_str[0])
            format_date(os->producer_reference_time_str,
                        sizeof(os->producer_reference_time_str),
                        os->producer_reference_time.wallclock);
        if ((ret = dash_flush(s, 0, pkt->stream_index)) < 0)
            return ret;
    }
    if (!os->packets_written) {
        // If we wrote a previous segment, adjust the start time of the segment
        // to the end of the previous one (which is the same as the mp4 muxer
        // does). This avoids gaps in the timeline.
        if (os->max_pts != AV_NOPTS_VALUE)
            os->start_pts = os->max_pts;
        else
            os->start_pts = pkt->pts;
    }
    if (os->max_pts == AV_NOPTS_VALUE)
        os->max_pts = pkt->pts + pkt->duration;
    else
        os->max_pts = FFMAX(os->max_pts, pkt->pts + pkt->duration);
    if (st->codecpar->codec_type == AVMEDIA_TYPE_VIDEO &&
        os->frag_type == FRAG_TYPE_PFRAMES &&
        os->packets_written) {
        if ((os->parser->pict_type == AV_PICTURE_TYPE_P &&
             st->codecpar->video_delay &&
             !(os->last_flags & AV_PKT_FLAG_KEY)) ||
            pkt->flags & AV_PKT_FLAG_KEY) {
            ret = av_write_frame(os->ctx, NULL);
            if (ret < 0)
                return ret;
            if (!os->availability_time_offset) {
                int64_t frag_duration = av_rescale_q(os->total_pkt_duration, st->time_base,
                                                     AV_TIME_BASE_Q);
                os->availability_time_offset = ((double) os->seg_duration -
                                                 frag_duration) / AV_TIME_BASE;
               as->max_frag_duration = FFMAX(frag_duration, as->max_frag_duration);
            }
        }
    }
    if (pkt->flags & AV_PKT_FLAG_KEY && (os->packets_written || os->nb_segments) && !os->gop_size && as->trick_idx < 0) {
        os->gop_size = os->last_duration + av_rescale_q(os->total_pkt_duration, st->time_base, AV_TIME_BASE_Q);
        c->max_gop_size = FFMAX(c->max_gop_size, os->gop_size);
    }
    if ((ret = ff_write_chained(os->ctx, 0, pkt, s, 0)) < 0)
        return ret;
    os->packets_written++;
    os->total_pkt_size += pkt->size;
    os->total_pkt_duration += pkt->duration;
    os->last_flags = pkt->flags;
    if (!os->init_range_length)
        flush_init_segment(s, os);
    //open the output context when the first frame of a segment is ready
    if (!c->single_file && os->packets_written == 1) {
        AVDictionary *opts = NULL;
        const char *proto = avio_find_protocol_name(s->url);
        int use_rename = proto && !strcmp(proto, "file");
        if (os->segment_type == SEGMENT_TYPE_MP4)
            write_styp(os->ctx->pb);
        os->filename[0] = os->full_path[0] = os->temp_path[0] = '\0';
        ff_dash_fill_tmpl_params(os->filename, sizeof(os->filename),
                                 os->media_seg_name, pkt->stream_index,
                                 os->segment_index, os->bit_rate, os->start_pts);
        snprintf(os->full_path, sizeof(os->full_path), "%s%s", c->dirname,
                 os->filename);
        snprintf(os->temp_path, sizeof(os->temp_path),
                 use_rename ? "%s.tmp" : "%s", os->full_path);
        set_http_options(&opts, c);
        ret = dashenc_io_open(s, &os->out, os->temp_path, &opts);
        av_dict_free(&opts);
        if (ret < 0) {
            return handle_io_open_error(s, ret, os->temp_path);
        }
        // in streaming mode, the segments are available for playing
        // before fully written but the manifest is needed so that
        // clients and discover the segment filenames.
        if (c->streaming) {
            write_manifest(s, 0);
        }
        if (c->lhls) {
            char *prefetch_url = use_rename ? NULL : os->filename;
            write_hls_media_playlist(os, s, pkt->stream_index, 0, prefetch_url);
        }
    }
    //write out the data immediately in streaming mode
    if (c->streaming && os->segment_type == SEGMENT_TYPE_MP4) {
        int len = 0;
        uint8_t *buf = NULL;
        avio_flush(os->ctx->pb);
        len = avio_get_dyn_buf (os->ctx->pb, &buf);
        if (os->out) {
            avio_write(os->out, buf + os->written_len, len - os->written_len);
            avio_flush(os->out);
        }
        os->written_len = len;
    }
    return ret;
}
