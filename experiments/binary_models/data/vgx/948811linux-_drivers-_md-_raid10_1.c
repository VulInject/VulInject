static void fix_read_error ( struct r10conf * conf , struct mddev * mddev , struct r10bio * r10_bio ) { int sect = 0 ; int sectors = r10_bio -> sectors ; struct md_rdev * rdev ; int max_read_errors = atomic_read ( & mddev -> max_corr_read_errors ) ; int d = r10_bio -> devs [ r10_bio -> read_slot ] . devnum ; rdev = conf -> mirrors [ d ] . rdev ; check_decay_read_errors ( mddev , rdev ) ; atomic_inc ( & rdev -> read_errors ) ; if ( atomic_read ( & rdev -> read_errors ) > max_read_errors ) { pr_notice ( "md/raid10:%s: %pg: Raid device exceeded read_error threshold [cur %d:max %d]\n" , mdname ( mddev ) , rdev -> bdev , atomic_read ( & rdev -> read_errors ) , max_read_errors ) ; pr_notice ( "md/raid10:%s: %pg: Failing raid device\n" , mdname ( mddev ) , rdev -> bdev ) ; md_error ( mddev , rdev ) ; r10_bio -> devs [ r10_bio -> read_slot ] . bio = IO_BLOCKED ; return ; } while ( sectors ) { int s = sectors ; int sl = r10_bio -> read_slot ; int success = 0 ; int start ; if ( s > ( PAGE_SIZE >> 9 ) ) { s = PAGE_SIZE >> 9 ; } rcu_read_lock ( ) ; { sector_t first_bad ; int bad_sectors ; d = r10_bio -> devs [ sl ] . devnum ; rdev = rcu_dereference ( conf -> mirrors [ d ] . rdev ) ; if ( rdev && test_bit ( In_sync , & rdev -> flags ) && ! test_bit ( Faulty , & rdev -> flags ) && is_badblock ( rdev , r10_bio -> devs [ sl ] . addr + sect , s , & first_bad , & bad_sectors ) == 0 ) { atomic_inc ( & rdev -> nr_pending ) ; rcu_read_unlock ( ) ; success = sync_page_io ( rdev , r10_bio -> devs [ sl ] . addr + sect , s << 9 , conf -> tmppage , REQ_OP_READ , false ) ; rdev_dec_pending ( rdev , mddev ) ; rcu_read_lock ( ) ; if ( success ) { break ; } } sl ++ ; if ( sl == conf -> copies ) { sl = 0 ; } } ! success && sl != r10_bio -> read_slot ; rcu_read_unlock ( ) ; if ( ! success ) { int dn = r10_bio -> devs [ r10_bio -> read_slot ] . devnum ; rdev = conf -> mirrors [ dn ] . rdev ; if ( ! rdev_set_badblocks ( rdev , r10_bio -> devs [ r10_bio -> read_slot ] . addr + sect , s , 0 ) ) { md_error ( mddev , rdev ) ; r10_bio -> devs [ r10_bio -> read_slot ] . bio = IO_BLOCKED ; } break ; } start = sl ; rcu_read_lock ( ) ; while ( sl != r10_bio -> read_slot ) { if ( sl == 0 ) { sl = conf -> copies ; } sl -- ; d = r10_bio -> devs [ sl ] . devnum ; rdev = rcu_dereference ( conf -> mirrors [ d ] . rdev ) ; if ( ! rdev || test_bit ( Faulty , & rdev -> flags ) || ! test_bit ( In_sync , & rdev -> flags ) ) { continue ; } atomic_inc ( & rdev -> nr_pending ) ; rcu_read_unlock ( ) ; if ( r10_sync_page_io ( rdev , r10_bio -> devs [ sl ] . addr + sect , s , conf -> tmppage , REQ_OP_WRITE ) == 0 ) { pr_notice ( "md/raid10:%s: read correction write failed (%d sectors at %llu on %pg)\n" , mdname ( mddev ) , s , ( unsigned long long ) ( sect + choose_data_offset ( r10_bio , rdev ) ) , rdev -> bdev ) ; pr_notice ( "md/raid10:%s: %pg: failing drive\n" , mdname ( mddev ) , rdev -> bdev ) ; } rdev_dec_pending ( rdev , mddev ) ; rcu_read_lock ( ) ; } sl = start ; while ( sl != r10_bio -> read_slot ) { if ( sl == 0 ) { sl = conf -> copies ; } sl -- ; d = r10_bio -> devs [ sl ] . devnum ; rdev = rcu_dereference ( conf -> mirrors [ d ] . rdev ) ; if ( ! rdev || test_bit ( Faulty , & rdev -> flags ) || ! test_bit ( In_sync , & rdev -> flags ) ) { continue ; } atomic_inc ( & rdev -> nr_pending ) ; rcu_read_unlock ( ) ; switch ( r10_sync_page_io ( rdev , r10_bio -> devs [ sl ] . addr + sect , s , conf -> tmppage , REQ_OP_READ ) ) { case 0 : pr_notice ( "md/raid10:%s: unable to read back corrected sectors (%d sectors at %llu on %pg)\n" , mdname ( mddev ) , s , ( unsigned long long ) ( sect + choose_data_offset ( r10_bio , rdev ) ) , rdev -> bdev ) ; pr_notice ( "md/raid10:%s: %pg: failing drive\n" , mdname ( mddev ) , rdev -> bdev ) ; break ; case 1 : pr_info ( "md/raid10:%s: read error corrected (%d sectors at %llu on %pg)\n" , mdname ( mddev ) , s , ( unsigned long long ) ( sect + choose_data_offset ( r10_bio , rdev ) ) , rdev -> bdev ) ; atomic_add ( s , & rdev -> corrected_errors ) ; } rdev_dec_pending ( rdev , mddev ) ; rcu_read_lock ( ) ; } rcu_read_unlock ( ) ; sectors -= s ; sect += s ; } } 