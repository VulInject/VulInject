static inline int __mod_timer ( struct timer_list * timer , unsigned long expires , unsigned int options ) { unsigned long clk = 0 , flags , bucket_expiry ; struct timer_base * base , * new_base ; unsigned int idx = UINT_MAX ; int ret = 0 ; debug_assert_init ( timer ) ; if ( ! ( options & MOD_TIMER_NOTPENDING ) && timer_pending ( timer ) ) { long diff = timer -> expires - expires ; if ( options & MOD_TIMER_REDUCE && diff <= 0 ) { return 1 ; } base = lock_timer_base ( timer , & flags ) ; if ( ! timer -> function ) { out_unlock } forward_timer_base ( base ) ; if ( timer_pending ( timer ) && ( options & MOD_TIMER_REDUCE ) && time_before_eq ( timer -> expires , expires ) ) { ret = 1 ; out_unlock } clk = base -> clk ; idx = calc_wheel_index ( expires , clk , & bucket_expiry ) ; if ( idx == timer_get_idx ( timer ) ) { if ( ! ( options & MOD_TIMER_REDUCE ) ) { timer -> expires = expires ; } if ( time_after ( timer -> expires , expires ) ) { timer -> expires = expires ; } ret = 1 ; out_unlock } } else { base = lock_timer_base ( timer , & flags ) ; if ( ! timer -> function ) { out_unlock } forward_timer_base ( base ) ; } ret = detach_if_pending ( timer , base , false ) ; if ( ! ret && ( options & MOD_TIMER_PENDING_ONLY ) ) { out_unlock } new_base = get_target_base ( base , timer -> flags ) ; if ( base != new_base ) { if ( likely ( base -> running_timer != timer ) ) { timer -> flags |= TIMER_MIGRATING ; raw_spin_unlock ( & base -> lock ) ; base = new_base ; raw_spin_lock ( & base -> lock ) ; WRITE_ONCE ( timer -> flags , ( timer -> flags & ~ TIMER_BASEMASK ) | base -> cpu ) ; forward_timer_base ( base ) ; } } debug_timer_activate ( timer ) ; timer -> expires = expires ; if ( idx != UINT_MAX && clk == base -> clk ) { enqueue_timer ( base , timer , idx , bucket_expiry ) ; } else { internal_add_timer ( base , timer ) ; } out_unlock raw_spin_unlock_irqrestore ( & base -> lock , flags ) ; return ret ; } 