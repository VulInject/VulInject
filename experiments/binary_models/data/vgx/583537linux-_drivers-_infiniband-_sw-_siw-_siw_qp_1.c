void siw_send_terminate ( struct siw_qp * qp ) { struct kvec iov [ 3 ] ; struct msghdr msg = { . msg_flags = MSG_DONTWAIT | MSG_EOR } ; struct iwarp_terminate * term = NULL ; union iwarp_hdr * err_hdr = NULL ; struct socket * s = qp -> attrs . sk ; struct siw_rx_stream * srx = & qp -> rx_stream ; union iwarp_hdr * rx_hdr = & srx -> hdr ; u32 crc = 0 ; int num_frags , len_terminate , rv ; if ( ! qp -> term_info . valid ) { return ; } qp -> term_info . valid = 0 ; if ( tx_wqe ( qp ) -> wr_status == SIW_WR_INPROGRESS ) { siw_dbg_qp ( qp , "cannot send TERMINATE: op %d in progress\n" , tx_type ( tx_wqe ( qp ) ) ) ; return ; } if ( ! s && qp -> cep ) { s = qp -> cep -> sock ; } if ( ! s ) { siw_dbg_qp ( qp , "cannot send TERMINATE: not connected\n" ) ; return ; } term = kzalloc ( sizeof ( * term ) , GFP_KERNEL ) ; if ( ! term ) { return ; } term -> ddp_qn = cpu_to_be32 ( RDMAP_UNTAGGED_QN_TERMINATE ) ; term -> ddp_mo = 0 ; term -> ddp_msn = cpu_to_be32 ( 1 ) ; iov [ 0 ] . iov_base = term ; iov [ 0 ] . iov_len = sizeof ( * term ) ; if ( ( qp -> term_info . layer == TERM_ERROR_LAYER_DDP ) || ( ( qp -> term_info . layer == TERM_ERROR_LAYER_RDMAP ) && ( qp -> term_info . etype != RDMAP_ETYPE_CATASTROPHIC ) ) ) { err_hdr = kzalloc ( sizeof ( * err_hdr ) , GFP_KERNEL ) ; if ( ! err_hdr ) { return ; } } memcpy ( & term -> ctrl , & iwarp_pktinfo [ RDMAP_TERMINATE ] . ctrl , sizeof ( iwarp_ctrl ) ) ; __rdmap_term_set_layer ( term , qp -> term_info . layer ) ; __rdmap_term_set_etype ( term , qp -> term_info . etype ) ; __rdmap_term_set_ecode ( term , qp -> term_info . ecode ) ; switch ( qp -> term_info . layer ) { case TERM_ERROR_LAYER_RDMAP : if ( qp -> term_info . etype == RDMAP_ETYPE_CATASTROPHIC ) { break ; } if ( qp -> term_info . etype == RDMAP_ETYPE_REMOTE_PROTECTION ) { term -> flag_m = 1 ; term -> flag_d = 1 ; term -> flag_r = 1 ; if ( qp -> term_info . in_tx ) { struct iwarp_rdma_rreq * rreq ; struct siw_wqe * wqe = tx_wqe ( qp ) ; rreq = ( iwarp_rdma_rreq * ) err_hdr ; memcpy ( & rreq -> ctrl , & iwarp_pktinfo [ RDMAP_RDMA_READ_REQ ] . ctrl , sizeof ( iwarp_ctrl ) ) ; rreq -> rsvd = 0 ; rreq -> ddp_qn = htonl ( RDMAP_UNTAGGED_QN_RDMA_READ ) ; rreq -> ddp_msn = htonl ( wqe -> sqe . sge [ 0 ] . length ) ; rreq -> ddp_mo = htonl ( wqe -> processed ) ; rreq -> sink_stag = htonl ( wqe -> sqe . rkey ) ; rreq -> sink_to = cpu_to_be64 ( wqe -> sqe . raddr ) ; rreq -> read_size = htonl ( wqe -> sqe . sge [ 0 ] . length ) ; rreq -> source_stag = htonl ( wqe -> sqe . sge [ 0 ] . lkey ) ; rreq -> source_to = cpu_to_be64 ( wqe -> sqe . sge [ 0 ] . laddr ) ; iov [ 1 ] . iov_base = rreq ; iov [ 1 ] . iov_len = sizeof ( * rreq ) ; rx_hdr = ( iwarp_hdr * ) rreq ; } else { iov [ 1 ] . iov_base = rx_hdr ; if ( __rdmap_get_opcode ( & rx_hdr -> ctrl ) == RDMAP_RDMA_READ_REQ ) { iov [ 1 ] . iov_len = sizeof ( iwarp_rdma_rreq ) ; } else { iov [ 1 ] . iov_len = sizeof ( iwarp_send ) ; } } } else { if ( ( qp -> term_info . ecode == RDMAP_ECODE_VERSION ) || ( qp -> term_info . ecode == RDMAP_ECODE_OPCODE ) ) { break ; } iov [ 1 ] . iov_base = rx_hdr ; if ( rx_hdr -> ctrl . ddp_rdmap_ctrl & DDP_FLAG_TAGGED ) { iov [ 1 ] . iov_len = sizeof ( iwarp_rdma_write ) ; } else { iov [ 1 ] . iov_len = sizeof ( iwarp_send ) ; } term -> flag_m = 1 ; term -> flag_d = 1 ; } term -> ctrl . mpa_len = cpu_to_be16 ( iov [ 1 ] . iov_len ) ; break ; case TERM_ERROR_LAYER_DDP : if ( ( ( qp -> term_info . etype == DDP_ETYPE_TAGGED_BUF ) && ( qp -> term_info . ecode == DDP_ECODE_T_VERSION ) ) || ( ( qp -> term_info . etype == DDP_ETYPE_UNTAGGED_BUF ) && ( qp -> term_info . ecode == DDP_ECODE_UT_VERSION ) ) ) { break ; } iov [ 1 ] . iov_base = rx_hdr ; if ( rx_hdr -> ctrl . ddp_rdmap_ctrl & DDP_FLAG_TAGGED ) { iov [ 1 ] . iov_len = sizeof ( iwarp_ctrl_tagged ) ; } else { iov [ 1 ] . iov_len = sizeof ( iwarp_ctrl_untagged ) ; } term -> flag_m = 1 ; term -> flag_d = 1 ; break ; default : break ; } if ( term -> flag_m || term -> flag_d || term -> flag_r ) { iov [ 2 ] . iov_base = & crc ; iov [ 2 ] . iov_len = sizeof ( crc ) ; len_terminate = sizeof ( * term ) + iov [ 1 ] . iov_len + MPA_CRC_SIZE ; num_frags = 3 ; } else { iov [ 1 ] . iov_base = & crc ; iov [ 1 ] . iov_len = sizeof ( crc ) ; len_terminate = sizeof ( * term ) + MPA_CRC_SIZE ; num_frags = 2 ; } if ( term -> flag_m ) { u32 real_ddp_len = be16_to_cpu ( rx_hdr -> ctrl . mpa_len ) ; enum rdma_opcode op = __rdmap_get_opcode ( & rx_hdr -> ctrl ) ; real_ddp_len -= iwarp_pktinfo [ op ] . hdr_len - MPA_HDR_SIZE ; rx_hdr -> ctrl . mpa_len = cpu_to_be16 ( real_ddp_len ) ; } term -> ctrl . mpa_len = cpu_to_be16 ( len_terminate - ( MPA_HDR_SIZE + MPA_CRC_SIZE ) ) ; if ( qp -> tx_ctx . mpa_crc_hd ) { crypto_shash_init ( qp -> tx_ctx . mpa_crc_hd ) ; if ( crypto_shash_update ( qp -> tx_ctx . mpa_crc_hd , ( u8 * ) iov [ 0 ] . iov_base , iov [ 0 ] . iov_len ) ) { out } if ( num_frags == 3 ) { if ( crypto_shash_update ( qp -> tx_ctx . mpa_crc_hd , ( u8 * ) iov [ 1 ] . iov_base , iov [ 1 ] . iov_len ) ) { out } } crypto_shash_final ( qp -> tx_ctx . mpa_crc_hd , ( u8 * ) & crc ) ; } rv = kernel_sendmsg ( s , & msg , iov , num_frags , len_terminate ) ; siw_dbg_qp ( qp , "sent TERM: %s, layer %d, type %d, code %d (%d bytes)\n" , rv == len_terminate ?"success" : "failure" , __rdmap_term_layer ( term ) , __rdmap_term_etype ( term ) , __rdmap_term_ecode ( term ) , rv ) ; out kfree ( term ) ; kfree ( err_hdr ) ; } 