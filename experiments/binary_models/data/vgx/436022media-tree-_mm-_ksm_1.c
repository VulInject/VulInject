static int replace_page ( struct vm_area_struct * vma , struct page * page , struct page * kpage , pte_t orig_pte ) { struct mm_struct * mm = vma -> vm_mm ; pmd_t * pmd ; pte_t * ptep ; pte_t newpte ; spinlock_t * ptl ; unsigned long addr ; int err = - EFAULT ; unsigned long mmun_start ; unsigned long mmun_end ; addr = page_address_in_vma ( page , vma ) ; pmd = mm_find_pmd ( mm , addr ) ; if ( ! pmd ) { out } mmun_start = addr ; mmun_end = addr + PAGE_SIZE ; mmu_notifier_invalidate_range_start ( mm , mmun_start , mmun_end ) ; ptep = pte_offset_map_lock ( mm , pmd , addr , & ptl ) ; if ( ! pte_same ( * ptep , orig_pte ) ) { pte_unmap_unlock ( ptep , ptl ) ; out_mn } if ( ! is_zero_pfn ( page_to_pfn ( kpage ) ) ) { get_page ( kpage ) ; page_add_anon_rmap ( kpage , vma , addr , false ) ; newpte = mk_pte ( kpage , vma -> vm_page_prot ) ; } else { newpte = pte_mkspecial ( pfn_pte ( page_to_pfn ( kpage ) , vma -> vm_page_prot ) ) ; } flush_cache_page ( vma , addr , pte_pfn ( * ptep ) ) ; ptep_clear_flush_notify ( vma , addr , ptep ) ; set_pte_at_notify ( mm , addr , ptep , newpte ) ; page_remove_rmap ( page , false ) ; if ( ! page_mapped ( page ) ) { try_to_free_swap ( page ) ; } put_page ( page ) ; pte_unmap_unlock ( ptep , ptl ) ; err = 0 ; out_mn mmu_notifier_invalidate_range_end ( mm , mmun_start , mmun_end ) ; out return err ; } 