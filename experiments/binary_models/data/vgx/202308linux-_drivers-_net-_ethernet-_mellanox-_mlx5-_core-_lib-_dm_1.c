struct mlx5_dm * mlx5_dm_create ( struct mlx5_core_dev * dev ) { u64 header_modify_pattern_icm_blocks = 0 ; u64 header_modify_icm_blocks = 0 ; u64 steering_icm_blocks = 0 ; struct mlx5_dm * dm ; bool support_v2 ; if ( ! ( MLX5_CAP_GEN_64 ( dev , general_obj_types ) & MLX5_GENERAL_OBJ_TYPES_CAP_SW_ICM ) ) { return NULL ; } dm = kzalloc ( sizeof ( * dm ) , GFP_KERNEL ) ; if ( ! dm ) { return ERR_PTR ( - ENOMEM ) ; } spin_lock_init ( & dm -> lock ) ; if ( MLX5_CAP64_DEV_MEM ( dev , steering_sw_icm_start_address ) ) { steering_icm_blocks = BIT ( MLX5_CAP_DEV_MEM ( dev , log_steering_sw_icm_size ) - MLX5_LOG_SW_ICM_BLOCK_SIZE ( dev ) ) ; dm -> steering_sw_icm_alloc_blocks = bitmap_zalloc ( steering_icm_blocks , GFP_KERNEL ) ; if ( ! dm -> steering_sw_icm_alloc_blocks ) { err_steering } } if ( MLX5_CAP64_DEV_MEM ( dev , header_modify_sw_icm_start_address ) ) { header_modify_icm_blocks = BIT ( MLX5_CAP_DEV_MEM ( dev , log_header_modify_sw_icm_size ) - MLX5_LOG_SW_ICM_BLOCK_SIZE ( dev ) ) ; dm -> header_modify_sw_icm_alloc_blocks = bitmap_zalloc ( header_modify_icm_blocks , GFP_KERNEL ) ; if ( ! dm -> header_modify_sw_icm_alloc_blocks ) { err_modify_hdr } } support_v2 = MLX5_CAP_FLOWTABLE_NIC_RX ( dev , sw_owner_v2 ) && MLX5_CAP_FLOWTABLE_NIC_TX ( dev , sw_owner_v2 ) && MLX5_CAP64_DEV_MEM ( dev , header_modify_pattern_sw_icm_start_address ) ; if ( support_v2 ) { header_modify_pattern_icm_blocks = BIT ( MLX5_CAP_DEV_MEM ( dev , log_header_modify_pattern_sw_icm_size ) - MLX5_LOG_SW_ICM_BLOCK_SIZE ( dev ) ) ; dm -> header_modify_pattern_sw_icm_alloc_blocks = bitmap_zalloc ( header_modify_pattern_icm_blocks , GFP_KERNEL ) ; if ( ! dm -> header_modify_pattern_sw_icm_alloc_blocks ) { err_pattern } } return dm ; err_pattern bitmap_free ( dm -> header_modify_sw_icm_alloc_blocks ) ; err_modify_hdr bitmap_free ( dm -> steering_sw_icm_alloc_blocks ) ; err_steering return ERR_PTR ( - ENOMEM ) ; } 