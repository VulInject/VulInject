static void tx_dle_intr ( struct atm_dev * dev ) { IADEV * iadev ; struct dle * dle , * cur_dle ; struct sk_buff * skb ; struct atm_vcc * vcc ; struct ia_vcc * iavcc ; u_int dle_lp ; unsigned long flags ; iadev = INPH_IA_DEV ( dev ) ; spin_lock_irqsave ( & iadev -> tx_lock , flags ) ; dle = iadev -> tx_dle_q . read ; dle_lp = readl ( iadev -> dma + IPHASE5575_TX_LIST_ADDR ) & ( sizeof ( dle ) * DLE_ENTRIES - 1 ) ; cur_dle = ( dle * ) ( iadev -> tx_dle_q . start + ( dle_lp >> 4 ) ) ; while ( dle != cur_dle ) { skb = skb_dequeue ( & iadev -> tx_dma_q ) ; if ( ! skb ) { break ; } if ( ! ( ( dle - iadev -> tx_dle_q . start ) % ( 2 * sizeof ( dle ) ) ) ) { dma_unmap_single ( & iadev -> pci -> dev , dle -> sys_pkt_addr , skb -> len , DMA_TO_DEVICE ) ; } vcc = ATM_SKB ( skb ) -> vcc ; if ( ! vcc ) { printk ( "tx_dle_intr: vcc is null\n" ) ; spin_unlock_irqrestore ( & iadev -> tx_lock , flags ) ; return ; } iavcc = INPH_IA_VCC ( vcc ) ; if ( ! iavcc ) { printk ( "tx_dle_intr: iavcc is null\n" ) ; spin_unlock_irqrestore ( & iadev -> tx_lock , flags ) ; dev_kfree_skb_any ( skb ) ; return ; } if ( vcc -> qos . txtp . pcr >= iadev -> rate_limit ) { if ( ( vcc -> pop ) && ( skb -> len != 0 ) ) { vcc -> pop ( vcc , skb ) ; } else { dev_kfree_skb_any ( skb ) ; } } else { IA_SKB_STATE ( skb ) |= IA_DLED ; skb_queue_tail ( & iavcc -> txing_skb , skb ) ; } IF_EVENT ( "tx_dle_intr: enque skb = 0x%p \n" ) if ( ++ dle == iadev -> tx_dle_q . end ) { dle = iadev -> tx_dle_q . start ; } } iadev -> tx_dle_q . read = dle ; spin_unlock_irqrestore ( & iadev -> tx_lock , flags ) ; } 