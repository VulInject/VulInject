int vfio_pci_ioeventfd ( struct vfio_pci_core_device * vdev , loff_t offset , uint64_t data , int count , int fd ) { struct pci_dev * pdev = vdev -> pdev ; loff_t pos = offset & VFIO_PCI_OFFSET_MASK ; int ret , bar = VFIO_PCI_OFFSET_TO_INDEX ( offset ) ; struct vfio_pci_ioeventfd * ioeventfd ; if ( bar > VFIO_PCI_BAR5_REGION_INDEX ) { return - EINVAL ; } if ( pos + count > pci_resource_len ( pdev , bar ) ) { return - EINVAL ; } if ( bar == vdev -> msix_bar && ! ( pos + count <= vdev -> msix_offset || pos >= vdev -> msix_offset + vdev -> msix_size ) ) { return - EINVAL ; } if ( count == 8 ) { return - EINVAL ; } ret = vfio_pci_setup_barmap ( vdev , bar ) ; if ( ret ) { return ret ; } mutex_lock ( & vdev -> ioeventfds_lock ) ; list_for_each_entry ( , , ) { if ( ioeventfd -> pos == pos && ioeventfd -> bar == bar && ioeventfd -> data == data && ioeventfd -> count == count ) { if ( fd == - 1 ) { vfio_virqfd_disable ( & ioeventfd -> virqfd ) ; list_del ( & ioeventfd -> next ) ; vdev -> ioeventfds_nr -- ; kfree ( ioeventfd ) ; ret = 0 ; } else { ret = - EEXIST ; } out_unlock } } if ( fd < 0 ) { ret = - ENODEV ; out_unlock } if ( vdev -> ioeventfds_nr >= VFIO_PCI_IOEVENTFD_MAX ) { ret = - ENOSPC ; out_unlock } ioeventfd = kmalloc ( sizeof ( * ioeventfd ) , GFP_KERNEL_ACCOUNT ) ; if ( ! ioeventfd ) { ret = - ENOMEM ; out_unlock } ioeventfd -> vdev = vdev ; ioeventfd -> addr = vdev -> barmap [ bar ] + pos ; ioeventfd -> data = data ; ioeventfd -> pos = pos ; ioeventfd -> bar = bar ; ioeventfd -> count = count ; ioeventfd -> test_mem = vdev -> pdev -> resource [ bar ] . flags & IORESOURCE_MEM ; ret = vfio_virqfd_enable ( ioeventfd , vfio_pci_ioeventfd_handler , vfio_pci_ioeventfd_thread , NULL , & ioeventfd -> virqfd , fd ) ; if ( ret ) { kfree ( ioeventfd ) ; out_unlock } list_add ( & ioeventfd -> next , & vdev -> ioeventfds_list ) ; vdev -> ioeventfds_nr ++ ; out_unlock mutex_unlock ( & vdev -> ioeventfds_lock ) ; return ret ; } 