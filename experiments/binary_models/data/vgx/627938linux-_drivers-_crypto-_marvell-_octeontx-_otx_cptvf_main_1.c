static int alloc_command_queues ( struct otx_cptvf * cptvf , struct otx_cpt_cmd_qinfo * cqinfo , u32 qlen ) { struct otx_cpt_cmd_chunk * curr , * first , * last ; struct otx_cpt_cmd_queue * queue = NULL ; struct pci_dev * pdev = cptvf -> pdev ; size_t q_size , c_size , rem_q_size ; u32 qcsize_bytes ; int i ; cptvf -> qsize = min ( qlen , cqinfo -> qchunksize ) * OTX_CPT_NEXT_CHUNK_PTR_SIZE + 1 ; q_size = qlen * OTX_CPT_INST_SIZE ; qcsize_bytes = cqinfo -> qchunksize * OTX_CPT_INST_SIZE ; for ( i = 0 ; i < cptvf -> num_queues ; i ++ ) { rem_q_size = q_size ; first = NULL ; last = NULL ; queue = & cqinfo -> queue [ i ] ; INIT_LIST_HEAD ( & queue -> chead ) ; { curr = kmalloc ( sizeof ( * curr ) , GFP_KERNEL ) ; if ( ! curr ) { cmd_qfail } c_size = ( rem_q_size > qcsize_bytes ) ?qcsize_bytes : rem_q_size ; curr -> head = dma_alloc_coherent ( & pdev -> dev , c_size + OTX_CPT_NEXT_CHUNK_PTR_SIZE , & curr -> dma_addr , GFP_KERNEL ) ; if ( ! curr -> head ) { dev_err ( & pdev -> dev , "Command Q (%d) chunk (%d) allocation failed\n" , i , queue -> num_chunks ) ; free_curr } curr -> size = c_size ; if ( queue -> num_chunks == 0 ) { first = curr ; queue -> base = first ; } list_add_tail ( & curr -> nextchunk , & cqinfo -> queue [ i ] . chead ) ; queue -> num_chunks ++ ; rem_q_size -= c_size ; if ( last ) { * ( ( u64 * ) ( & last -> head [ last -> size ] ) ) = ( u64 ) curr -> dma_addr ; } last = curr ; } rem_q_size ; curr = first ; * ( ( u64 * ) ( & last -> head [ last -> size ] ) ) = ( u64 ) curr -> dma_addr ; queue -> qhead = curr ; } return 0 ; free_curr kfree ( curr ) ; cmd_qfail free_command_queues ( cptvf , cqinfo ) ; return - ENOMEM ; } 