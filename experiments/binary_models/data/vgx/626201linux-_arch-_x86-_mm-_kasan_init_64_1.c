void __init kasan_init ( void ) { unsigned long shadow_cea_begin , shadow_cea_per_cpu_begin , shadow_cea_end ; int i ; memcpy ( early_top_pgt , init_top_pgt , sizeof ( early_top_pgt ) ) ; if ( pgtable_l5_enabled ( ) ) { void * ptr ; ptr = ( void * ) pgd_page_vaddr ( * pgd_offset_k ( KASAN_SHADOW_END ) ) ; memcpy ( tmp_p4d_table , ( void * ) ptr , sizeof ( tmp_p4d_table ) ) ; set_pgd ( & early_top_pgt [ pgd_index ( KASAN_SHADOW_END ) ] , __pgd ( __pa ( tmp_p4d_table ) | _KERNPG_TABLE ) ) ; } load_cr3 ( early_top_pgt ) ; __flush_tlb_all ( ) ; clear_pgds ( KASAN_SHADOW_START & PGDIR_MASK , KASAN_SHADOW_END ) ; kasan_populate_early_shadow ( ( void * ) ( KASAN_SHADOW_START & PGDIR_MASK ) , kasan_mem_to_shadow ( ( void * ) PAGE_OFFSET ) ) ; for ( i = 0 ; i < E820_MAX_ENTRIES ; i ++ ) { if ( pfn_mapped [ i ] . end == 0 ) { break ; } map_range ( & pfn_mapped [ i ] ) ; } shadow_cea_begin = kasan_mem_to_shadow_align_down ( CPU_ENTRY_AREA_BASE ) ; shadow_cea_per_cpu_begin = kasan_mem_to_shadow_align_up ( CPU_ENTRY_AREA_PER_CPU ) ; shadow_cea_end = kasan_mem_to_shadow_align_up ( CPU_ENTRY_AREA_BASE + CPU_ENTRY_AREA_MAP_SIZE ) ; kasan_populate_early_shadow ( kasan_mem_to_shadow ( ( void * ) PAGE_OFFSET + MAXMEM ) , kasan_mem_to_shadow ( ( void * ) VMALLOC_START ) ) ; if ( IS_ENABLED ( CONFIG_KASAN_VMALLOC ) ) { kasan_shallow_populate_pgds ( kasan_mem_to_shadow ( ( void * ) VMALLOC_START ) , kasan_mem_to_shadow ( ( void * ) VMALLOC_END ) ) ; } else { kasan_populate_early_shadow ( kasan_mem_to_shadow ( ( void * ) VMALLOC_START ) , kasan_mem_to_shadow ( ( void * ) VMALLOC_END ) ) ; } kasan_populate_early_shadow ( kasan_mem_to_shadow ( ( void * ) VMALLOC_END + 1 ) , ( void * ) shadow_cea_begin ) ; kasan_populate_shadow ( shadow_cea_begin , shadow_cea_per_cpu_begin , 0 ) ; kasan_populate_early_shadow ( ( void * ) shadow_cea_end , kasan_mem_to_shadow ( ( void * ) __START_KERNEL_map ) ) ; kasan_populate_shadow ( ( unsigned long ) kasan_mem_to_shadow ( _stext ) , ( unsigned long ) kasan_mem_to_shadow ( _end ) , early_pfn_to_nid ( __pa ( _stext ) ) ) ; kasan_populate_early_shadow ( kasan_mem_to_shadow ( ( void * ) MODULES_END ) , ( void * ) KASAN_SHADOW_END ) ; load_cr3 ( init_top_pgt ) ; __flush_tlb_all ( ) ; for ( i = 0 ; i < PTRS_PER_PTE ; i ++ ) { pte_t pte ; pgprot_t prot ; prot = __pgprot ( __PAGE_KERNEL_RO | _PAGE_ENC ) ; pgprot_val ( prot ) &= __default_kernel_pte_mask ; pte = __pte ( __pa ( kasan_early_shadow_page ) | pgprot_val ( prot ) ) ; set_pte ( & kasan_early_shadow_pte [ i ] , pte ) ; } __flush_tlb_all ( ) ; init_task . kasan_depth = 0 ; pr_info ( "KernelAddressSanitizer initialized\n" ) ; } 