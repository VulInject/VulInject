static int nvkm_acr_oneinit ( struct nvkm_subdev * subdev ) { struct nvkm_device * device = subdev -> device ; struct nvkm_acr * acr = nvkm_acr ( subdev ) ; struct nvkm_acr_hsfw * hsfw ; struct nvkm_acr_lsfw * lsfw , * lsft ; struct nvkm_acr_lsf * lsf , * rtos ; struct nvkm_falcon * falcon ; u32 wpr_size = 0 ; u64 falcons ; int ret , i ; if ( list_empty ( & acr -> hsfw ) ) { nvkm_debug ( subdev , "No HSFW(s)\n" ) ; nvkm_acr_cleanup ( acr ) ; return 0 ; } list_for_each_entry_safe ( , , , ) { if ( acr -> wpr_fw ) { if ( ! lsfw -> func ) { nvkm_acr_lsfw_del ( lsfw , NULL ) ; continue ; } wpr_size = acr -> wpr_fw -> size ; } ret = nvkm_falcon_get ( lsfw -> falcon , subdev ) ; if ( ret ) { return ret ; } nvkm_falcon_put ( lsfw -> falcon , subdev ) ; if ( ! ( lsf = kmalloc ( sizeof ( * lsf ) , GFP_KERNEL ) ) ) { return - ENOMEM ; } lsf -> func = lsfw -> func ; lsf -> falcon = lsfw -> falcon ; lsf -> id = lsfw -> id ; list_add_tail ( & lsf -> head , & acr -> lsf ) ; acr -> managed_falcons |= BIT_ULL ( lsf -> id ) ; } rtos = nvkm_acr_rtos ( acr ) ; if ( rtos ) { falcons = rtos -> func -> bootstrap_falcons ; list_move ( & rtos -> head , & acr -> lsf ) ; } else { falcons = acr -> func -> bootstrap_falcons ; } list_for_each_entry_safe ( , , , ) { if ( ! ( falcons & BIT_ULL ( lsfw -> id ) ) ) { nvkm_warn ( subdev , "%s falcon cannot be bootstrapped\n" , nvkm_acr_lsf_id ( lsfw -> id ) ) ; nvkm_acr_lsfw_del ( lsfw ) ; } } if ( ! acr -> wpr_fw || acr -> wpr_comp ) { wpr_size = acr -> func -> wpr_layout ( acr ) ; } ret = acr -> func -> wpr_alloc ( acr , wpr_size ) ; if ( ret ) { return ret ; } nvkm_debug ( subdev , "WPR region is from 0x%llx-0x%llx (shadow 0x%llx)\n" , acr -> wpr_start , acr -> wpr_end , acr -> shadow_start ) ; nvkm_kmap ( acr -> wpr ) ; if ( acr -> wpr_fw && ! acr -> wpr_comp ) { nvkm_wobj ( acr -> wpr , 0 , acr -> wpr_fw -> data , acr -> wpr_fw -> size ) ; } if ( ! acr -> wpr_fw || acr -> wpr_comp ) { acr -> func -> wpr_build ( acr , rtos ) ; } acr -> func -> wpr_patch ( acr , ( s64 ) acr -> wpr_start - acr -> wpr_prev ) ; if ( acr -> wpr_fw && acr -> wpr_comp ) { nvkm_kmap ( acr -> wpr ) ; for ( i = 0 ; i < acr -> wpr_fw -> size ; i += 4 ) { u32 us = nvkm_ro32 ( acr -> wpr , i ) ; u32 fw = ( ( u32 * ) acr -> wpr_fw -> data ) [ i / 4 ] ; if ( fw != us ) { nvkm_warn ( subdev , "%08x: %08x %08x\n" , i , us , fw ) ; } } return - EINVAL ; } nvkm_done ( acr -> wpr ) ; ret = nvkm_memory_new ( device , NVKM_MEM_TARGET_INST , 0x1000 , 0 , true , & acr -> inst ) ; if ( ret ) { return ret ; } ret = nvkm_vmm_new ( device , 0 , 0 , NULL , 0 , NULL , "acr" , & acr -> vmm ) ; if ( ret ) { return ret ; } acr -> vmm -> debug = acr -> subdev . debug ; ret = nvkm_vmm_join ( acr -> vmm , acr -> inst ) ; if ( ret ) { return ret ; } list_for_each_entry ( , , ) { switch ( hsfw -> falcon_id ) { case NVKM_ACR_HSF_PMU : falcon = & device -> pmu -> falcon ; break ; case NVKM_ACR_HSF_SEC2 : falcon = & device -> sec2 -> falcon ; break ; case NVKM_ACR_HSF_GSP : falcon = & device -> gsp -> falcon ; break ; default : WARN_ON ( 1 ) ; return - EINVAL ; } ret = nvkm_falcon_fw_oneinit ( & hsfw -> fw , falcon , acr -> vmm , acr -> inst ) ; if ( ret ) { return ret ; } } nvkm_acr_cleanup ( acr ) ; return 0 ; } 