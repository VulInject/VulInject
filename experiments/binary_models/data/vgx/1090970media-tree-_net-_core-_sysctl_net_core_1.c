static int flow_limit_cpu_sysctl ( struct ctl_table * table , int write , void __user * buffer , size_t * lenp , loff_t * ppos ) { struct sd_flow_limit * cur ; struct softnet_data * sd ; cpumask_var_t mask ; int i , len , ret = 0 ; if ( ! alloc_cpumask_var ( & mask , GFP_KERNEL ) ) { return - ENOMEM ; } if ( write ) { ret = cpumask_parse_user ( buffer , * lenp , mask ) ; if ( ret ) { done } mutex_lock ( & flow_limit_update_mutex ) ; len = sizeof ( * cur ) + netdev_flow_limit_table_len ; for_each_possible_cpu ( ) { sd = & per_cpu ( softnet_data , i ) ; cur = rcu_dereference_protected ( sd -> flow_limit , lockdep_is_held ( & flow_limit_update_mutex ) ) ; if ( cur && ! cpumask_test_cpu ( i , mask ) ) { RCU_INIT_POINTER ( sd -> flow_limit , NULL ) ; synchronize_rcu ( ) ; } if ( ! cur && cpumask_test_cpu ( i , mask ) ) { cur = kzalloc_node ( len , GFP_KERNEL , cpu_to_node ( i ) ) ; if ( ! cur ) { ret = - ENOMEM ; write_unlock } cur -> num_buckets = netdev_flow_limit_table_len ; rcu_assign_pointer ( sd -> flow_limit , cur ) ; } } write_unlock mutex_unlock ( & flow_limit_update_mutex ) ; } else { char kbuf [ 128 ] ; if ( * ppos || ! * lenp ) { * lenp = 0 ; done } cpumask_clear ( mask ) ; rcu_read_lock ( ) ; for_each_possible_cpu ( ) { sd = & per_cpu ( softnet_data , i ) ; if ( rcu_dereference ( sd -> flow_limit ) ) { cpumask_set_cpu ( i , mask ) ; } } rcu_read_unlock ( ) ; len = min ( sizeof ( kbuf ) - 1 , * lenp ) ; len = scnprintf ( kbuf , len , "%*pb" , cpumask_pr_args ( mask ) ) ; if ( ! len ) { * lenp = 0 ; done } if ( len < * lenp ) { kbuf [ len ++ ] = '\n' ; } if ( copy_to_user ( buffer , kbuf , len ) ) { ret = - EFAULT ; done } * lenp = len ; * ppos += len ; } done free_cpumask_var ( mask ) ; return ret ; } 