static void nvmet_fc_handle_fcp_rqst ( struct nvmet_fc_tgtport * tgtport , struct nvmet_fc_fcp_iod * fod ) { struct nvme_fc_cmd_iu * cmdiu = & fod -> cmdiubuf ; int ret ; fod -> fcpreq -> done = nvmet_fc_xmt_fcp_op_done ; fod -> total_length = be32_to_cpu ( cmdiu -> data_len ) ; if ( cmdiu -> flags & FCNVME_CMD_FLAGS_WRITE ) { fod -> io_dir = NVMET_FCP_WRITE ; if ( ! nvme_is_write ( & cmdiu -> sqe ) ) { transport_error } } if ( cmdiu -> flags & FCNVME_CMD_FLAGS_READ ) { fod -> io_dir = NVMET_FCP_READ ; if ( nvme_is_write ( & cmdiu -> sqe ) ) { transport_error } } else { fod -> io_dir = NVMET_FCP_NODATA ; if ( fod -> total_length ) { transport_error } } fod -> req . cmd = & fod -> cmdiubuf . sqe ; fod -> req . rsp = & fod -> rspiubuf . cqe ; fod -> req . port = fod -> queue -> port ; fod -> req . execute = NULL ; ret = nvmet_req_init ( & fod -> req , & fod -> queue -> nvme_cq , & fod -> queue -> nvme_sq , & nvmet_fc_tgt_fcp_ops ) ; if ( ! ret ) { nvmet_fc_abort_op ( tgtport , fod ) ; return ; } atomic_inc ( & fod -> queue -> sqtail ) ; fod -> data_sg = NULL ; fod -> data_sg_cnt = 0 ; if ( fod -> total_length ) { ret = nvmet_fc_alloc_tgt_pgs ( fod ) ; if ( ret ) { nvmet_req_complete ( & fod -> req , ret ) ; return ; } } fod -> req . sg = fod -> data_sg ; fod -> req . sg_cnt = fod -> data_sg_cnt ; fod -> offset = 0 ; fod -> next_sg = fod -> data_sg ; fod -> next_sg_offset = 0 ; if ( fod -> io_dir == NVMET_FCP_WRITE ) { nvmet_fc_transfer_fcp_data ( tgtport , fod , NVMET_FCOP_WRITEDATA ) ; return ; } fod -> req . execute ( & fod -> req ) ; return ; transport_error nvmet_fc_abort_op ( tgtport , fod ) ; } 