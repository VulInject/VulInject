static int gve_clean_tx_done ( struct gve_priv * priv , struct gve_tx_ring * tx , u32 to_do , bool try_to_wake ) { struct gve_tx_buffer_state * info ; u64 pkts = 0 , bytes = 0 ; int space_freed = 0 ; struct sk_buff * skb ; int i , j ; u32 idx ; for ( j = 0 ; j < to_do ; j ++ ) { idx = tx -> done & tx -> mask ; netif_info ( priv , tx_done , priv -> dev , "[%d] %s: idx=%d (req=%u done=%u)\n" , tx -> q_num , __func__ , idx , tx -> req , tx -> done ) ; info = & tx -> info [ idx ] ; skb = info -> skb ; if ( tx -> raw_addressing ) { gve_tx_unmap_buf ( tx -> dev , info ) ; } tx -> done ++ ; if ( skb ) { info -> skb = NULL ; bytes += skb -> len ; pkts ++ ; dev_consume_skb_any ( skb ) ; if ( tx -> raw_addressing ) { continue ; } for ( i = 0 ; i < ARRAY_SIZE ( info -> iov ) ; i ++ ) { space_freed += info -> iov [ i ] . iov_len + info -> iov [ i ] . iov_padding ; info -> iov [ i ] . iov_len = 0 ; info -> iov [ i ] . iov_padding = 0 ; } } } if ( ! tx -> raw_addressing ) { gve_tx_free_fifo ( & tx -> tx_fifo , space_freed ) ; } u64_stats_update_begin ( & tx -> statss ) ; tx -> bytes_done += bytes ; tx -> pkt_done += pkts ; u64_stats_update_end ( & tx -> statss ) ; netdev_tx_completed_queue ( tx -> netdev_txq , pkts , bytes ) ; smp_mb ( ) ; if ( try_to_wake && netif_tx_queue_stopped ( tx -> netdev_txq ) && likely ( gve_can_tx ( tx , GVE_TX_START_THRESH ) ) ) { tx -> wake_queue ++ ; netif_tx_wake_queue ( tx -> netdev_txq ) ; } return pkts ; } 