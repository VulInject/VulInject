int gro_cells_receive ( struct gro_cells * gcells , struct sk_buff * skb ) { struct net_device * dev = skb -> dev ; struct gro_cell * cell ; int res ; rcu_read_lock ( ) ; if ( unlikely ( ! ( dev -> flags & IFF_UP ) ) ) { drop } if ( ! gcells -> cells || skb_cloned ( skb ) || netif_elide_gro ( dev ) ) { res = netif_rx ( skb ) ; unlock } cell = this_cpu_ptr ( gcells -> cells ) ; if ( skb_queue_len ( & cell -> napi_skbs ) > READ_ONCE ( netdev_max_backlog ) ) { drop dev_core_stats_rx_dropped_inc ( dev ) ; res = NET_RX_DROP ; unlock } __skb_queue_tail ( & cell -> napi_skbs , skb ) ; if ( skb_queue_len ( & cell -> napi_skbs ) == 1 ) { napi_schedule ( & cell -> napi ) ; } res = NET_RX_SUCCESS ; unlock rcu_read_unlock ( ) ; return res ; } 