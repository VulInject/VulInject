static int vcn_v4_0_sw_init ( void * handle ) { struct amdgpu_ring * ring ; struct amdgpu_device * adev = ( amdgpu_device * ) handle ; int i , r ; r = amdgpu_vcn_sw_init ( adev ) ; if ( r ) { return r ; } amdgpu_vcn_setup_ucode ( adev , NULL ) ; r = amdgpu_vcn_resume ( adev ) ; if ( r ) { return r ; } for ( i = 0 ; i < adev -> vcn . num_vcn_inst ; i ++ ) { volatile struct amdgpu_vcn4_fw_shared * fw_shared ; if ( adev -> vcn . harvest_config & ( 1 << i ) ) { continue ; } atomic_set ( & adev -> vcn . inst [ i ] . sched_score , 0 ) ; r = amdgpu_irq_add_id ( adev , amdgpu_ih_clientid_vcns [ i ] , VCN_4_0__SRCID__UVD_ENC_GENERAL_PURPOSE , & adev -> vcn . inst [ i ] . irq ) ; if ( r ) { return r ; } r = amdgpu_irq_add_id ( adev , amdgpu_ih_clientid_vcns [ i ] , VCN_4_0__SRCID_UVD_POISON , & adev -> vcn . inst [ i ] . irq ) ; if ( r ) { return r ; } ring = & adev -> vcn . inst [ i ] . ring_enc [ 0 ] ; ring -> use_doorbell = true ; if ( amdgpu_sriov_vf ( adev ) ) { ring -> doorbell_index = ( adev -> doorbell_index . vcn . vcn_ring0_1 << 1 ) + i * ( adev -> vcn . num_enc_rings + 1 ) + 1 ; } else { ring -> doorbell_index = ( adev -> doorbell_index . vcn . vcn_ring0_1 << 1 ) + 2 + 8 * i ; } sprintf ( ring -> name , "vcn_unified_%d" , i ) ; r = amdgpu_ring_init ( adev , ring , 512 , & adev -> vcn . inst [ i ] . irq , 0 , AMDGPU_RING_PRIO_0 , & adev -> vcn . inst [ i ] . sched_score ) ; if ( r ) { return r ; } fw_shared = adev -> vcn . inst [ i ] . fw_shared . cpu_addr ; fw_shared -> present_flag_0 = cpu_to_le32 ( AMDGPU_FW_SHARED_FLAG_0_UNIFIED_QUEUE ) ; fw_shared -> sq . is_enabled = 1 ; fw_shared -> present_flag_0 |= cpu_to_le32 ( AMDGPU_VCN_SMU_DPM_INTERFACE_FLAG ) ; fw_shared -> smu_dpm_interface . smu_interface_type = ( adev -> flags & AMD_IS_APU ) ?AMDGPU_VCN_SMU_DPM_INTERFACE_APU : AMDGPU_VCN_SMU_DPM_INTERFACE_DGPU ; if ( amdgpu_sriov_vf ( adev ) ) { fw_shared -> present_flag_0 |= cpu_to_le32 ( AMDGPU_VCN_VF_RB_SETUP_FLAG ) ; } if ( amdgpu_vcnfw_log ) { amdgpu_vcn_fwlog_init ( & adev -> vcn . inst [ i ] ) ; } } if ( amdgpu_sriov_vf ( adev ) ) { r = amdgpu_virt_alloc_mm_table ( adev ) ; if ( r ) { return r ; } } if ( adev -> pg_flags & AMD_PG_SUPPORT_VCN_DPG ) { adev -> vcn . pause_dpg_mode = vcn_v4_0_pause_dpg_mode ; } return 0 ; } 