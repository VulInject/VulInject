static void scftorture_invoke_one ( struct scf_statistics * scfp , struct torture_random_state * trsp ) { uintptr_t cpu ; int ret = 0 ; struct scf_check * scfcp = NULL ; struct scf_selector * scfsp = scf_sel_rand ( trsp ) ; if ( use_cpus_read_lock ) { cpus_read_lock ( ) ; } else { preempt_disable ( ) ; } if ( scfsp -> scfs_prim == SCF_PRIM_SINGLE || scfsp -> scfs_wait ) { scfcp = kmalloc ( sizeof ( * scfcp ) , GFP_ATOMIC ) ; if ( WARN_ON_ONCE ( ! scfcp ) ) { atomic_inc ( & n_alloc_errs ) ; } else { scfcp -> scfc_cpu = - 1 ; scfcp -> scfc_wait = scfsp -> scfs_wait ; scfcp -> scfc_out = false ; scfcp -> scfc_rpc = false ; } } switch ( scfsp -> scfs_prim ) { case SCF_PRIM_RESCHED : if ( IS_BUILTIN ( CONFIG_SCF_TORTURE_TEST ) ) { cpu = torture_random ( trsp ) % nr_cpu_ids ; scfp -> n_resched ++ ; resched_cpu ( cpu ) ; this_cpu_inc ( scf_invoked_count ) ; } break ; case SCF_PRIM_SINGLE : cpu = torture_random ( trsp ) % nr_cpu_ids ; if ( scfsp -> scfs_wait ) { scfp -> n_single_wait ++ ; } else { scfp -> n_single ++ ; } if ( scfcp ) { scfcp -> scfc_cpu = cpu ; barrier ( ) ; scfcp -> scfc_in = true ; } ret = smp_call_function_single ( cpu , scf_handler_1 , ( void * ) scfcp , scfsp -> scfs_wait ) ; if ( ret ) { if ( scfsp -> scfs_wait ) { scfp -> n_single_wait_ofl ++ ; } else { scfp -> n_single_ofl ++ ; } scfcp = NULL ; } break ; case SCF_PRIM_SINGLE_RPC : if ( ! scfcp ) { break ; } cpu = torture_random ( trsp ) % nr_cpu_ids ; scfp -> n_single_rpc ++ ; scfcp -> scfc_cpu = cpu ; scfcp -> scfc_wait = true ; init_completion ( & scfcp -> scfc_completion ) ; scfcp -> scfc_rpc = true ; barrier ( ) ; scfcp -> scfc_in = true ; ret = smp_call_function_single ( cpu , scf_handler_1 , ( void * ) scfcp , 0 ) ; if ( ! ret ) { if ( use_cpus_read_lock ) { cpus_read_unlock ( ) ; } else { preempt_enable ( ) ; } wait_for_completion ( & scfcp -> scfc_completion ) ; if ( use_cpus_read_lock ) { cpus_read_lock ( ) ; } else { preempt_disable ( ) ; } } else { scfp -> n_single_rpc_ofl ++ ; kfree ( scfcp ) ; scfcp = NULL ; } break ; case SCF_PRIM_MANY : if ( scfsp -> scfs_wait ) { scfp -> n_many_wait ++ ; } else { scfp -> n_many ++ ; } if ( scfcp ) { barrier ( ) ; scfcp -> scfc_in = true ; } smp_call_function_many ( cpu_online_mask , scf_handler , scfcp , scfsp -> scfs_wait ) ; break ; case SCF_PRIM_ALL : if ( scfsp -> scfs_wait ) { scfp -> n_all_wait ++ ; } else { scfp -> n_all ++ ; } if ( scfcp ) { barrier ( ) ; scfcp -> scfc_in = true ; } smp_call_function ( scf_handler , scfcp , scfsp -> scfs_wait ) ; break ; default : WARN_ON_ONCE ( 1 ) ; if ( scfcp ) { scfcp -> scfc_out = true ; } } if ( scfcp && scfsp -> scfs_wait ) { if ( WARN_ON_ONCE ( ( num_online_cpus ( ) > 1 || scfsp -> scfs_prim == SCF_PRIM_SINGLE ) && ! scfcp -> scfc_out ) ) { pr_warn ( "%s: Memory-ordering failure, scfs_prim: %d.\n" , __func__ , scfsp -> scfs_prim ) ; atomic_inc ( & n_mb_out_errs ) ; } else { kfree ( scfcp ) ; } barrier ( ) ; } if ( use_cpus_read_lock ) { cpus_read_unlock ( ) ; } else { preempt_enable ( ) ; } if ( ! ( torture_random ( trsp ) & 0xfff ) ) { schedule_timeout_uninterruptible ( 1 ) ; } } 