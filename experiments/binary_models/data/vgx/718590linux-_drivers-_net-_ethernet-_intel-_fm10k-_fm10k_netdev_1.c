static netdev_tx_t fm10k_xmit_frame ( struct sk_buff * skb , struct net_device * dev ) { struct fm10k_intfc * interface = netdev_priv ( dev ) ; int num_tx_queues = READ_ONCE ( interface -> num_tx_queues ) ; unsigned int r_idx = skb -> queue_mapping ; int err ; if ( ! num_tx_queues ) { return NETDEV_TX_BUSY ; } if ( ( skb -> protocol == htons ( ETH_P_8021Q ) ) && ! skb_vlan_tag_present ( skb ) ) { struct vlan_hdr * vhdr ; __be16 proto ; skb = skb_share_check ( skb , GFP_ATOMIC ) ; if ( ! skb ) { return NETDEV_TX_OK ; } if ( unlikely ( ! pskb_may_pull ( skb , VLAN_ETH_HLEN ) ) ) { return NETDEV_TX_OK ; } err = skb_cow_head ( skb , 0 ) ; if ( err ) { return NETDEV_TX_OK ; } vhdr = ( vlan_hdr * ) ( skb -> data + ETH_HLEN ) ; __vlan_hwaccel_put_tag ( skb , htons ( ETH_P_8021Q ) , ntohs ( vhdr -> h_vlan_TCI ) ) ; proto = vhdr -> h_vlan_encapsulated_proto ; skb -> protocol = ( ntohs ( proto ) >= 1536 ) ?proto : htons ( ETH_P_802_2 ) ; memmove ( skb -> data + VLAN_HLEN , skb -> data , 12 ) ; __skb_pull ( skb , VLAN_HLEN ) ; skb_reset_mac_header ( skb ) ; } if ( unlikely ( skb -> len < 17 ) ) { int pad_len = 17 - skb -> len ; if ( skb_pad ( skb , pad_len ) ) { return NETDEV_TX_OK ; } __skb_put ( skb , pad_len ) ; } if ( r_idx >= num_tx_queues ) { r_idx %= num_tx_queues ; } err = fm10k_xmit_frame_ring ( skb , interface -> tx_ring [ r_idx ] ) ; return err ; } 