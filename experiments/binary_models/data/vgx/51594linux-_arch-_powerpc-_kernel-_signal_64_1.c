static long restore_tm_sigcontexts ( struct task_struct * tsk , struct sigcontext __user * sc , struct sigcontext __user * tm_sc ) { elf_vrreg_t __user * v_regs , * tm_v_regs ; unsigned long err = 0 ; unsigned long msr ; struct pt_regs * regs = tsk -> thread . regs ; int i ; BUG_ON ( tsk != current ) ; if ( tm_suspend_disabled ) { return - EINVAL ; } err |= __copy_from_user ( regs -> gpr , tm_sc -> gp_regs , sizeof ( regs -> gpr ) ) ; err |= __copy_from_user ( & tsk -> thread . ckpt_regs , sc -> gp_regs , sizeof ( regs -> gpr ) ) ; err |= __get_user ( regs -> nip , & tm_sc -> gp_regs [ PT_NIP ] ) ; err |= __get_user ( tsk -> thread . tm_tfhar , & sc -> gp_regs [ PT_NIP ] ) ; err |= __get_user ( msr , & sc -> gp_regs [ PT_MSR ] ) ; regs_set_return_msr ( regs , ( regs -> msr & ~ MSR_LE ) | ( msr & MSR_LE ) ) ; err |= __get_user ( regs -> ctr , & tm_sc -> gp_regs [ PT_CTR ] ) ; err |= __get_user ( regs -> link , & tm_sc -> gp_regs [ PT_LNK ] ) ; err |= __get_user ( regs -> xer , & tm_sc -> gp_regs [ PT_XER ] ) ; err |= __get_user ( regs -> ccr , & tm_sc -> gp_regs [ PT_CCR ] ) ; err |= __get_user ( tsk -> thread . ckpt_regs . ctr , & sc -> gp_regs [ PT_CTR ] ) ; err |= __get_user ( tsk -> thread . ckpt_regs . link , & sc -> gp_regs [ PT_LNK ] ) ; err |= __get_user ( tsk -> thread . ckpt_regs . xer , & sc -> gp_regs [ PT_XER ] ) ; err |= __get_user ( tsk -> thread . ckpt_regs . ccr , & sc -> gp_regs [ PT_CCR ] ) ; set_trap_norestart ( regs ) ; err |= __get_user ( regs -> dar , & sc -> gp_regs [ PT_DAR ] ) ; err |= __get_user ( regs -> dsisr , & sc -> gp_regs [ PT_DSISR ] ) ; err |= __get_user ( regs -> result , & sc -> gp_regs [ PT_RESULT ] ) ; regs_set_return_msr ( regs , regs -> msr & ~ ( MSR_FP | MSR_FE0 | MSR_FE1 | MSR_VEC | MSR_VSX ) ) ; err |= __get_user ( v_regs , & sc -> v_regs ) ; err |= __get_user ( tm_v_regs , & tm_sc -> v_regs ) ; if ( err ) { return err ; } if ( v_regs && ! access_ok ( v_regs , 34 * sizeof ( vector128 ) ) ) { return - EFAULT ; } if ( tm_v_regs && ! access_ok ( tm_v_regs , 34 * sizeof ( vector128 ) ) ) { return - EFAULT ; } if ( v_regs != NULL && tm_v_regs != NULL && ( msr & MSR_VEC ) != 0 ) { err |= __copy_from_user ( & tsk -> thread . ckvr_state , v_regs , 33 * sizeof ( vector128 ) ) ; err |= __copy_from_user ( & tsk -> thread . vr_state , tm_v_regs , 33 * sizeof ( vector128 ) ) ; current -> thread . used_vr = true ; } if ( tsk -> thread . used_vr ) { memset ( & tsk -> thread . vr_state , 0 , 33 * sizeof ( vector128 ) ) ; memset ( & tsk -> thread . ckvr_state , 0 , 33 * sizeof ( vector128 ) ) ; } if ( v_regs != NULL && tm_v_regs != NULL ) { err |= __get_user ( tsk -> thread . ckvrsave , ( u32 __user * ) & v_regs [ 33 ] ) ; err |= __get_user ( tsk -> thread . vrsave , ( u32 __user * ) & tm_v_regs [ 33 ] ) ; } else { tsk -> thread . vrsave = 0 ; tsk -> thread . ckvrsave = 0 ; } if ( cpu_has_feature ( CPU_FTR_ALTIVEC ) ) { mtspr ( SPRN_VRSAVE , tsk -> thread . vrsave ) ; } err |= copy_fpr_from_user ( tsk , & tm_sc -> fp_regs ) ; err |= copy_ckfpr_from_user ( tsk , & sc -> fp_regs ) ; if ( v_regs && ( ( msr & MSR_VSX ) != 0 ) ) { v_regs += ELF_NVRREG ; tm_v_regs += ELF_NVRREG ; err |= copy_vsx_from_user ( tsk , tm_v_regs ) ; err |= copy_ckvsx_from_user ( tsk , v_regs ) ; tsk -> thread . used_vsr = true ; } else { for ( i = 0 ; i < 32 ; i ++ ) { tsk -> thread . fp_state . fpr [ i ] [ TS_VSRLOWOFFSET ] = 0 ; tsk -> thread . ckfp_state . fpr [ i ] [ TS_VSRLOWOFFSET ] = 0 ; } } tm_enable ( ) ; tsk -> thread . tm_texasr |= TEXASR_FS ; preempt_disable ( ) ; regs_set_return_msr ( regs , regs -> msr | ( msr & MSR_TS_MASK ) ) ; regs_set_return_msr ( regs , regs -> msr | MSR_TM ) ; tm_recheckpoint ( & tsk -> thread ) ; msr_check_and_set ( msr & ( MSR_FP | MSR_VEC ) ) ; if ( msr & MSR_FP ) { load_fp_state ( & tsk -> thread . fp_state ) ; regs_set_return_msr ( regs , regs -> msr | ( MSR_FP | tsk -> thread . fpexc_mode ) ) ; } if ( msr & MSR_VEC ) { load_vr_state ( & tsk -> thread . vr_state ) ; regs_set_return_msr ( regs , regs -> msr | MSR_VEC ) ; } preempt_enable ( ) ; return err ; } 