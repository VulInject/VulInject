s32 bcm_to_h_msg_dequeue ( struct bcm_vk * vk ) { struct device * dev = & vk -> pdev -> dev ; struct bcm_vk_msg_chan * chan = & vk -> to_h_msg_chan ; struct vk_msg_blk * data ; struct vk_msg_blk __iomem * src ; struct vk_msg_blk * dst ; struct bcm_vk_msgq __iomem * msgq ; struct bcm_vk_sync_qinfo * qinfo ; struct bcm_vk_wkent * entry ; u32 rd_idx , wr_idx ; u32 q_num , msg_id , j ; u32 num_blks ; s32 total = 0 ; int cnt = 0 ; int msg_processed = 0 ; int max_msg_to_process ; bool exit_loop ; mutex_lock ( & chan -> msgq_mutex ) ; for ( q_num = 0 ; q_num < chan -> q_nr ; q_num ++ ) { msgq = chan -> msgq [ q_num ] ; qinfo = & chan -> sync_qinfo [ q_num ] ; max_msg_to_process = BCM_VK_MSG_PROC_MAX_LOOP * qinfo -> q_size ; rd_idx = readl_relaxed ( & msgq -> rd_idx ) ; wr_idx = readl_relaxed ( & msgq -> wr_idx ) ; msg_processed = 0 ; exit_loop = false ; while ( ( rd_idx != wr_idx ) && ! exit_loop ) { u8 src_size ; src = msgq_blk_addr ( qinfo , rd_idx & qinfo -> q_mask ) ; src_size = readb ( & src -> size ) ; if ( ( rd_idx >= qinfo -> q_size ) || ( src_size > ( qinfo -> q_size - 1 ) ) ) { dev_crit ( dev , "Invalid rd_idx 0x%x or size 0x%x =>max 0x%x!" , rd_idx , src_size , qinfo -> q_size ) ; bcm_vk_blk_drv_access ( vk ) ; bcm_vk_set_host_alert ( vk , ERR_LOG_HOST_PCIE_DWN ) ; idx_err } num_blks = src_size + 1 ; data = kzalloc ( num_blks * VK_MSGQ_BLK_SIZE , GFP_KERNEL ) ; if ( data ) { dst = data ; for ( j = 0 ; j < num_blks ; j ++ ) { memcpy_fromio ( dst , src , sizeof ( * dst ) ) ; dst ++ ; rd_idx = msgq_inc ( qinfo , rd_idx , 1 ) ; src = msgq_blk_addr ( qinfo , rd_idx ) ; } total ++ ; } else { dev_crit ( dev , "Kernel mem allocation failure.\n" ) ; total = - ENOMEM ; idx_err } writel ( rd_idx , & msgq -> rd_idx ) ; dev_dbg ( dev , "MsgQ[%d] [Rd Wr]= [%d %d] blks extracted %d - Q = [u-%d a-%d]/%d\n" , readl_relaxed ( & msgq -> num ) , rd_idx , wr_idx , num_blks , msgq_occupied ( msgq , qinfo ) , msgq_avail_space ( msgq , qinfo ) , readl_relaxed ( & msgq -> size ) ) ; if ( data -> function_id == VK_FID_SHUTDOWN ) { continue ; } msg_id = get_msg_id ( data ) ; entry = bcm_vk_dequeue_pending ( vk , & vk -> to_v_msg_chan , q_num , msg_id ) ; if ( entry ) { entry -> to_h_blks = num_blks ; entry -> to_h_msg = data ; bcm_vk_append_pendq ( & vk -> to_h_msg_chan , q_num , entry ) ; } else { if ( cnt ++ < batch_log ) { dev_info ( dev , "Could not find MsgId[0x%x] for resp func %d bmap %d\n" , msg_id , data -> function_id , test_bit ( msg_id , vk -> bmap ) ) ; } kfree ( data ) ; } wr_idx = readl ( & msgq -> wr_idx ) ; if ( ++ msg_processed >= max_msg_to_process ) { dev_warn ( dev , "Q[%d] Per loop processing exceeds %d\n" , q_num , max_msg_to_process ) ; exit_loop = true ; } } } idx_err mutex_unlock ( & chan -> msgq_mutex ) ; dev_dbg ( dev , "total %d drained from queues\n" , total ) ; return total ; } 