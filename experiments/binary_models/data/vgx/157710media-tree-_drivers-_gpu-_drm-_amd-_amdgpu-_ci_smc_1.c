int amdgpu_ci_load_smc_ucode ( struct amdgpu_device * adev , u32 limit ) { const struct smc_firmware_header_v1_0 * hdr ; unsigned long flags ; u32 ucode_start_address ; u32 ucode_size ; const u8 * src ; u32 data ; if ( ! adev -> pm . fw ) { return - EINVAL ; } hdr = ( const smc_firmware_header_v1_0 * ) adev -> pm . fw -> data ; amdgpu_ucode_print_smc_hdr ( & hdr -> header ) ; adev -> pm . fw_version = le32_to_cpu ( hdr -> header . ucode_version ) ; ucode_start_address = le32_to_cpu ( hdr -> ucode_start_addr ) ; ucode_size = le32_to_cpu ( hdr -> header . ucode_size_bytes ) ; src = ( const u8 * ) ( adev -> pm . fw -> data + le32_to_cpu ( hdr -> header . ucode_array_offset_bytes ) ) ; spin_lock_irqsave ( & adev -> smc_idx_lock , flags ) ; WREG32 ( mmSMC_IND_INDEX_0 , ucode_start_address ) ; WREG32_P ( mmSMC_IND_ACCESS_CNTL , SMC_IND_ACCESS_CNTL__AUTO_INCREMENT_IND_0_MASK , ~ SMC_IND_ACCESS_CNTL__AUTO_INCREMENT_IND_0_MASK ) ; while ( ucode_size >= 4 ) { data = ( src [ 0 ] << 24 ) | ( src [ 1 ] << 16 ) | ( src [ 2 ] << 8 ) | src [ 3 ] ; WREG32 ( mmSMC_IND_DATA_0 , data ) ; src += 4 ; ucode_size -= 4 ; } WREG32_P ( mmSMC_IND_ACCESS_CNTL , 0 , ~ SMC_IND_ACCESS_CNTL__AUTO_INCREMENT_IND_0_MASK ) ; spin_unlock_irqrestore ( & adev -> smc_idx_lock , flags ) ; return 0 ; } 