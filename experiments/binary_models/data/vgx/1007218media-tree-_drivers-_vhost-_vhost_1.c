static long vhost_set_memory ( struct vhost_dev * d , struct vhost_memory __user * m ) { struct vhost_memory mem , * newmem ; struct vhost_memory_region * region ; struct vhost_umem * newumem , * oldumem ; unsigned long size = offsetof ( vhost_memory , regions ) ; int i ; if ( copy_from_user ( & mem , m , size ) ) { return - EFAULT ; } if ( mem . padding ) { return - EOPNOTSUPP ; } if ( mem . nregions > max_mem_regions ) { return - E2BIG ; } newmem = kvzalloc ( size + mem . nregions * sizeof ( * m -> regions ) , GFP_KERNEL ) ; if ( ! newmem ) { return - ENOMEM ; } memcpy ( newmem , & mem , size ) ; if ( copy_from_user ( newmem -> regions , m -> regions , mem . nregions * sizeof m -> regions ) ) { kvfree ( newmem ) ; return - EFAULT ; } newumem = vhost_umem_alloc ( ) ; if ( ! newumem ) { return - ENOMEM ; } for ( region = newmem -> regions ; region < newmem -> regions + mem . nregions ; region ++ ) { if ( vhost_new_umem_range ( newumem , region -> guest_phys_addr , region -> memory_size , region -> guest_phys_addr + region -> memory_size - 1 , region -> userspace_addr , VHOST_ACCESS_RW ) ) { err } } if ( ! memory_access_ok ( d , newumem , 0 ) ) { err } oldumem = d -> umem ; d -> umem = newumem ; for ( i = 0 ; i < d -> nvqs ; ++ i ) { mutex_lock ( & d -> vqs [ i ] -> mutex ) ; d -> vqs [ i ] -> umem = newumem ; mutex_unlock ( & d -> vqs [ i ] -> mutex ) ; } kvfree ( newmem ) ; vhost_umem_clean ( oldumem ) ; return 0 ; err vhost_umem_clean ( newumem ) ; kvfree ( newmem ) ; return - EFAULT ; } 