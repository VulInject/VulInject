static void sfq_rehash ( struct Qdisc * sch ) { struct sfq_sched_data * q = qdisc_priv ( sch ) ; struct sk_buff * skb ; int i ; struct sfq_slot * slot ; struct sk_buff_head list ; int dropped = 0 ; unsigned int drop_len = 0 ; __skb_queue_head_init ( & list ) ; for ( i = 0 ; i < q -> maxflows ; i ++ ) { slot = & q -> slots [ i ] ; if ( ! slot -> qlen ) { continue ; } while ( slot -> qlen ) { skb = slot_dequeue_head ( slot ) ; sfq_dec ( q , i ) ; __skb_queue_tail ( & list , skb ) ; } slot -> backlog = 0 ; red_set_vars ( & slot -> vars ) ; q -> ht [ slot -> hash ] = SFQ_EMPTY_SLOT ; } q -> tail = NULL ; while ( ( skb = __skb_dequeue ( & list ) ) != NULL ) { unsigned int hash = sfq_hash ( q , skb ) ; sfq_index x = q -> ht [ hash ] ; slot = & q -> slots [ x ] ; if ( x == SFQ_EMPTY_SLOT ) { x = q -> dep [ 0 ] . next ; if ( x >= SFQ_MAX_FLOWS ) { drop qdisc_qstats_backlog_dec ( sch , skb ) ; drop_len += qdisc_pkt_len ( skb ) ; dropped ++ ; continue ; } q -> ht [ hash ] = x ; slot = & q -> slots [ x ] ; slot -> hash = hash ; } if ( slot -> qlen >= q -> maxdepth ) { drop } slot_queue_add ( slot , skb ) ; if ( q -> red_parms ) { slot -> vars . qavg = red_calc_qavg ( q -> red_parms , & slot -> vars , slot -> backlog ) ; } slot -> backlog += qdisc_pkt_len ( skb ) ; sfq_inc ( q , x ) ; if ( slot -> qlen == 1 ) { if ( q -> tail == NULL ) { slot -> next = x ; } else { slot -> next = q -> tail -> next ; q -> tail -> next = x ; } q -> tail = slot ; slot -> allot = q -> scaled_quantum ; } } sch -> q . qlen -= dropped ; qdisc_tree_reduce_backlog ( sch , dropped , drop_len ) ; } 