static int xts_decrypt ( struct skcipher_request * req ) { struct crypto_skcipher * tfm = crypto_skcipher_reqtfm ( req ) ; struct crypto_aes_xts_ctx * ctx = crypto_skcipher_ctx ( tfm ) ; int err , first , rounds = num_rounds ( & ctx -> key1 ) ; int tail = req -> cryptlen % AES_BLOCK_SIZE ; struct scatterlist sg_src [ 2 ] , sg_dst [ 2 ] ; struct skcipher_request subreq ; struct scatterlist * src , * dst ; struct skcipher_walk walk ; if ( req -> cryptlen < AES_BLOCK_SIZE ) { return - EINVAL ; } err = skcipher_walk_virt ( & walk , req , false ) ; if ( unlikely ( tail > 0 && walk . nbytes < walk . total ) ) { int xts_blocks = DIV_ROUND_UP ( req -> cryptlen , AES_BLOCK_SIZE ) - 2 ; skcipher_walk_abort ( & walk ) ; skcipher_request_set_tfm ( & subreq , tfm ) ; skcipher_request_set_callback ( & subreq , skcipher_request_flags ( req ) , NULL , NULL ) ; skcipher_request_set_crypt ( & subreq , req -> src , req -> dst , xts_blocks * AES_BLOCK_SIZE , req -> iv ) ; req = & subreq ; err = skcipher_walk_virt ( & walk , req , false ) ; } else { tail = 0 ; } for ( first = 1 ; walk . nbytes >= AES_BLOCK_SIZE ; first = 0 ) { int nbytes = walk . nbytes ; if ( walk . nbytes < walk . total ) { nbytes &= ~ ( AES_BLOCK_SIZE - 1 ) ; } kernel_neon_begin ( ) ; ce_aes_xts_decrypt ( walk . dst . virt . addr , walk . src . virt . addr , ctx -> key1 . key_dec , rounds , nbytes , walk . iv , ctx -> key2 . key_enc , first ) ; kernel_neon_end ( ) ; err = skcipher_walk_done ( & walk , walk . nbytes - nbytes ) ; } if ( err || likely ( ! tail ) ) { return err ; } dst = src = scatterwalk_ffwd ( sg_src , req -> src , req -> cryptlen ) ; if ( req -> dst != req -> src ) { dst = scatterwalk_ffwd ( sg_dst , req -> dst , req -> cryptlen ) ; } skcipher_request_set_crypt ( req , src , dst , AES_BLOCK_SIZE + tail , req -> iv ) ; err = skcipher_walk_virt ( & walk , req , false ) ; kernel_neon_begin ( ) ; ce_aes_xts_decrypt ( walk . dst . virt . addr , walk . src . virt . addr , ctx -> key1 . key_dec , rounds , walk . nbytes , walk . iv , ctx -> key2 . key_enc , first ) ; kernel_neon_end ( ) ; return skcipher_walk_done ( & walk , 0 ) ; } static struct skcipher_alg aes_algs [ ] { { . base . cra_name = "__ecb(aes)" . base . cra_driver_name = "__ecb-aes-ce" . base . cra_priority = 300 . base . cra_flags = CRYPTO_ALG_INTERNAL . base . cra_blocksize = AES_BLOCK_SIZE . base . cra_ctxsize = sizeof ( crypto_aes_ctx ) . base . cra_module = THIS_MODULE . min_keysize = AES_MIN_KEY_SIZE . max_keysize = AES_MAX_KEY_SIZE . setkey = ce_aes_setkey . encrypt = ecb_encrypt . decrypt = ecb_decrypt } { . base . cra_name = "__cbc(aes)" . base . cra_driver_name = "__cbc-aes-ce" . base . cra_priority = 300 . base . cra_flags = CRYPTO_ALG_INTERNAL . base . cra_blocksize = AES_BLOCK_SIZE . base . cra_ctxsize = sizeof ( crypto_aes_ctx ) . base . cra_module = THIS_MODULE . min_keysize = AES_MIN_KEY_SIZE . max_keysize = AES_MAX_KEY_SIZE . ivsize = AES_BLOCK_SIZE . setkey = ce_aes_setkey . encrypt = cbc_encrypt . decrypt = cbc_decrypt } { . base . cra_name = "__cts(cbc(aes))" . base . cra_driver_name = "__cts-cbc-aes-ce" . base . cra_priority = 300 . base . cra_flags = CRYPTO_ALG_INTERNAL . base . cra_blocksize = AES_BLOCK_SIZE . base . cra_ctxsize = sizeof ( crypto_aes_ctx ) . base . cra_module = THIS_MODULE . min_keysize = AES_MIN_KEY_SIZE . max_keysize = AES_MAX_KEY_SIZE . ivsize = AES_BLOCK_SIZE . walksize = 2 * AES_BLOCK_SIZE . setkey = ce_aes_setkey . encrypt = cts_cbc_encrypt . decrypt = cts_cbc_decrypt } { . base . cra_name = "__ctr(aes)" . base . cra_driver_name = "__ctr-aes-ce" . base . cra_priority = 300 . base . cra_flags = CRYPTO_ALG_INTERNAL . base . cra_blocksize = 1 . base . cra_ctxsize = sizeof ( crypto_aes_ctx ) . base . cra_module = THIS_MODULE . min_keysize = AES_MIN_KEY_SIZE . max_keysize = AES_MAX_KEY_SIZE . ivsize = AES_BLOCK_SIZE . chunksize = AES_BLOCK_SIZE . setkey = ce_aes_setkey . encrypt = ctr_encrypt . decrypt = ctr_encrypt } { . base . cra_name = "ctr(aes)" . base . cra_driver_name = "ctr-aes-ce-sync" . base . cra_priority = 300 - 1 . base . cra_blocksize = 1 . base . cra_ctxsize = sizeof ( crypto_aes_ctx ) . base . cra_module = THIS_MODULE . min_keysize = AES_MIN_KEY_SIZE . max_keysize = AES_MAX_KEY_SIZE . ivsize = AES_BLOCK_SIZE . chunksize = AES_BLOCK_SIZE . setkey = ce_aes_setkey . encrypt = ctr_encrypt_sync . decrypt = ctr_encrypt_sync } { . base . cra_name = "__xts(aes)" . base . cra_driver_name = "__xts-aes-ce" . base . cra_priority = 300 . base . cra_flags = CRYPTO_ALG_INTERNAL . base . cra_blocksize = AES_BLOCK_SIZE . base . cra_ctxsize = sizeof ( crypto_aes_xts_ctx ) . base . cra_module = THIS_MODULE . min_keysize = 2 * AES_MIN_KEY_SIZE . max_keysize = 2 * AES_MAX_KEY_SIZE . ivsize = AES_BLOCK_SIZE . walksize = 2 * AES_BLOCK_SIZE . setkey = xts_set_key . encrypt = xts_encrypt . decrypt = xts_decrypt } } ; ; 