static int cxgbit_uld_lro_rx_handler ( void * hndl , const __be64 * rsp , const struct pkt_gl * gl , struct t4_lro_mgr * lro_mgr , struct napi_struct * napi ) { struct cxgbit_device * cdev = hndl ; struct cxgb4_lld_info * lldi = & cdev -> lldi ; struct cpl_tx_data * rpl = NULL ; struct cxgbit_sock * csk = NULL ; unsigned int tid = 0 ; struct sk_buff * skb ; unsigned int op = * ( u8 * ) rsp ; bool lro_flush = true ; switch ( op ) { case CPL_ISCSI_HDR : case CPL_ISCSI_DATA : case CPL_RX_ISCSI_CMP : case CPL_RX_ISCSI_DDP : case CPL_FW4_ACK : lro_flush = false ; fallthrough ; case CPL_ABORT_RPL_RSS : case CPL_PASS_ESTABLISH : case CPL_PEER_CLOSE : case CPL_CLOSE_CON_RPL : case CPL_ABORT_REQ_RSS : case CPL_SET_TCB_RPL : case CPL_RX_DATA : rpl = gl ?( cpl_tx_data * ) gl -> va : ( cpl_tx_data * ) ( rsp + 1 ) ; tid = GET_TID ( rpl ) ; csk = lookup_tid ( lldi -> tids , tid ) ; break ; default : break ; } if ( csk && csk -> lro_skb && lro_flush ) { cxgbit_lro_flush ( lro_mgr , csk -> lro_skb ) ; } if ( ! gl ) { unsigned int len ; if ( op == CPL_RX_ISCSI_DDP ) { if ( ! cxgbit_lro_receive ( csk , op , rsp , NULL , lro_mgr , napi ) ) { return 0 ; } } len = 64 - sizeof ( rsp_ctrl ) - 8 ; skb = napi_alloc_skb ( napi , len ) ; if ( ! skb ) { nomem } __skb_put ( skb , len ) ; skb_copy_to_linear_data ( skb , & rsp [ 1 ] , len ) ; } else { if ( unlikely ( op != * ( u8 * ) gl -> va ) ) { pr_info ( "? FL 0x%p,RSS%#llx,FL %#llx,len %u.\n" , gl -> va , be64_to_cpu ( * rsp ) , get_unaligned_be64 ( gl -> va ) , gl -> tot_len ) ; return 0 ; } if ( ( op == CPL_ISCSI_HDR ) || ( op == CPL_ISCSI_DATA ) || ( op == CPL_RX_ISCSI_CMP ) ) { if ( ! cxgbit_lro_receive ( csk , op , rsp , gl , lro_mgr , napi ) ) { return 0 ; } } skb = cxgb4_pktgl_to_skb ( gl , RX_PULL_LEN , RX_PULL_LEN ) ; if ( unlikely ( ! skb ) ) { nomem } } rpl = ( cpl_tx_data * ) skb -> data ; op = rpl -> ot . opcode ; cxgbit_skcb_rx_opcode ( skb ) = op ; pr_debug ( "cdev %p, opcode 0x%x(0x%x,0x%x), skb %p.\n" , cdev , op , rpl -> ot . opcode_tid , ntohl ( rpl -> ot . opcode_tid ) , skb ) ; if ( op < NUM_CPL_CMDS && cxgbit_cplhandlers [ op ] ) { cxgbit_cplhandlers [ op ] ( cdev , skb ) ; } else { pr_err ( "No handler for opcode 0x%x.\n" , op ) ; } return 0 ; nomem pr_err ( "%s OOM bailing out.\n" , __func__ ) ; return 1 ; } cxgbit_dcb_work { struct dcb_app_type dcb_app ; struct work_struct work ; } 