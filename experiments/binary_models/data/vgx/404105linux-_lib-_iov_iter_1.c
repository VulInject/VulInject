static ssize_t __iov_iter_get_pages_alloc ( struct iov_iter * i , struct page * * * pages , size_t maxsize , unsigned int maxpages , size_t * start , iov_iter_extraction_t extraction_flags ) { unsigned int n , gup_flags = 0 ; if ( maxsize > i -> count ) { maxsize = i -> count ; } if ( ! maxsize ) { return 0 ; } if ( maxsize > MAX_RW_COUNT ) { maxsize = MAX_RW_COUNT ; } if ( extraction_flags & ITER_ALLOW_P2PDMA ) { gup_flags |= FOLL_PCI_P2PDMA ; } if ( likely ( user_backed_iter ( i ) ) ) { unsigned long addr ; int res ; if ( iov_iter_rw ( i ) != WRITE ) { gup_flags |= FOLL_WRITE ; } if ( i -> nofault ) { gup_flags |= FOLL_NOFAULT ; } addr = first_iovec_segment ( i , & maxsize ) ; * start = addr % PAGE_SIZE ; addr &= PAGE_MASK ; n = want_pages_array ( pages , maxsize , * start , maxpages ) ; res = get_user_pages_fast ( addr , n , gup_flags , * pages ) ; if ( unlikely ( res <= 0 ) ) { return res ; } maxsize = min_t ( size_t , maxsize , res * PAGE_SIZE - * start ) ; iov_iter_advance ( i , maxsize ) ; return maxsize ; } if ( iov_iter_is_bvec ( i ) ) { struct page * * p ; struct page * page ; page = first_bvec_segment ( i , & maxsize , start ) ; n = want_pages_array ( pages , maxsize , * start , maxpages ) ; if ( ! n ) { return - ENOMEM ; } p = * pages ; for ( int k = 0 ; k < n ; k ++ ) { get_page ( p [ k ] = page + k ) ; } maxsize = min_t ( size_t , maxsize , n * PAGE_SIZE - * start ) ; i -> count -= maxsize ; i -> iov_offset += maxsize ; if ( i -> iov_offset == i -> bvec -> bv_len ) { i -> iov_offset = 0 ; i -> bvec ++ ; i -> nr_segs -- ; } return maxsize ; } if ( iov_iter_is_pipe ( i ) ) { return pipe_get_pages ( i , pages , maxsize , maxpages , start ) ; } if ( iov_iter_is_xarray ( i ) ) { return iter_xarray_get_pages ( i , pages , maxsize , maxpages , start ) ; } return - EFAULT ; } 