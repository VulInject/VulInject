u64 btrfs_find_space_for_alloc ( struct btrfs_block_group * block_group , u64 offset , u64 bytes , u64 empty_size , u64 * max_extent_size ) { struct btrfs_free_space_ctl * ctl = block_group -> free_space_ctl ; struct btrfs_discard_ctl * discard_ctl = & block_group -> fs_info -> discard_ctl ; struct btrfs_free_space * entry = NULL ; u64 bytes_search = bytes + empty_size ; u64 ret = 0 ; u64 align_gap = 0 ; u64 align_gap_len = 0 ; enum btrfs_trim_state align_gap_trim_state = BTRFS_TRIM_STATE_UNTRIMMED ; bool use_bytes_index = ( offset == block_group -> start ) ; ASSERT ( ! btrfs_is_zoned ( block_group -> fs_info ) ) ; spin_lock ( & ctl -> tree_lock ) ; entry = find_free_space ( ctl , & offset , & bytes_search , block_group -> full_stripe_len , max_extent_size , use_bytes_index ) ; if ( ! entry ) { out } ret = offset ; if ( entry -> bitmap ) { bitmap_clear_bits ( ctl , entry , offset , bytes , true ) ; if ( ! btrfs_free_space_trimmed ( entry ) ) { atomic64_add ( bytes , & discard_ctl -> discard_bytes_saved ) ; } if ( ! entry -> bytes ) { free_bitmap ( ctl , entry ) ; } } else { unlink_free_space ( ctl , entry , true ) ; align_gap_len = offset - entry -> offset ; align_gap = entry -> offset ; align_gap_trim_state = entry -> trim_state ; if ( ! btrfs_free_space_trimmed ( entry ) ) { atomic64_add ( bytes , & discard_ctl -> discard_bytes_saved ) ; } entry -> offset = offset + bytes ; WARN_ON ( entry -> bytes < bytes + align_gap_len ) ; entry -> bytes -= bytes + align_gap_len ; else { link_free_space ( ctl , entry ) ; } } out btrfs_discard_update_discardable ( block_group ) ; spin_unlock ( & ctl -> tree_lock ) ; if ( align_gap_len ) { __btrfs_add_free_space ( block_group , align_gap , align_gap_len , align_gap_trim_state ) ; } return ret ; } 