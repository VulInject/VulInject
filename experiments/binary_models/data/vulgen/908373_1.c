struct gru_state * gru_assign_gru_context ( struct gru_thread_state * gts ) { struct gru_state * gru , * grux ; int i , max_active_contexts ; int blade_id = gts -> ts_user_blade_id ; if ( blade_id < 0 ) { blade_id = uv_numa_blade_id ( ) ; } again gru = NULL ; max_active_contexts = GRU_NUM_CCH ; for_each_gru_on_blade ( , , ) { if ( ! gru_check_chiplet_assignment ( grux , gts ) ) { continue ; } if ( check_gru_resources ( grux , gts -> ts_cbr_au_count , gts -> ts_dsr_au_count , max_active_contexts ) ) { gru = grux ; max_active_contexts = grux -> gs_active_contexts ; } } if ( gru ) { spin_lock ( & gru -> gs_lock ) ; if ( ! check_gru_resources ( gru , gts -> ts_cbr_au_count , gts -> ts_dsr_au_count , GRU_NUM_CCH ) ) { spin_unlock ( & gru -> gs_lock ) ; again } reserve_gru_resources ( gru , gts ) ; gts -> ts_gru = gru ; gts -> ts_blade = gru -> gs_blade_id ; gts -> ts_ctxnum = gru_assign_context_number ( gru ) ; refcount_inc ( & gts -> ts_refcnt ) ; gru -> gs_gts [ gts -> ts_ctxnum ] = gts ; spin_unlock ( & gru -> gs_lock ) ; STAT ( assign_context ) ; gru_dbg ( grudev , "gseg %p, gts %p, gid %d, ctx %d, cbr %d, dsr %d\n" , gseg_virtual_address ( gts -> ts_gru , gts -> ts_ctxnum ) , gts , gts -> ts_gru -> gs_gid , gts -> ts_ctxnum , gts -> ts_cbr_au_count , gts -> ts_dsr_au_count ) ; } else { gru_dbg ( grudev , "failed to allocate a GTS %s\n" , "" ) ; STAT ( assign_context_failed ) ; } return gru ; } 