* = - 1.613125930 * z10 - z10 + z5 ; * / z5 = _mm_add_pi16 ( tmp10 , tmp12 ) ; z5 = _mm_mulhi_pi16 ( z5 , PW_F1847 ) ; tmp10 = _mm_mulhi_pi16 ( tmp10 , PW_F1082 ) ; tmp10 = _mm_sub_pi16 ( tmp10 , z5 ) ; tmp12 = _mm_mulhi_pi16 ( tmp12 , PW_MF1613 ) ; tmp12 = _mm_sub_pi16 ( tmp12 , z10 ) ; tmp12 = _mm_sub_pi16 ( tmp12 , z10 ) ; tmp12 = _mm_sub_pi16 ( tmp12 , z10 ) ; tmp12 = _mm_add_pi16 ( tmp12 , z5 ) ; tmp6 = _mm_sub_pi16 ( tmp12 , tmp7 ) ; tmp5 = _mm_sub_pi16 ( tmp11 , tmp6 ) ; tmp4 = _mm_add_pi16 ( tmp10 , tmp5 ) ; out0 = _mm_add_pi16 ( tmp0 , tmp7 ) ; out7 = _mm_sub_pi16 ( tmp0 , tmp7 ) ; out1 = _mm_add_pi16 ( tmp1 , tmp6 ) ; out6 = _mm_sub_pi16 ( tmp1 , tmp6 ) ; out2 = _mm_add_pi16 ( tmp2 , tmp5 ) ; out5 = _mm_sub_pi16 ( tmp2 , tmp5 ) ; out4 = _mm_add_pi16 ( tmp3 , tmp4 ) ; out3 = _mm_sub_pi16 ( tmp3 , tmp4 ) ; col0l , col1l , col2l , col3l , col4l , col5l , col6l , col7l ; __m64 quant0l , quant1l , quant2l , quant3l ; __m64 quant4l , quant5l , quant6l , quant7l ; __m64 row01a , row01b , row01c , row01d , row23a , row23b , row23c , row23d ; __m64 row0l , row0h , row1l , row1h , row2l , row2h , row3l , row3h ; __m32 col0a , col1a , mm0 ; col0a = _mm_load_si32 ( ( __m32 * ) & inptr [ DCTSIZE * 1 ] ) ; col1a = _mm_load_si32 ( ( __m32 * ) & inptr [ DCTSIZE * 2 ] ) ; mm0 = _mm_or_si32 ( col0a , col1a ) ; if ( test_m32_zero ( mm0 ) ) { __m64 mm1 , mm2 ; col0l = _mm_load_si64 ( ( __m64 * ) & inptr [ DCTSIZE * 0 ] ) ; col1l = _mm_load_si64 ( ( __m64 * ) & inptr [ DCTSIZE * 1 ] ) ; col2l = _mm_load_si64 ( ( __m64 * ) & inptr [ DCTSIZE * 2 ] ) ; col3l = _mm_load_si64 ( ( __m64 * ) & inptr [ DCTSIZE * 3 ] ) ; col4l = _mm_load_si64 ( ( __m64 * ) & inptr [ DCTSIZE * 4 ] ) ; col5l = _mm_load_si64 ( ( __m64 * ) & inptr [ DCTSIZE * 5 ] ) ; col6l = _mm_load_si64 ( ( __m64 * ) & inptr [ DCTSIZE * 6 ] ) ; col7l = _mm_load_si64 ( ( __m64 * ) & inptr [ DCTSIZE * 7 ] ) ; mm1 = _mm_or_si64 ( col1l , col3l ) ; mm2 = _mm_or_si64 ( col2l , col4l ) ; mm1 = _mm_or_si64 ( mm1 , col5l ) ; mm2 = _mm_or_si64 ( mm2 , col6l ) ; mm1 = _mm_or_si64 ( mm1 , col7l ) ; mm1 = _mm_or_si64 ( mm1 , mm2 ) ; } col0l = _mm_load_si64 ( ( __m64 * ) & inptr [ DCTSIZE * 0 ] ) ; col2l = _mm_load_si64 ( ( __m64 * ) & inptr [ DCTSIZE * 2 ] ) ; col4l = _mm_load_si64 ( ( __m64 * ) & inptr [ DCTSIZE * 4 ] ) ; col6l = _mm_load_si64 ( ( __m64 * ) & inptr [ DCTSIZE * 6 ] ) ; quant0l = _mm_load_si64 ( ( __m64 * ) & quantptr [ DCTSIZE * 0 ] ) ; quant2l = _mm_load_si64 ( ( __m64 * ) & quantptr [ DCTSIZE * 2 ] ) ; quant4l = _mm_load_si64 ( ( __m64 * ) & quantptr [ DCTSIZE * 4 ] ) ; quant6l = _mm_load_si64 ( ( __m64 * ) & quantptr [ DCTSIZE * 6 ] ) ; tmp0 = _mm_mullo_pi16 ( col0l , quant0l ) ; tmp1 = _mm_mullo_pi16 ( col2l , quant2l ) ; tmp2 = _mm_mullo_pi16 ( col4l , quant4l ) ; tmp3 = _mm_mullo_pi16 ( col6l , quant6l ) ; tmp10 = _mm_add_pi16 ( tmp0 , tmp2 ) ; tmp11 = _mm_sub_pi16 ( tmp0 , tmp2 ) ; tmp13 = _mm_add_pi16 ( tmp1 , tmp3 ) ; tmp12 = _mm_sub_pi16 ( tmp1 , tmp3 ) ; tmp12 = _mm_slli_pi16 ( tmp12 , PRE_MULTIPLY_SCALE_BITS ) ; tmp12 = _mm_mulhi_pi16 ( tmp12 , PW_F1414 ) ; tmp12 = _mm_sub_pi16 ( tmp12 , tmp13 ) ; tmp0 = _mm_add_pi16 ( tmp10 , tmp13 ) ; tmp3 = _mm_sub_pi16 ( tmp10 , tmp13 ) ; tmp1 = _mm_add_pi16 ( tmp11 , tmp12 ) ; tmp2 = _mm_sub_pi16 ( tmp11 , tmp12 ) ; col1l = _mm_load_si64 ( ( __m64 * ) & inptr [ DCTSIZE * 1 ] ) ; col3l = _mm_load_si64 ( ( __m64 * ) & inptr [ DCTSIZE * 3 ] ) ; col5l = _mm_load_si64 ( ( __m64 * ) & inptr [ DCTSIZE * 5 ] ) ; col7l = _mm_load_si64 ( ( __m64 * ) & inptr [ DCTSIZE * 7 ] ) ; quant1l = _mm_load_si64 ( ( __m64 * ) & quantptr [ DCTSIZE * 1 ] ) ; quant3l = _mm_load_si64 ( ( __m64 * ) & quantptr [ DCTSIZE * 3 ] ) ; quant5l = _mm_load_si64 ( ( __m64 * ) & quantptr [ DCTSIZE * 5 ] ) ; quant7l = _mm_load_si64 ( ( __m64 * ) & quantptr [ DCTSIZE * 7 ] ) ; tmp4 = _mm_mullo_pi16 ( col1l , quant1l ) ; tmp5 = _mm_mullo_pi16 ( col3l , quant3l ) ; tmp6 = _mm_mullo_pi16 ( col5l , quant5l ) ; tmp7 = _mm_mullo_pi16 ( col7l , quant7l ) ; z13 = _mm_add_pi16 ( tmp6 , tmp5 ) ; z10 = _mm_sub_pi16 ( tmp6 , tmp5 ) ; z11 = _mm_add_pi16 ( tmp4 , tmp7 ) ; z12 = _mm_sub_pi16 ( tmp4 , tmp7 ) ; DO_IDCT_COMMON ( ) row01a = _mm_unpacklo_pi16 ( out0 , out1 ) ; row23a = _mm_unpackhi_pi16 ( out0 , out1 ) ; row01d = _mm_unpacklo_pi16 ( out6 , out7 ) ; row23d = _mm_unpackhi_pi16 ( out6 , out7 ) ; row01b = _mm_unpacklo_pi16 ( out2 , out3 ) ; row23b = _mm_unpackhi_pi16 ( out2 , out3 ) ; row01c = _mm_unpacklo_pi16 ( out4 , out5 ) ; row23c = _mm_unpackhi_pi16 ( out4 , out5 ) ; row0l = _mm_unpacklo_pi32 ( row01a , row01b ) ; row1l = _mm_unpackhi_pi32 ( row01a , row01b ) ; row2l = _mm_unpacklo_pi32 ( row23a , row23b ) ; row3l = _mm_unpackhi_pi32 ( row23a , row23b ) ; row0h = _mm_unpacklo_pi32 ( row01c , row01d ) ; row1h = _mm_unpackhi_pi32 ( row01c , row01d ) ; row2h = _mm_unpacklo_pi32 ( row23c , row23d ) ; row3h = _mm_unpackhi_pi32 ( row23c , row23d ) ; _mm_store_si64 ( ( __m64 * ) & wsptr [ DCTSIZE * 0 ] , row0l ) ; _mm_store_si64 ( ( __m64 * ) & wsptr [ DCTSIZE * 0 + 4 ] , row0h ) ; _mm_store_si64 ( ( __m64 * ) & wsptr [ DCTSIZE * 1 ] , row1l ) ; _mm_store_si64 ( ( __m64 * ) & wsptr [ DCTSIZE * 1 + 4 ] , row1h ) ; _mm_store_si64 ( ( __m64 * ) & wsptr [ DCTSIZE * 2 ] , row2l ) ; _mm_store_si64 ( ( __m64 * ) & wsptr [ DCTSIZE * 2 + 4 ] , row2h ) ; _mm_store_si64 ( ( __m64 * ) & wsptr [ DCTSIZE * 3 ] , row3l ) ; _mm_store_si64 ( ( __m64 * ) & wsptr [ DCTSIZE * 3 + 4 ] , row3h ) ; 