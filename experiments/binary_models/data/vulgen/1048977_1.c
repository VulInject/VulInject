static int perf_move_data ( struct pthr_ctx * pctx , char __iomem * dst , char * src , u64 buf_size , u64 win_size , u64 total ) { int chunks , total_chunks , i ; int copied_chunks = 0 ; u64 copied = 0 , result ; char __iomem * tmp = dst ; u64 perf , diff_us ; ktime_t kstart , kstop , kdiff ; chunks = div64_u64 ( win_size , buf_size ) ; total_chunks = div64_u64 ( total , buf_size ) ; kstart = ktime_get ( ) ; for ( i = 0 ; i < total_chunks ; i ++ ) { result = perf_copy ( pctx , tmp , src , buf_size ) ; copied += result ; copied_chunks ++ ; if ( copied_chunks == chunks ) { tmp = dst ; copied_chunks = 0 ; } else { tmp += buf_size ; } if ( unlikely ( ( jiffies - last_sleep ) > 5 * HZ ) ) { last_sleep = jiffies ; set_current_state ( TASK_INTERRUPTIBLE ) ; schedule_timeout ( 1 ) ; } if ( unlikely ( kthread_should_stop ( ) ) ) { break ; } } if ( use_dma ) { pr_debug ( "%s: All DMA descriptors submitted\n" , current -> comm ) ; while ( atomic_read ( & pctx -> dma_sync ) != 0 ) { if ( kthread_should_stop ( ) ) { break ; } msleep ( 20 ) ; } } kstop = ktime_get ( ) ; kdiff = ktime_sub ( kstop , kstart ) ; diff_us = ktime_to_us ( kdiff ) ; pr_debug ( "%s: copied %llu bytes\n" , current -> comm , copied ) ; pr_debug ( "%s: lasted %llu usecs\n" , current -> comm , diff_us ) ; perf = div64_u64 ( copied , diff_us ) ; pr_debug ( "%s: MBytes/s: %llu\n" , current -> comm , perf ) ; pctx -> copied = copied ; pctx -> diff_us = diff_us ; return 0 ; } 