static struct hfs_bnode * __hfs_bnode_create ( struct hfs_btree * tree , u32 cnid ) { struct hfs_bnode * node , * node2 ; struct address_space * mapping ; struct page * page ; int size , block , i , hash ; loff_t off ; if ( cnid >= tree -> node_count ) { pr_err ( "request for non-existent node %d in B*Tree\n" , cnid ) ; return NULL ; } size = sizeof ( hfs_bnode ) + tree -> pages_per_bnode * sizeof ( page * ) ; node = kzalloc ( size , GFP_KERNEL ) ; if ( ! node ) { return NULL ; } node -> tree = tree ; node -> this = cnid ; set_bit ( HFS_BNODE_NEW , & node -> flags ) ; atomic_set ( & node -> refcnt , 1 ) ; hfs_dbg ( BNODE_REFS , "new_node(%d:%d): 1\n" , node -> tree -> cnid , node -> this ) ; init_waitqueue_head ( & node -> lock_wq ) ; spin_lock ( & tree -> hash_lock ) ; node2 = hfs_bnode_findhash ( tree , cnid ) ; if ( ! node2 ) { hash = hfs_bnode_hash ( cnid ) ; node -> next_hash = tree -> node_hash [ hash ] ; tree -> node_hash [ hash ] = node ; tree -> node_hash_cnt ++ ; } else { hfs_bnode_get ( node2 ) ; spin_unlock ( & tree -> hash_lock ) ; wait_event ( node2 -> lock_wq , ! test_bit ( HFS_BNODE_NEW , & node2 -> flags ) ) ; return node2 ; } spin_unlock ( & tree -> hash_lock ) ; mapping = tree -> inode -> i_mapping ; off = ( loff_t ) cnid * tree -> node_size ; block = off >> PAGE_SHIFT ; node -> page_offset = off & ~ PAGE_MASK ; for ( i = 0 ; i < tree -> pages_per_bnode ; i ++ ) { page = read_mapping_page ( mapping , block ++ , NULL ) ; if ( IS_ERR ( page ) ) { fail } node -> page [ i ] = page ; } return node ; fail set_bit ( HFS_BNODE_ERROR , & node -> flags ) ; return node ; } 