static void vmcb_init ( struct svm_softc * sc , int vcpu , uint64_t iopm_base_pa , uint64_t msrpm_base_pa , uint64_t np_pml4 ) { struct vmcb_ctrl * ctrl ; struct vmcb_state * state ; uint32_t mask ; int n ; ctrl = svm_get_vmcb_ctrl ( sc , vcpu ) ; state = svm_get_vmcb_state ( sc , vcpu ) ; ctrl -> iopm_base_pa = iopm_base_pa ; ctrl -> msrpm_base_pa = msrpm_base_pa ; ctrl -> np_ctrl = NP_ENABLE ; ctrl -> n_cr3 = np_pml4 ; for ( n = 0 ; n < 16 ; n ++ ) { mask = ( BIT ( n ) << 16 ) | BIT ( n ) ; if ( n == 0 || n == 2 || n == 3 || n == 4 || n == 8 ) { svm_disable_intercept ( sc , vcpu , VMCB_CR_INTCPT , mask ) ; } else { svm_enable_intercept ( sc , vcpu , VMCB_CR_INTCPT , mask ) ; } } if ( vcpu_trace_exceptions ( sc -> vm , vcpu ) ) { for ( n = 0 ; n < 32 ; n ++ ) { if ( n == 2 || n == 9 ) { continue ; } svm_enable_intercept ( sc , vcpu , VMCB_EXC_INTCPT , BIT ( n ) ) ; } } else { svm_enable_intercept ( sc , vcpu , VMCB_EXC_INTCPT , BIT ( IDT_MC ) ) ; } svm_enable_intercept ( sc , vcpu , VMCB_CTRL1_INTCPT , VMCB_INTCPT_IO ) ; svm_enable_intercept ( sc , vcpu , VMCB_CTRL1_INTCPT , VMCB_INTCPT_MSR ) ; svm_enable_intercept ( sc , vcpu , VMCB_CTRL1_INTCPT , VMCB_INTCPT_CPUID ) ; svm_enable_intercept ( sc , vcpu , VMCB_CTRL1_INTCPT , VMCB_INTCPT_INTR ) ; svm_enable_intercept ( sc , vcpu , VMCB_CTRL1_INTCPT , VMCB_INTCPT_INIT ) ; svm_enable_intercept ( sc , vcpu , VMCB_CTRL1_INTCPT , VMCB_INTCPT_NMI ) ; svm_enable_intercept ( sc , vcpu , VMCB_CTRL1_INTCPT , VMCB_INTCPT_SMI ) ; svm_enable_intercept ( sc , vcpu , VMCB_CTRL1_INTCPT , VMCB_INTCPT_SHUTDOWN ) ; svm_enable_intercept ( sc , vcpu , VMCB_CTRL1_INTCPT , VMCB_INTCPT_FERR_FREEZE ) ; svm_enable_intercept ( sc , vcpu , VMCB_CTRL1_INTCPT , VMCB_INTCPT_HLT ) ; svm_enable_intercept ( sc , vcpu , VMCB_CTRL2_INTCPT , VMCB_INTCPT_MONITOR ) ; svm_enable_intercept ( sc , vcpu , VMCB_CTRL2_INTCPT , VMCB_INTCPT_MWAIT ) ; svm_enable_intercept ( sc , vcpu , VMCB_CTRL1_INTCPT , VMCB_INTCPT_INVD ) ; svm_enable_intercept ( sc , vcpu , VMCB_CTRL1_INTCPT , VMCB_INTCPT_INVLPGA ) ; svm_enable_intercept ( sc , vcpu , VMCB_CTRL2_INTCPT , VMCB_INTCPT_VMRUN ) ; svm_enable_intercept ( sc , vcpu , VMCB_CTRL2_INTCPT , VMCB_INTCPT_VMMCALL ) ; svm_enable_intercept ( sc , vcpu , VMCB_CTRL2_INTCPT , VMCB_INTCPT_VMLOAD ) ; svm_enable_intercept ( sc , vcpu , VMCB_CTRL2_INTCPT , VMCB_INTCPT_VMSAVE ) ; svm_enable_intercept ( sc , vcpu , VMCB_CTRL2_INTCPT , VMCB_INTCPT_STGI ) ; svm_enable_intercept ( sc , vcpu , VMCB_CTRL2_INTCPT , VMCB_INTCPT_CLGI ) ; svm_enable_intercept ( sc , vcpu , VMCB_CTRL2_INTCPT , VMCB_INTCPT_SKINIT ) ; if ( vcpu_trap_wbinvd ( sc -> vm , vcpu ) != 0 ) { svm_enable_intercept ( sc , vcpu , VMCB_CTRL2_INTCPT , VMCB_INTCPT_WBINVD ) ; } ctrl -> asid = 0 ; ctrl -> v_intr_ctrl |= V_INTR_MASKING ; ctrl -> misc_ctrl |= LBR_VIRT_ENABLE ; state -> dbgctl = BIT ( 0 ) ; state -> efer = EFER_SVM ; state -> g_pat = PAT_VALUE ( 0 , PAT_WRITE_BACK ) | PAT_VALUE ( 1 , PAT_WRITE_THROUGH ) | PAT_VALUE ( 2 , PAT_UNCACHED ) | PAT_VALUE ( 3 , PAT_UNCACHEABLE ) | PAT_VALUE ( 4 , PAT_WRITE_BACK ) | PAT_VALUE ( 5 , PAT_WRITE_THROUGH ) | PAT_VALUE ( 6 , PAT_UNCACHED ) | PAT_VALUE ( 7 , PAT_UNCACHEABLE ) ; state -> dr6 = DBREG_DR6_RESERVED1 ; state -> dr7 = DBREG_DR7_RESERVED1 ; } 