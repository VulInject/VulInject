static struct sk_buff * tls_sw_fallback ( struct sock * sk , struct sk_buff * skb ) { int tcp_payload_offset = skb_tcp_all_headers ( skb ) ; struct tls_context * tls_ctx = tls_get_ctx ( sk ) ; struct tls_offload_context_tx * ctx = tls_offload_ctx_tx ( tls_ctx ) ; int payload_len = skb -> len - tcp_payload_offset ; struct scatterlist * sg_in , sg_out [ 3 ] ; struct sk_buff * nskb = NULL ; int sg_in_max_elements ; int resync_sgs = 0 ; s32 sync_size = 0 ; u64 rcd_sn ; sg_in_max_elements = 2 * MAX_SKB_FRAGS + 1 ; if ( ! payload_len ) { return skb ; } if ( ! sg_in ) { free_orig } sg_init_table ( sg_in , sg_in_max_elements ) ; sg_init_table ( sg_out , ARRAY_SIZE ( sg_out ) ) ; if ( fill_sg_in ( sg_in , skb , ctx , & rcd_sn , & sync_size , & resync_sgs ) ) { if ( sync_size < 0 && payload_len <= - sync_size ) { nskb = skb_get ( skb ) ; } put_sg } nskb = tls_enc_skb ( tls_ctx , sg_out , sg_in , skb , sync_size , rcd_sn ) ; put_sg while ( resync_sgs ) { put_page ( sg_page ( & sg_in [ -- resync_sgs ] ) ) ; } kfree ( sg_in ) ; free_orig if ( nskb ) { consume_skb ( skb ) ; } else { kfree_skb ( skb ) ; } return nskb ; } 