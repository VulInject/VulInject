static void virtio_transport_send_pkt_work ( struct work_struct * work ) { struct virtio_vsock * vsock = container_of ( work , virtio_vsock , send_pkt_work ) ; struct virtqueue * vq ; bool added = false ; bool restart_rx = false ; mutex_lock ( & vsock -> tx_lock ) ; vq = vsock -> vqs [ VSOCK_VQ_TX ] ; for ( ; ; ) { struct virtio_vsock_pkt * pkt ; struct scatterlist hdr , buf , * sgs [ 2 ] ; int ret , in_sg = 0 , out_sg = 0 ; bool reply ; spin_lock_bh ( & vsock -> send_pkt_list_lock ) ; if ( list_empty ( & vsock -> send_pkt_list ) ) { spin_unlock_bh ( & vsock -> send_pkt_list_lock ) ; break ; } pkt = list_first_entry ( & vsock -> send_pkt_list , virtio_vsock_pkt , list ) ; list_del_init ( & pkt -> list ) ; spin_unlock_bh ( & vsock -> send_pkt_list_lock ) ; virtio_transport_deliver_tap_pkt ( pkt ) ; reply = pkt -> reply ; sg_init_one ( & hdr , & pkt -> hdr , sizeof ( pkt -> hdr ) ) ; sgs [ out_sg ++ ] = & hdr ; if ( pkt -> buf ) { sg_init_one ( & buf , pkt -> buf , pkt -> len ) ; sgs [ out_sg ++ ] = & buf ; } ret = virtqueue_add_sgs ( vq , sgs , out_sg , in_sg , pkt , GFP_KERNEL ) ; if ( ret < 0 ) { spin_lock_bh ( & vsock -> send_pkt_list_lock ) ; list_add ( & pkt -> list , & vsock -> send_pkt_list ) ; spin_unlock_bh ( & vsock -> send_pkt_list_lock ) ; break ; } if ( reply ) { struct virtqueue * rx_vq = vsock -> vqs [ VSOCK_VQ_RX ] ; int val ; val = atomic_dec_return ( & vsock -> queued_replies ) ; if ( val + 1 == virtqueue_get_vring_size ( rx_vq ) ) { restart_rx = true ; } } added = true ; } if ( added ) { virtqueue_kick ( vq ) ; } if ( restart_rx ) { queue_work ( virtio_vsock_workqueue , & vsock -> rx_work ) ; } } 