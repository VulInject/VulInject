static void ops_run_reconstruct6 ( struct stripe_head * sh , struct raid5_percpu * percpu , struct dma_async_tx_descriptor * tx ) { struct async_submit_ctl submit ; struct page * * blocks ; int count , i , j = 0 ; struct stripe_head * head_sh = sh ; int last_stripe ; int synflags ; unsigned long txflags ; pr_debug ( "%s: stripe %llu\n" , __func__ , ( unsigned long long ) sh -> sector ) ; for ( i = 0 ; i < sh -> disks ; i ++ ) { if ( sh -> pd_idx == i || sh -> qd_idx == i ) { continue ; } if ( ! test_bit ( R5_Discard , & sh -> dev [ i ] . flags ) ) { break ; } } again blocks = to_addr_page ( percpu , j ) ; if ( sh -> reconstruct_state == reconstruct_state_prexor_drain_run ) { synflags = SYNDROME_SRC_WRITTEN ; txflags = ASYNC_TX_ACK | ASYNC_TX_PQ_XOR_DST ; } else { synflags = SYNDROME_SRC_ALL ; txflags = ASYNC_TX_ACK ; } count = set_syndrome_sources ( blocks , sh , synflags ) ; last_stripe = ! head_sh -> batch_head || list_first_entry ( & sh -> batch_list , stripe_head , batch_list ) == head_sh ; if ( last_stripe ) { atomic_inc ( & head_sh -> count ) ; init_async_submit ( & submit , txflags , tx , ops_complete_reconstruct , head_sh , to_addr_conv ( sh , percpu , j ) ) ; } else { init_async_submit ( & submit , 0 , tx , NULL , NULL , to_addr_conv ( sh , percpu , j ) ) ; } tx = async_gen_syndrome ( blocks , 0 , count + 2 , STRIPE_SIZE , & submit ) ; if ( ! last_stripe ) { j ++ ; sh = list_first_entry ( & sh -> batch_list , stripe_head , batch_list ) ; again } } 