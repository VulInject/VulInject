void libxsmm_generator_packed_gemm_bc_rm_aarch64 ( libxsmm_generated_code * io_generated_code , const libxsmm_gemm_descriptor * i_xgemm_desc , const unsigned int i_packed_width ) { unsigned int l_max_reg_block = 0 ; unsigned int l_n1_range = 0 ; unsigned int l_n2_range = 0 ; unsigned int l_n1_block = 0 ; unsigned int l_n2_block = 0 ; libxsmm_micro_kernel_config l_micro_kernel_config ; libxsmm_loop_label_tracker l_loop_label_tracker ; libxsmm_gp_reg_mapping l_gp_reg_mapping ; l_max_reg_block = 28 ; l_gp_reg_mapping . gp_reg_param_struct = LIBXSMM_AARCH64_GP_REG_X0 ; l_gp_reg_mapping . gp_reg_a = LIBXSMM_AARCH64_GP_REG_X0 ; l_gp_reg_mapping . gp_reg_b = LIBXSMM_AARCH64_GP_REG_X1 ; l_gp_reg_mapping . gp_reg_c = LIBXSMM_AARCH64_GP_REG_X2 ; l_gp_reg_mapping . gp_reg_a_prefetch = LIBXSMM_AARCH64_GP_REG_X3 ; l_gp_reg_mapping . gp_reg_b_prefetch = LIBXSMM_AARCH64_GP_REG_X4 ; l_gp_reg_mapping . gp_reg_mloop = LIBXSMM_AARCH64_GP_REG_X6 ; l_gp_reg_mapping . gp_reg_nloop = LIBXSMM_AARCH64_GP_REG_X7 ; l_gp_reg_mapping . gp_reg_kloop = LIBXSMM_AARCH64_GP_REG_X8 ; l_gp_reg_mapping . gp_reg_help_0 = LIBXSMM_AARCH64_GP_REG_X9 ; l_gp_reg_mapping . gp_reg_help_1 = LIBXSMM_AARCH64_GP_REG_X10 ; l_gp_reg_mapping . gp_reg_help_2 = LIBXSMM_AARCH64_GP_REG_X11 ; l_gp_reg_mapping . gp_reg_help_3 = LIBXSMM_AARCH64_GP_REG_X12 ; l_gp_reg_mapping . gp_reg_help_4 = LIBXSMM_AARCH64_GP_REG_UNDEF ; l_gp_reg_mapping . gp_reg_help_5 = LIBXSMM_AARCH64_GP_REG_UNDEF ; libxsmm_reset_loop_label_tracker ( & l_loop_label_tracker ) ; libxsmm_generator_gemm_init_micro_kernel_config_aarch64 ( & l_micro_kernel_config , io_generated_code -> arch , i_xgemm_desc ) ; if ( libxsmm_compute_equalized_blocking ( i_xgemm_desc -> n , l_max_reg_block , & l_n1_range , & l_n1_block , & l_n2_range , & l_n2_block ) ) { LIBXSMM_HANDLE_ERROR ( io_generated_code , LIBXSMM_ERR_N_BLOCK ) ; return ; } libxsmm_aarch64_instruction_open_stream ( io_generated_code , 0xf ) ; if ( ( ( LIBXSMM_GEMM_FLAG_USE_XGEMM_ABI & i_xgemm_desc -> flags ) == LIBXSMM_GEMM_FLAG_USE_XGEMM_ABI ) ) { libxsmm_aarch64_instruction_alu_compute_shifted_reg ( io_generated_code , LIBXSMM_AARCH64_INSTR_GP_AND_SR , l_gp_reg_mapping . gp_reg_param_struct , l_gp_reg_mapping . gp_reg_param_struct , l_gp_reg_mapping . gp_reg_help_1 , 0 , LIBXSMM_AARCH64_SHIFTMODE_LSL ) ; libxsmm_aarch64_instruction_alu_move ( io_generated_code , LIBXSMM_AARCH64_INSTR_GP_LDR_I_OFF , l_gp_reg_mapping . gp_reg_help_1 , LIBXSMM_AARCH64_GP_REG_UNDEF , 32 , l_gp_reg_mapping . gp_reg_a ) ; libxsmm_aarch64_instruction_alu_move ( io_generated_code , LIBXSMM_AARCH64_INSTR_GP_LDR_I_OFF , l_gp_reg_mapping . gp_reg_help_1 , LIBXSMM_AARCH64_GP_REG_UNDEF , 64 , l_gp_reg_mapping . gp_reg_b ) ; libxsmm_aarch64_instruction_alu_move ( io_generated_code , LIBXSMM_AARCH64_INSTR_GP_LDR_I_OFF , l_gp_reg_mapping . gp_reg_help_1 , LIBXSMM_AARCH64_GP_REG_UNDEF , 96 , l_gp_reg_mapping . gp_reg_c ) ; if ( i_xgemm_desc -> prefetch != LIBXSMM_GEMM_PREFETCH_NONE ) { libxsmm_aarch64_instruction_alu_move ( io_generated_code , LIBXSMM_AARCH64_INSTR_GP_LDR_I_OFF , l_gp_reg_mapping . gp_reg_help_1 , LIBXSMM_AARCH64_GP_REG_UNDEF , 56 , l_gp_reg_mapping . gp_reg_a_prefetch ) ; libxsmm_aarch64_instruction_alu_move ( io_generated_code , LIBXSMM_AARCH64_INSTR_GP_LDR_I_OFF , l_gp_reg_mapping . gp_reg_help_1 , LIBXSMM_AARCH64_GP_REG_UNDEF , 88 , l_gp_reg_mapping . gp_reg_b_prefetch ) ; } } else { LIBXSMM_HANDLE_ERROR ( io_generated_code , LIBXSMM_ERR_ILLEGAL_ABI ) ; return ; } if ( ( io_generated_code -> arch >= LIBXSMM_AARCH64_SVE128 ) && ( io_generated_code -> arch <= LIBXSMM_AARCH64_ALLFEAT ) ) { libxsmm_generator_set_p_register_aarch64_sve ( io_generated_code , LIBXSMM_AARCH64_SVE_REG_P0 , - 1 , l_gp_reg_mapping . gp_reg_help_0 ) ; } libxsmm_generator_loop_header_aarch64 ( io_generated_code , & l_loop_label_tracker , l_gp_reg_mapping . gp_reg_mloop , i_xgemm_desc -> m ) ; if ( l_n1_block == i_xgemm_desc -> n ) { libxsmm_generator_packed_gemm_bc_rm_aarch64_kloop ( io_generated_code , & l_loop_label_tracker , & l_gp_reg_mapping , & l_micro_kernel_config , i_xgemm_desc , i_packed_width , i_xgemm_desc -> n ) ; } if ( ( l_n1_range > 0 ) && ( l_n2_range > 0 ) ) { libxsmm_generator_loop_header_aarch64 ( io_generated_code , & l_loop_label_tracker , l_gp_reg_mapping . gp_reg_nloop , l_n1_range ) ; libxsmm_generator_packed_gemm_bc_rm_aarch64_kloop ( io_generated_code , & l_loop_label_tracker , & l_gp_reg_mapping , & l_micro_kernel_config , i_xgemm_desc , i_packed_width , l_n1_block ) ; libxsmm_generator_loop_footer_aarch64 ( io_generated_code , & l_loop_label_tracker , l_gp_reg_mapping . gp_reg_nloop , l_n1_block ) ; libxsmm_generator_loop_header_aarch64 ( io_generated_code , & l_loop_label_tracker , l_gp_reg_mapping . gp_reg_nloop , i_xgemm_desc -> n - l_n1_range ) ; libxsmm_generator_packed_gemm_bc_rm_aarch64_kloop ( io_generated_code , & l_loop_label_tracker , & l_gp_reg_mapping , & l_micro_kernel_config , i_xgemm_desc , i_packed_width , l_n2_block ) ; libxsmm_generator_loop_footer_aarch64 ( io_generated_code , & l_loop_label_tracker , l_gp_reg_mapping . gp_reg_nloop , l_n2_block ) ; libxsmm_aarch64_instruction_alu_compute_imm64 ( io_generated_code , LIBXSMM_AARCH64_INSTR_GP_META_SUB , l_gp_reg_mapping . gp_reg_b , l_gp_reg_mapping . gp_reg_help_1 , l_gp_reg_mapping . gp_reg_b , ( long long ) i_xgemm_desc -> n * i_packed_width * l_micro_kernel_config . datatype_size_in ) ; libxsmm_aarch64_instruction_alu_compute_imm64 ( io_generated_code , LIBXSMM_AARCH64_INSTR_GP_META_SUB , l_gp_reg_mapping . gp_reg_c , l_gp_reg_mapping . gp_reg_help_2 , l_gp_reg_mapping . gp_reg_c , ( long long ) i_xgemm_desc -> n * i_packed_width * l_micro_kernel_config . datatype_size_out ) ; } if ( ( l_n1_range > 0 ) && ( l_n2_range == 0 ) ) { libxsmm_generator_loop_header_aarch64 ( io_generated_code , & l_loop_label_tracker , l_gp_reg_mapping . gp_reg_nloop , i_xgemm_desc -> n ) ; libxsmm_generator_packed_gemm_bc_rm_aarch64_kloop ( io_generated_code , & l_loop_label_tracker , & l_gp_reg_mapping , & l_micro_kernel_config , i_xgemm_desc , i_packed_width , l_n1_block ) ; libxsmm_generator_loop_footer_aarch64 ( io_generated_code , & l_loop_label_tracker , l_gp_reg_mapping . gp_reg_nloop , l_n1_block ) ; libxsmm_aarch64_instruction_alu_compute_imm64 ( io_generated_code , LIBXSMM_AARCH64_INSTR_GP_META_SUB , l_gp_reg_mapping . gp_reg_b , l_gp_reg_mapping . gp_reg_help_1 , l_gp_reg_mapping . gp_reg_b , ( long long ) i_xgemm_desc -> n * i_packed_width * l_micro_kernel_config . datatype_size_in ) ; libxsmm_aarch64_instruction_alu_compute_imm64 ( io_generated_code , LIBXSMM_AARCH64_INSTR_GP_META_SUB , l_gp_reg_mapping . gp_reg_c , l_gp_reg_mapping . gp_reg_help_2 , l_gp_reg_mapping . gp_reg_c , ( long long ) i_xgemm_desc -> n * i_packed_width * l_micro_kernel_config . datatype_size_out ) ; } else { LIBXSMM_HANDLE_ERROR ( io_generated_code , LIBXSMM_ERR_N_BLOCK ) ; return ; } libxsmm_aarch64_instruction_alu_compute_imm64 ( io_generated_code , LIBXSMM_AARCH64_INSTR_GP_META_ADD , l_gp_reg_mapping . gp_reg_a , l_gp_reg_mapping . gp_reg_help_0 , l_gp_reg_mapping . gp_reg_a , ( long long ) l_micro_kernel_config . datatype_size_in * i_xgemm_desc -> lda ) ; libxsmm_aarch64_instruction_alu_compute_imm64 ( io_generated_code , LIBXSMM_AARCH64_INSTR_GP_META_ADD , l_gp_reg_mapping . gp_reg_c , l_gp_reg_mapping . gp_reg_help_2 , l_gp_reg_mapping . gp_reg_c , ( long long ) l_micro_kernel_config . datatype_size_out * i_packed_width * i_xgemm_desc -> ldc ) ; libxsmm_generator_loop_footer_aarch64 ( io_generated_code , & l_loop_label_tracker , l_gp_reg_mapping . gp_reg_mloop , 1 ) ; libxsmm_aarch64_instruction_close_stream ( io_generated_code , 0xf ) ; } 