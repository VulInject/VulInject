static struct dma_async_tx_descriptor * sirfsoc_dma_prep_interleaved ( struct dma_chan * chan , struct dma_interleaved_template * xt , unsigned long flags ) { struct sirfsoc_dma * sdma = dma_chan_to_sirfsoc_dma ( chan ) ; struct sirfsoc_dma_chan * schan = dma_chan_to_sirfsoc_dma_chan ( chan ) ; struct sirfsoc_dma_desc * sdesc = NULL ; unsigned long iflags ; int ret ; if ( ( xt -> dir != DMA_MEM_TO_DEV ) && ( xt -> dir != DMA_DEV_TO_MEM ) ) { ret = - EINVAL ; err_dir } spin_lock_irqsave ( & schan -> lock , iflags ) ; if ( ! list_empty ( & schan -> free ) ) { sdesc = list_first_entry ( & schan -> free , sirfsoc_dma_desc , node ) ; list_del ( & sdesc -> node ) ; } spin_unlock_irqrestore ( & schan -> lock , iflags ) ; if ( ! sdesc ) { sirfsoc_dma_process_completed ( sdma ) ; ret = 0 ; no_desc } spin_lock_irqsave ( & schan -> lock , iflags ) ; if ( ( xt -> frame_size == 1 ) && ( xt -> numf > 0 ) ) { sdesc -> cyclic = 0 ; sdesc -> xlen = xt -> sgl [ 0 ] . size / SIRFSOC_DMA_WORD_LEN ; sdesc -> width = ( xt -> sgl [ 0 ] . size + xt -> sgl [ 0 ] . icg ) / SIRFSOC_DMA_WORD_LEN ; sdesc -> ylen = xt -> numf - 1 ; else { sdesc -> addr = xt -> dst_start ; sdesc -> dir = 0 ; } list_add_tail ( & sdesc -> node , & schan -> prepared ) ; } else { pr_err ( "sirfsoc DMA Invalid xfer\n" ) ; ret = - EINVAL ; err_xfer } spin_unlock_irqrestore ( & schan -> lock , iflags ) ; return & sdesc -> desc ; err_xfer spin_unlock_irqrestore ( & schan -> lock , iflags ) ; no_desc err_dir return ERR_PTR ( ret ) ; } 