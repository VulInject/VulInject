void tee_pager_add_pages ( vaddr_t vaddr , size_t npages , bool unmap ) { size_t n = 0 ; DMSG ( "0x%" PRIxVA " - 0x%" PRIxVA " : %d" , vaddr , vaddr + npages * SMALL_PAGE_SIZE , ( int ) unmap ) ; for ( n = 0 ; n < npages ; n ++ ) { struct core_mmu_table_info * ti = NULL ; struct tee_pager_pmem * pmem = NULL ; vaddr_t va = vaddr + n * SMALL_PAGE_SIZE ; struct tblidx tblidx = { } ; unsigned int pgidx = 0 ; paddr_t pa = 0 ; uint32_t attr = 0 ; ti = find_table_info ( va ) ; pgidx = core_mmu_va2idx ( ti , va ) ; core_mmu_get_entry ( ti , pgidx , & pa , & attr ) ; pmem = calloc ( 1 , sizeof ( tee_pager_pmem ) ) ; if ( ! pmem ) { panic ( "out of mem" ) ; } pmem_clear ( pmem ) ; pmem -> va_alias = pager_add_alias_page ( pa ) ; if ( unmap ) { core_mmu_set_entry ( ti , pgidx , 0 , 0 ) ; pgt_dec_used_entries ( find_core_pgt ( va ) ) ; } else { struct vm_paged_region * reg = NULL ; reg = find_region ( & core_vm_regions , va ) ; assert ( reg ) ; pmem_assign_fobj_page ( pmem , reg , va ) ; tblidx = pmem_get_region_tblidx ( pmem , reg ) ; assert ( tblidx . pgt == find_core_pgt ( va ) ) ; assert ( pa == get_pmem_pa ( pmem ) ) ; tblidx_set_entry ( tblidx , pa , get_region_mattr ( reg -> flags ) ) ; } if ( unmap && IS_ENABLED ( CFG_CORE_PAGE_TAG_AND_IV ) && ! pager_spare_pmem ) { pager_spare_pmem = pmem ; } else { tee_pager_npages ++ ; incr_npages_all ( ) ; set_npages ( ) ; TAILQ_INSERT_TAIL ( & tee_pager_pmem_head , pmem , link ) ; } } tlbi_all ( ) ; } 