static bool virtio_poll_done ( struct scmi_chan_info * cinfo , struct scmi_xfer * xfer ) { bool pending , found = false ; unsigned int length , any_prefetched ; unsigned long flags ; struct scmi_vio_msg * next_msg , * msg = xfer -> priv ; struct scmi_vio_channel * vioch = cinfo -> transport_info ; if ( ! msg ) { return true ; } if ( msg -> poll_status == VIO_MSG_POLL_DONE ) { return true ; } if ( ! scmi_vio_channel_acquire ( vioch ) ) { return true ; } pending = virtqueue_poll ( vioch -> vqueue , msg -> poll_idx ) ; if ( ! pending ) { scmi_vio_channel_release ( vioch ) ; return false ; } spin_lock_irqsave ( & vioch -> lock , flags ) ; virtqueue_disable_cb ( vioch -> vqueue ) ; while ( ( next_msg = virtqueue_get_buf ( vioch -> vqueue , & length ) ) ) { bool next_msg_done = false ; spin_lock ( & next_msg -> poll_lock ) ; if ( next_msg -> poll_status == VIO_MSG_POLLING ) { next_msg -> poll_status = VIO_MSG_POLL_DONE ; next_msg_done = true ; } spin_unlock ( & next_msg -> poll_lock ) ; next_msg -> rx_len = length ; if ( next_msg == msg ) { found = true ; break ; } if ( next_msg_done ) { continue ; } spin_lock ( & next_msg -> poll_lock ) ; if ( next_msg -> poll_status == VIO_MSG_NOT_POLLED || next_msg -> poll_status == VIO_MSG_POLL_TIMEOUT ) { spin_unlock ( & next_msg -> poll_lock ) ; any_prefetched ++ ; spin_lock ( & vioch -> pending_lock ) ; list_add_tail ( & next_msg -> list , & vioch -> pending_cmds_list ) ; spin_unlock ( & vioch -> pending_lock ) ; } else { spin_unlock ( & next_msg -> poll_lock ) ; } } if ( found ) { pending = ! virtqueue_enable_cb ( vioch -> vqueue ) ; } else { msg -> poll_idx = virtqueue_enable_cb_prepare ( vioch -> vqueue ) ; pending = virtqueue_poll ( vioch -> vqueue , msg -> poll_idx ) ; } if ( vioch -> deferred_tx_wq && ( any_prefetched || pending ) ) { queue_work ( vioch -> deferred_tx_wq , & vioch -> deferred_tx_work ) ; } spin_unlock_irqrestore ( & vioch -> lock , flags ) ; scmi_vio_channel_release ( vioch ) ; return found ; } 