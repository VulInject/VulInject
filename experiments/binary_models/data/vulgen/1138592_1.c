static bool netsec_clean_tx_dring ( struct netsec_priv * priv ) { struct netsec_desc_ring * dring = & priv -> desc_ring [ NETSEC_RING_TX ] ; struct xdp_frame_bulk bq ; struct netsec_de * entry ; int tail = dring -> tail ; unsigned int bytes ; int cnt = 0 ; spin_lock ( & dring -> lock ) ; bytes = 0 ; xdp_frame_bulk_init ( & bq ) ; entry = dring -> vaddr + DESC_SZ * tail ; rcu_read_lock ( ) ; while ( ! ( entry -> attr & ( 1U << NETSEC_TX_SHIFT_OWN_FIELD ) ) && cnt < DESC_NUM ) { struct netsec_desc * desc ; int eop ; desc = & dring -> desc [ tail ] ; eop = ( entry -> attr >> NETSEC_TX_LAST ) & 1 ; dma_rmb ( ) ; if ( ! eop ) { next } if ( desc -> buf_type == TYPE_NETSEC_SKB ) { bytes += desc -> skb -> len ; dev_kfree_skb ( desc -> skb ) ; } else { bytes += desc -> xdpf -> len ; if ( desc -> buf_type == TYPE_NETSEC_XDP_TX ) { xdp_return_frame_rx_napi ( desc -> xdpf ) ; } else { xdp_return_frame_bulk ( desc -> xdpf , & bq ) ; } } next * desc = ( netsec_desc ) { } ; entry -> attr = 1U << NETSEC_TX_SHIFT_OWN_FIELD ; dring -> tail = ( tail + 1 ) % DESC_NUM ; tail = dring -> tail ; entry = dring -> vaddr + DESC_SZ * tail ; cnt ++ ; } xdp_flush_frame_bulk ( & bq ) ; rcu_read_unlock ( ) ; spin_unlock ( & dring -> lock ) ; if ( ! cnt ) { return false ; } netsec_read ( priv , NETSEC_REG_NRM_TX_DONE_PKTCNT ) ; priv -> ndev -> stats . tx_packets += cnt ; priv -> ndev -> stats . tx_bytes += bytes ; netdev_completed_queue ( priv -> ndev , cnt , bytes ) ; return true ; } 