struct dma_fence * etnaviv_gpu_submit ( struct etnaviv_gem_submit * submit ) { struct etnaviv_gpu * gpu = submit -> gpu ; struct dma_fence * gpu_fence ; unsigned int i , nr_events = 1 , event [ 3 ] ; int ret ; if ( ! submit -> runtime_resumed ) { ret = pm_runtime_get_sync ( gpu -> dev ) ; if ( ret < 0 ) { pm_runtime_put_noidle ( gpu -> dev ) ; return NULL ; } submit -> runtime_resumed = true ; } if ( submit -> nr_pmrs ) { nr_events = 3 ; } ret = event_alloc ( gpu , nr_events , event ) ; if ( ret ) { DRM_ERROR ( "no free events\n" ) ; pm_runtime_put_noidle ( gpu -> dev ) ; return NULL ; } mutex_lock ( & gpu -> lock ) ; gpu_fence = etnaviv_gpu_fence_alloc ( gpu ) ; if ( ! gpu_fence ) { for ( i = 0 ; i < nr_events ; i ++ ) { event_free ( gpu , event [ i ] ) ; } out_unlock } if ( ! gpu -> fe_running ) { etnaviv_gpu_start_fe_idleloop ( gpu , submit -> mmu_context ) ; } if ( submit -> prev_mmu_context ) { etnaviv_iommu_context_put ( submit -> prev_mmu_context ) ; } submit -> prev_mmu_context = etnaviv_iommu_context_get ( gpu -> mmu_context ) ; if ( submit -> nr_pmrs ) { gpu -> event [ event [ 1 ] ] . sync_point = & sync_point_perfmon_sample_pre ; gpu -> event [ event [ 1 ] ] . submit = submit ; etnaviv_sync_point_queue ( gpu , event [ 1 ] ) ; } gpu -> event [ event [ 0 ] ] . fence = gpu_fence ; submit -> cmdbuf . user_size = submit -> cmdbuf . size - 8 ; etnaviv_buffer_queue ( gpu , submit -> exec_state , submit -> mmu_context , event [ 0 ] , & submit -> cmdbuf ) ; if ( submit -> nr_pmrs ) { gpu -> event [ event [ 2 ] ] . sync_point = & sync_point_perfmon_sample_post ; kref_get ( & submit -> refcount ) ; gpu -> event [ event [ 2 ] ] . submit = submit ; etnaviv_sync_point_queue ( gpu , event [ 2 ] ) ; } out_unlock mutex_unlock ( & gpu -> lock ) ; return gpu_fence ; } 