static ssize_t goldfish_pipe_read_write ( struct file * filp , char __user * buffer , size_t bufflen , int is_write ) { struct goldfish_pipe * pipe = filp -> private_data ; int count = 0 , ret = - EINVAL ; unsigned long address , address_end , last_page ; unsigned int last_page_size ; if ( unlikely ( test_bit ( BIT_CLOSED_ON_HOST , & pipe -> flags ) ) ) { return - EIO ; } if ( unlikely ( ! access_ok ( is_write ?VERIFY_WRITE : VERIFY_READ , buffer , bufflen ) ) ) { return - EFAULT ; } address = ( unsigned long ) buffer ; address_end = address + bufflen ; last_page = ( address_end - 1 ) & PAGE_MASK ; last_page_size = ( ( address_end - 1 ) & ~ PAGE_MASK ) + 1 ; while ( address < address_end ) { s32 consumed_size ; int status ; ret = transfer_max_buffers ( pipe , address , address_end , is_write , last_page , last_page_size , & consumed_size , & status ) ; if ( ret < 0 ) { break ; } if ( consumed_size > 0 ) { count += consumed_size ; address += consumed_size ; } if ( status > 0 ) { continue ; } if ( status == 0 ) { ret = 0 ; break ; } if ( count > 0 ) { if ( status != PIPE_ERROR_AGAIN ) { pr_info_ratelimited ( "goldfish_pipe: backend error %d on %s\n" , status , is_write ?"write" : "read" ) ; } break ; } if ( status != PIPE_ERROR_AGAIN || ( filp -> f_flags & O_NONBLOCK ) != 0 ) { ret = goldfish_pipe_error_convert ( status ) ; break ; } status = wait_for_host_signal ( pipe , is_write ) ; if ( status < 0 ) { return status ; } } if ( count > 0 ) { return count ; } return ret ; } 