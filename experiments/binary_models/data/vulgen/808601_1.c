void libxsmm_generator_spgemm_csr_asparse_reg_aarch64_neon ( libxsmm_generated_code * io_generated_code , const libxsmm_gemm_descriptor * i_xgemm_desc , const unsigned int * i_row_idx , const unsigned int * i_column_idx , const double * i_values ) { unsigned int l_n , l_z ; unsigned int l_unique , l_uoff ; unsigned int l_m_blocking , l_n_blocking ; unsigned int l_n_row_idx = i_row_idx [ i_xgemm_desc -> m ] ; double * const l_unique_values = ( double * ) ( 0 != l_n_row_idx ?malloc ( sizeof ( double ) * l_n_row_idx ) : NULL ) ; unsigned int * const l_unique_pos = ( unsigned int * ) ( 0 != l_n_row_idx ?malloc ( ( unsigned int ) * l_n_row_idx ) : NULL ) ; int * const l_unique_sgn = ( int * ) ( 0 != l_n_row_idx ?malloc ( sizeof ( int ) * l_n_row_idx ) : NULL ) ; const unsigned int l_fp64 = LIBXSMM_DATATYPE_F64 == LIBXSMM_GETENUM_INP ( i_xgemm_desc -> datatype ) ; unsigned int l_reg_unique , l_base_c_reg , l_base_c_gp_reg , l_base_ld_reg ; int l_curr_b_disp = 0 , l_curr_rvb_disp = - 1 ; unsigned int l_bcast_reg_vals [ 120 ] , l_nbcast_vals = 0 ; const libxsmm_aarch64_asimd_tupletype l_tuplet = ( l_fp64 ) ?LIBXSMM_AARCH64_ASIMD_TUPLETYPE_2D : LIBXSMM_AARCH64_ASIMD_TUPLETYPE_4S ; const libxsmm_aarch64_asimd_width l_width = ( l_fp64 ) ?LIBXSMM_AARCH64_ASIMD_WIDTH_D : LIBXSMM_AARCH64_ASIMD_WIDTH_S ; const unsigned int l_values_per_reg = ( l_fp64 ) ?2 : 4 ; const unsigned int l_fbytes = ( l_fp64 ) ?8 : 4 ; const unsigned int l_c_is_nt = ( ( LIBXSMM_GEMM_FLAG_ALIGN_C_NTS_HINT == ( LIBXSMM_GEMM_FLAG_ALIGN_C_NTS_HINT & i_xgemm_desc -> flags ) && 0 == ( i_xgemm_desc -> ldc % l_values_per_reg ) ) ?1 : 0 ) ; const unsigned int l_beta0 = LIBXSMM_GEMM_FLAG_BETA_0 & i_xgemm_desc -> flags ; libxsmm_asparse_reg_op * l_ops = ( libxsmm_asparse_reg_op * ) malloc ( sizeof ( libxsmm_asparse_reg_op ) * LIBXSMM_ASPARSE_REG_MAX_OPS ) ; unsigned int l_n_ops , l_op_idx ; libxsmm_loop_label_tracker l_loop_label_tracker ; libxsmm_const_data_tracker l_const_data_tracker ; libxsmm_gp_reg_mapping l_gp_reg_mapping ; if ( 0 == l_unique_values || 0 == l_unique_pos || 0 == l_unique_sgn || 0 == l_ops ) { LIBXSMM_HANDLE_ERROR ( io_generated_code , LIBXSMM_ERR_CSR_ALLOC_DATA ) ; cleanup } if ( i_xgemm_desc -> n == l_values_per_reg ) { l_n_blocking = 1 ; } if ( i_xgemm_desc -> n == 2 * l_values_per_reg ) { l_n_blocking = 2 ; } if ( i_xgemm_desc -> n == 4 * l_values_per_reg ) { l_n_blocking = 4 ; } else { LIBXSMM_HANDLE_ERROR ( io_generated_code , LIBXSMM_ERR_N_BLOCK ) ; cleanup } l_reg_unique = l_values_per_reg * ( 32 - l_n_blocking - ( ( l_n_blocking > 1 ) ?2 : 1 ) ) ; LIBXSMM_ASSERT ( 0 != i_values ) ; libxsmm_analyse_sparse_nnz ( l_n_row_idx , i_values , & l_unique , l_unique_values , l_unique_pos , l_unique_sgn ) ; if ( l_unique > 1280 ) { LIBXSMM_HANDLE_ERROR ( io_generated_code , LIBXSMM_ERR_UNIQUE_VAL ) ; cleanup } if ( ! l_fp64 ) { for ( l_z = 0 ; l_z < l_unique ; l_z ++ ) { float l_fval = ( float ) l_unique_values [ l_z ] ; memcpy ( ( ( float * ) l_unique_values ) + l_z , & l_fval , sizeof ( l_fval ) ) ; } } if ( l_unique <= l_reg_unique ) { l_base_ld_reg = LIBXSMM_UPDIV ( l_unique , l_values_per_reg ) ; l_base_c_reg = l_base_ld_reg + ( ( l_n_blocking > 1 ) ?2 : 1 ) ; l_base_c_gp_reg = LIBXSMM_AARCH64_GP_REG_X12 ; if ( l_base_c_reg + 4 * l_n_blocking <= 32 ) { l_m_blocking = 4 ; } if ( l_base_c_reg + 2 * l_n_blocking <= 32 ) { l_m_blocking = 2 ; } else { l_m_blocking = 1 ; } } else { l_m_blocking = 4 ; l_base_c_gp_reg = LIBXSMM_AARCH64_GP_REG_X12 ; l_base_c_reg = 32 - l_m_blocking * l_n_blocking ; l_base_ld_reg = l_base_c_reg - ( ( l_n_blocking > 1 ) ?2 : 1 ) ; l_nbcast_vals = l_base_ld_reg * l_values_per_reg ; } libxsmm_asparse_reg_sequence ( i_xgemm_desc -> m , l_m_blocking , i_row_idx , i_column_idx , l_unique_pos , l_unique_sgn , LIBXSMM_ASPARSE_REG_MAX_OPS , l_ops , & l_n_ops ) ; if ( 0 == l_n_ops ) { LIBXSMM_HANDLE_ERROR ( io_generated_code , LIBXSMM_ERR_ARCH ) ; cleanup } libxsmm_reset_aarch64_gp_reg_mapping ( & l_gp_reg_mapping ) ; l_gp_reg_mapping . gp_reg_param_struct = LIBXSMM_AARCH64_GP_REG_X0 ; l_gp_reg_mapping . gp_reg_b = LIBXSMM_AARCH64_GP_REG_X1 ; l_gp_reg_mapping . gp_reg_c = LIBXSMM_AARCH64_GP_REG_X2 ; l_gp_reg_mapping . gp_reg_help_0 = LIBXSMM_AARCH64_GP_REG_X24 ; l_gp_reg_mapping . gp_reg_help_1 = LIBXSMM_AARCH64_GP_REG_X25 ; memset ( l_bcast_reg_vals , ~ 0 , sizeof ( l_bcast_reg_vals ) ) ; libxsmm_reset_const_data_tracker ( & l_const_data_tracker ) ; libxsmm_reset_loop_label_tracker ( & l_loop_label_tracker ) ; libxsmm_aarch64_instruction_open_stream ( io_generated_code , 0xfff ) ; if ( ( ( LIBXSMM_GEMM_FLAG_USE_XGEMM_ABI & i_xgemm_desc -> flags ) == LIBXSMM_GEMM_FLAG_USE_XGEMM_ABI ) ) { libxsmm_aarch64_instruction_alu_compute_shifted_reg ( io_generated_code , LIBXSMM_AARCH64_INSTR_GP_AND_SR , l_gp_reg_mapping . gp_reg_param_struct , l_gp_reg_mapping . gp_reg_param_struct , l_gp_reg_mapping . gp_reg_help_1 , 0 , LIBXSMM_AARCH64_SHIFTMODE_LSL ) ; libxsmm_aarch64_instruction_alu_move ( io_generated_code , LIBXSMM_AARCH64_INSTR_GP_LDR_I_OFF , l_gp_reg_mapping . gp_reg_help_1 , LIBXSMM_AARCH64_GP_REG_UNDEF , 64 , l_gp_reg_mapping . gp_reg_b ) ; libxsmm_aarch64_instruction_alu_move ( io_generated_code , LIBXSMM_AARCH64_INSTR_GP_LDR_I_OFF , l_gp_reg_mapping . gp_reg_help_1 , LIBXSMM_AARCH64_GP_REG_UNDEF , 96 , l_gp_reg_mapping . gp_reg_c ) ; if ( i_xgemm_desc -> prefetch != LIBXSMM_GEMM_PREFETCH_NONE ) { libxsmm_aarch64_instruction_alu_move ( io_generated_code , LIBXSMM_AARCH64_INSTR_GP_LDR_I_OFF , l_gp_reg_mapping . gp_reg_help_1 , LIBXSMM_AARCH64_GP_REG_UNDEF , 56 , l_gp_reg_mapping . gp_reg_a_prefetch ) ; libxsmm_aarch64_instruction_alu_move ( io_generated_code , LIBXSMM_AARCH64_INSTR_GP_LDR_I_OFF , l_gp_reg_mapping . gp_reg_help_1 , LIBXSMM_AARCH64_GP_REG_UNDEF , 88 , l_gp_reg_mapping . gp_reg_b_prefetch ) ; } } else { LIBXSMM_HANDLE_ERROR ( io_generated_code , LIBXSMM_ERR_ILLEGAL_ABI ) ; return ; } if ( l_unique <= l_reg_unique ) { l_uoff = libxsmm_aarch64_instruction_add_data ( io_generated_code , ( unsigned char * ) l_unique_values , l_unique * l_fbytes , 16 , 1 , & l_const_data_tracker ) ; if ( ( l_unique * l_fbytes ) % 16 != 0 ) { unsigned char l_pad [ 15 ] { 0 } ; ; libxsmm_aarch64_instruction_add_data ( io_generated_code , l_pad , ( l_unique * l_fbytes ) % 16 , 1 , 1 , & l_const_data_tracker ) ; } libxsmm_aarch64_instruction_adr_data ( io_generated_code , l_gp_reg_mapping . gp_reg_help_0 , l_uoff , & l_const_data_tracker ) ; if ( ( l_base_ld_reg % 2 ) != 0 ) { libxsmm_aarch64_instruction_asimd_move ( io_generated_code , LIBXSMM_AARCH64_INSTR_ASIMD_LDR_I_OFF , l_gp_reg_mapping . gp_reg_help_0 , 0 , 0 , 0 , LIBXSMM_AARCH64_ASIMD_WIDTH_Q ) ; } for ( l_z = l_base_ld_reg % 2 ; l_z < l_base_ld_reg ; l_z += 2 ) { libxsmm_aarch64_instruction_asimd_pair_move ( io_generated_code , LIBXSMM_AARCH64_INSTR_ASIMD_LDP_I_OFF , l_gp_reg_mapping . gp_reg_help_0 , 16 * l_z , l_z , l_z + 1 , LIBXSMM_AARCH64_ASIMD_WIDTH_Q ) ; } } libxsmm_generator_loop_header_aarch64 ( io_generated_code , & l_loop_label_tracker , LIBXSMM_AARCH64_GP_REG_X23 , ( unsigned int ) i_xgemm_desc -> c1 ) ; if ( l_unique > l_reg_unique ) { libxsmm_aarch64_instruction_adr_data ( io_generated_code , LIBXSMM_AARCH64_GP_REG_X26 , 0 , & l_const_data_tracker ) ; } libxsmm_generator_mov_aarch64 ( io_generated_code , l_gp_reg_mapping . gp_reg_b , l_gp_reg_mapping . gp_reg_help_1 ) ; for ( l_op_idx = 0 ; l_op_idx < l_n_ops ; l_op_idx ++ ) { libxsmm_asparse_reg_op op = l_ops [ l_op_idx ] ; unsigned int l_rvb = l_base_ld_reg ; int l_b_disp = op . b_disp * i_xgemm_desc -> ldb * l_fbytes ; if ( l_b_disp != l_curr_b_disp ) { unsigned int l_disp_insn = ( l_b_disp > l_curr_b_disp ) ?LIBXSMM_AARCH64_INSTR_GP_META_ADD : LIBXSMM_AARCH64_INSTR_GP_META_SUB ; libxsmm_aarch64_instruction_alu_compute_imm64 ( io_generated_code , l_disp_insn , l_gp_reg_mapping . gp_reg_help_1 , l_gp_reg_mapping . gp_reg_help_0 , l_gp_reg_mapping . gp_reg_help_1 , LIBXSMM_DELTA ( l_b_disp , l_curr_b_disp ) ) ; l_curr_b_disp = l_b_disp ; } if ( 1 == l_n_blocking ) { if ( l_curr_rvb_disp != l_b_disp ) { libxsmm_aarch64_instruction_asimd_move ( io_generated_code , LIBXSMM_AARCH64_INSTR_ASIMD_LDR_I_OFF , l_gp_reg_mapping . gp_reg_help_1 , 0 , 0 , l_rvb , LIBXSMM_AARCH64_ASIMD_WIDTH_Q ) ; l_curr_rvb_disp = l_b_disp ; } for ( l_z = 0 ; l_z < op . n ; l_z ++ ) { unsigned int l_u = op . src_vals [ l_z ] , l_v ; unsigned int l_rg = l_base_c_gp_reg + op . acc_idxs [ l_z ] ; unsigned int l_rva = ( l_unique > l_reg_unique ) ?~ 0U : l_u ; unsigned int l_rvc = l_base_c_reg + op . acc_idxs [ l_z ] ; unsigned int l_c_disp = op . c_disps [ l_z ] * i_xgemm_desc -> ldc * l_fbytes ; unsigned int l_neg = 0 ; unsigned int l_fma_insn = ( op . src_sgns [ l_z ] == 1 ) ?LIBXSMM_AARCH64_INSTR_ASIMD_FMLA_E_V : LIBXSMM_AARCH64_INSTR_ASIMD_FMLS_E_V ; if ( LIBXSMM_ASPARSE_REG_FLAG_FIRST & op . flags [ l_z ] ) { libxsmm_aarch64_instruction_alu_compute_imm64 ( io_generated_code , LIBXSMM_AARCH64_INSTR_GP_META_ADD , l_gp_reg_mapping . gp_reg_c , l_gp_reg_mapping . gp_reg_help_0 , l_rg , l_c_disp ) ; if ( l_beta0 ) { l_fma_insn = LIBXSMM_AARCH64_INSTR_ASIMD_FMUL_E_V ; l_neg = op . src_sgns [ l_z ] == - 1 ; } else { libxsmm_aarch64_instruction_asimd_move ( io_generated_code , LIBXSMM_AARCH64_INSTR_ASIMD_LDR_I_OFF , l_rg , 0 , 0 , l_rvc , LIBXSMM_AARCH64_ASIMD_WIDTH_Q ) ; } } if ( l_unique > l_reg_unique ) { for ( l_v = 0 ; l_v < l_nbcast_vals ; l_v ++ ) { if ( l_bcast_reg_vals [ l_v ] == l_u ) { l_rva = l_v ; break ; } } if ( ~ 0U == l_rva ) { l_rva = libxsmm_asparse_reg_pick_bcast_reg ( l_bcast_reg_vals , l_nbcast_vals , l_ops + l_op_idx + 1 , l_n_ops - l_op_idx - 1 ) ; libxsmm_aarch64_instruction_add_data ( io_generated_code , ( ( unsigned char * ) l_unique_values ) + l_fbytes * l_u , l_fbytes , l_fbytes , 1 , & l_const_data_tracker ) ; libxsmm_aarch64_instruction_asimd_struct_move ( io_generated_code , LIBXSMM_AARCH64_INSTR_ASIMD_LD1_I_POST , LIBXSMM_AARCH64_GP_REG_X26 , 0 , l_fbytes , l_rva / l_values_per_reg , ( short ) ( l_rva % l_values_per_reg ) , l_width ) ; l_bcast_reg_vals [ l_rva ] = l_u ; } } libxsmm_aarch64_instruction_asimd_compute ( io_generated_code , l_fma_insn , l_rvb , l_rva / l_values_per_reg , ( unsigned char ) ( l_rva % l_values_per_reg ) , l_rvc , l_tuplet ) ; if ( l_neg ) { libxsmm_aarch64_instruction_asimd_compute ( io_generated_code , LIBXSMM_AARCH64_INSTR_ASIMD_FNEG_V , l_rvc , LIBXSMM_AARCH64_ASIMD_REG_UNDEF , 0 , l_rvc , l_tuplet ) ; } if ( LIBXSMM_ASPARSE_REG_FLAG_LAST & op . flags [ l_z ] ) { libxsmm_aarch64_instruction_asimd_move ( io_generated_code , LIBXSMM_AARCH64_INSTR_ASIMD_STR_I_OFF , l_rg , 0 , 0 , l_rvc , LIBXSMM_AARCH64_ASIMD_WIDTH_Q ) ; } } } else { for ( l_n = 0 ; l_n < l_n_blocking ; l_n += 2 ) { if ( l_curr_rvb_disp != ( l_b_disp + ( int ) l_n * 16 ) ) { libxsmm_aarch64_instruction_asimd_pair_move ( io_generated_code , LIBXSMM_AARCH64_INSTR_ASIMD_LDP_I_OFF , l_gp_reg_mapping . gp_reg_help_1 , 16 * l_n , l_rvb , l_rvb + 1 , LIBXSMM_AARCH64_ASIMD_WIDTH_Q ) ; l_curr_rvb_disp = l_b_disp + 16 * l_n ; } for ( l_z = 0 ; l_z < op . n ; l_z ++ ) { unsigned int l_u = op . src_vals [ l_z ] , l_v ; unsigned int l_rg = l_base_c_gp_reg + op . acc_idxs [ l_z ] ; unsigned int l_rva = ( l_unique > l_reg_unique ) ?~ 0U : l_u ; unsigned int l_rvc = l_base_c_reg + l_n_blocking * op . acc_idxs [ l_z ] ; unsigned int l_c_disp = op . c_disps [ l_z ] * i_xgemm_desc -> ldc * l_fbytes ; unsigned int l_neg = 0 ; unsigned int l_fma_insn = ( op . src_sgns [ l_z ] == 1 ) ?LIBXSMM_AARCH64_INSTR_ASIMD_FMLA_E_V : LIBXSMM_AARCH64_INSTR_ASIMD_FMLS_E_V ; unsigned int l_stp_insn = ( l_c_is_nt ) ?LIBXSMM_AARCH64_INSTR_ASIMD_STNP_I_OFF : LIBXSMM_AARCH64_INSTR_ASIMD_STP_I_OFF ; if ( LIBXSMM_ASPARSE_REG_FLAG_FIRST & op . flags [ l_z ] ) { if ( 0 == l_n ) { libxsmm_aarch64_instruction_alu_compute_imm64 ( io_generated_code , LIBXSMM_AARCH64_INSTR_GP_META_ADD , l_gp_reg_mapping . gp_reg_c , l_gp_reg_mapping . gp_reg_help_0 , l_rg , l_c_disp ) ; } if ( l_beta0 ) { l_fma_insn = LIBXSMM_AARCH64_INSTR_ASIMD_FMUL_E_V ; l_neg = op . src_sgns [ l_z ] == - 1 ; } else { libxsmm_aarch64_instruction_asimd_pair_move ( io_generated_code , LIBXSMM_AARCH64_INSTR_ASIMD_LDP_I_OFF , l_rg , 16 * l_n , l_rvc + l_n , l_rvc + l_n + 1 , LIBXSMM_AARCH64_ASIMD_WIDTH_Q ) ; } } if ( l_unique > l_reg_unique ) { for ( l_v = 0 ; l_v < l_nbcast_vals ; l_v ++ ) { if ( l_bcast_reg_vals [ l_v ] == l_u ) { l_rva = l_v ; break ; } } if ( ~ 0U == l_rva ) { l_rva = libxsmm_asparse_reg_pick_bcast_reg ( l_bcast_reg_vals , l_nbcast_vals , l_ops + l_op_idx + 1 , l_n_ops - l_op_idx - 1 ) ; libxsmm_aarch64_instruction_add_data ( io_generated_code , ( ( unsigned char * ) l_unique_values ) + l_fbytes * l_u , l_fbytes , l_fbytes , 1 , & l_const_data_tracker ) ; libxsmm_aarch64_instruction_asimd_struct_move ( io_generated_code , LIBXSMM_AARCH64_INSTR_ASIMD_LD1_I_POST , LIBXSMM_AARCH64_GP_REG_X26 , 0 , l_fbytes , l_rva / l_values_per_reg , ( short ) ( l_rva % l_values_per_reg ) , l_width ) ; l_bcast_reg_vals [ l_rva ] = l_u ; } } libxsmm_aarch64_instruction_asimd_compute ( io_generated_code , l_fma_insn , l_rvb , l_rva / l_values_per_reg , ( unsigned char ) ( l_rva % l_values_per_reg ) , l_rvc + l_n , l_tuplet ) ; libxsmm_aarch64_instruction_asimd_compute ( io_generated_code , l_fma_insn , l_rvb + 1 , l_rva / l_values_per_reg , ( unsigned char ) ( l_rva % l_values_per_reg ) , l_rvc + l_n + 1 , l_tuplet ) ; if ( l_neg ) { libxsmm_aarch64_instruction_asimd_compute ( io_generated_code , LIBXSMM_AARCH64_INSTR_ASIMD_FNEG_V , l_rvc + l_n , LIBXSMM_AARCH64_ASIMD_REG_UNDEF , 0 , l_rvc + l_n , l_tuplet ) ; libxsmm_aarch64_instruction_asimd_compute ( io_generated_code , LIBXSMM_AARCH64_INSTR_ASIMD_FNEG_V , l_rvc + l_n + 1 , LIBXSMM_AARCH64_ASIMD_REG_UNDEF , 0 , l_rvc + l_n + 1 , l_tuplet ) ; } if ( LIBXSMM_ASPARSE_REG_FLAG_LAST & op . flags [ l_z ] ) { libxsmm_aarch64_instruction_asimd_pair_move ( io_generated_code , l_stp_insn , l_rg , 16 * l_n , l_rvc + l_n , l_rvc + l_n + 1 , LIBXSMM_AARCH64_ASIMD_WIDTH_Q ) ; } } } } } if ( l_beta0 ) { unsigned int l_zeroed = 0 ; unsigned int l_stp_insn ; if ( 1 == l_n_blocking ) { l_stp_insn = LIBXSMM_AARCH64_INSTR_ASIMD_STR_I_OFF ; } else { l_stp_insn = ( l_c_is_nt ) ?LIBXSMM_AARCH64_INSTR_ASIMD_STNP_I_OFF : LIBXSMM_AARCH64_INSTR_ASIMD_STP_I_OFF ; } for ( l_z = 0 ; l_z < i_xgemm_desc -> m ; l_z ++ ) { } } libxsmm_aarch64_instruction_alu_compute_imm12 ( io_generated_code , LIBXSMM_AARCH64_INSTR_GP_ADD_I , l_gp_reg_mapping . gp_reg_b , l_gp_reg_mapping . gp_reg_b , 16 * l_n_blocking , 0 ) ; libxsmm_aarch64_instruction_alu_compute_imm12 ( io_generated_code , LIBXSMM_AARCH64_INSTR_GP_ADD_I , l_gp_reg_mapping . gp_reg_c , l_gp_reg_mapping . gp_reg_c , 16 * l_n_blocking , 0 ) ; libxsmm_generator_loop_footer_aarch64 ( io_generated_code , & l_loop_label_tracker , LIBXSMM_AARCH64_GP_REG_X23 , l_values_per_reg * l_n_blocking ) ; libxsmm_aarch64_instruction_close_stream ( io_generated_code , 0xfff ) ; libxsmm_aarch64_instruction_close_data ( io_generated_code , & l_const_data_tracker ) ; cleanup free ( l_unique_values ) ; free ( l_unique_pos ) ; free ( l_unique_sgn ) ; free ( l_ops ) ; } 