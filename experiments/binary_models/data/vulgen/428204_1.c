int xhci_endpoint_init ( struct xhci_hcd * xhci , struct xhci_virt_device * virt_dev , struct usb_device * udev , struct usb_host_endpoint * ep , gfp_t mem_flags ) { unsigned int ep_index ; struct xhci_ep_ctx * ep_ctx ; struct xhci_ring * ep_ring ; unsigned int max_packet ; enum xhci_ring_type ring_type ; u32 max_esit_payload ; u32 endpoint_type ; unsigned int max_burst ; unsigned int interval ; unsigned int mult ; unsigned int avg_trb_len ; unsigned int err_count = 0 ; ep_index = xhci_get_endpoint_index ( & ep -> desc ) ; ep_ctx = xhci_get_ep_ctx ( xhci , virt_dev -> in_ctx , ep_index ) ; endpoint_type = xhci_get_endpoint_type ( ep ) ; ring_type = usb_endpoint_type ( & ep -> desc ) ; max_esit_payload = xhci_get_max_esit_payload ( udev , ep ) ; interval = xhci_get_endpoint_interval ( udev , ep ) ; if ( usb_endpoint_xfer_int ( & ep -> desc ) || usb_endpoint_xfer_isoc ( & ep -> desc ) ) { if ( ( xhci -> quirks & XHCI_LIMIT_ENDPOINT_INTERVAL_7 ) && udev -> speed >= USB_SPEED_HIGH && interval >= 7 ) { interval = 6 ; } } mult = xhci_get_endpoint_mult ( udev , ep ) ; max_packet = usb_endpoint_maxp ( & ep -> desc ) ; max_burst = xhci_get_endpoint_max_burst ( udev , ep ) ; avg_trb_len = max_esit_payload ; if ( ! usb_endpoint_xfer_isoc ( & ep -> desc ) ) { err_count = 3 ; } if ( usb_endpoint_xfer_bulk ( & ep -> desc ) && udev -> speed == USB_SPEED_HIGH ) { max_packet = 512 ; } if ( usb_endpoint_xfer_control ( & ep -> desc ) && xhci -> hci_version >= 0x100 ) { avg_trb_len = 8 ; } if ( ( xhci -> hci_version > 0x100 ) && HCC2_LEC ( xhci -> hcc_params2 ) ) { mult = 0 ; } virt_dev -> eps [ ep_index ] . new_ring = xhci_ring_alloc ( xhci , 2 , 1 , ring_type , max_packet , mem_flags ) ; if ( ! virt_dev -> eps [ ep_index ] . new_ring ) { if ( virt_dev -> num_rings_cached == 0 ) { return - ENOMEM ; } virt_dev -> num_rings_cached -- ; virt_dev -> eps [ ep_index ] . new_ring = virt_dev -> ring_cache [ virt_dev -> num_rings_cached ] ; virt_dev -> ring_cache [ virt_dev -> num_rings_cached ] = NULL ; xhci_reinit_cached_ring ( xhci , virt_dev -> eps [ ep_index ] . new_ring , 1 , ring_type ) ; } virt_dev -> eps [ ep_index ] . skip = false ; ep_ring = virt_dev -> eps [ ep_index ] . new_ring ; ep_ctx -> ep_info = cpu_to_le32 ( EP_MAX_ESIT_PAYLOAD_HI ( max_esit_payload ) | EP_INTERVAL ( interval ) | EP_MULT ( mult ) ) ; ep_ctx -> ep_info2 = cpu_to_le32 ( EP_TYPE ( endpoint_type ) | MAX_PACKET ( max_packet ) | MAX_BURST ( max_burst ) | ERROR_COUNT ( err_count ) ) ; ep_ctx -> deq = cpu_to_le64 ( ep_ring -> first_seg -> dma | ep_ring -> cycle_state ) ; ep_ctx -> tx_info = cpu_to_le32 ( EP_MAX_ESIT_PAYLOAD_LO ( max_esit_payload ) | EP_AVG_TRB_LENGTH ( avg_trb_len ) ) ; return 0 ; } 