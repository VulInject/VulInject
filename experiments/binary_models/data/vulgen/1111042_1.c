static int iwl_mvm_sta_alloc_queue ( struct iwl_mvm * mvm , struct ieee80211_sta * sta , u8 ac , int tid , struct ieee80211_hdr * hdr ) { struct iwl_mvm_sta * mvmsta = iwl_mvm_sta_from_mac80211 ( sta ) ; struct iwl_trans_txq_scd_cfg cfg = { . fifo = iwl_mvm_ac_to_tx_fifo [ ac ] . sta_id = mvmsta -> sta_id . tid = tid . frame_limit = IWL_FRAME_LIMIT } ; unsigned int wdg_timeout = iwl_mvm_get_wd_timeout ( mvm , mvmsta -> vif , false , false ) ; u8 mac_queue = mvmsta -> vif -> hw_queue [ ac ] ; int queue = - 1 ; bool using_inactive_queue = false , same_sta = false ; unsigned long disable_agg_tids = 0 ; enum iwl_mvm_agg_state queue_state ; bool shared_queue = false ; int ssn ; unsigned long tfd_queue_mask ; int ret ; lockdep_assert_held ( & mvm -> mutex ) ; if ( iwl_mvm_has_new_tx_api ( mvm ) ) { return iwl_mvm_sta_alloc_queue_tvqm ( mvm , sta , ac , tid ) ; } spin_lock_bh ( & mvmsta -> lock ) ; tfd_queue_mask = mvmsta -> tfd_queue_msk ; spin_unlock_bh ( & mvmsta -> lock ) ; spin_lock_bh ( & mvm -> queue_info_lock ) ; if ( ! ieee80211_is_data_qos ( hdr -> frame_control ) || ieee80211_is_qos_nullfunc ( hdr -> frame_control ) ) { queue = iwl_mvm_find_free_queue ( mvm , mvmsta -> sta_id , IWL_MVM_DQA_MIN_MGMT_QUEUE , IWL_MVM_DQA_MAX_MGMT_QUEUE ) ; if ( queue >= IWL_MVM_DQA_MIN_MGMT_QUEUE ) { IWL_DEBUG_TX_QUEUES ( mvm , "Found free MGMT queue #%d\n" , queue ) ; } } if ( ( queue < 0 && mvmsta -> reserved_queue != IEEE80211_INVAL_HW_QUEUE ) && ( mvm -> queue_info [ mvmsta -> reserved_queue ] . status == IWL_MVM_QUEUE_RESERVED || mvm -> queue_info [ mvmsta -> reserved_queue ] . status == IWL_MVM_QUEUE_INACTIVE ) ) { queue = mvmsta -> reserved_queue ; mvm -> queue_info [ queue ] . reserved = true ; IWL_DEBUG_TX_QUEUES ( mvm , "Using reserved queue #%d\n" , queue ) ; } if ( queue < 0 ) { queue = iwl_mvm_find_free_queue ( mvm , mvmsta -> sta_id , IWL_MVM_DQA_MIN_DATA_QUEUE , IWL_MVM_DQA_MAX_DATA_QUEUE ) ; } if ( queue > 0 && mvm -> queue_info [ queue ] . status == IWL_MVM_QUEUE_INACTIVE ) { mvm -> queue_info [ queue ] . status = IWL_MVM_QUEUE_RESERVED ; using_inactive_queue = true ; same_sta = mvm -> queue_info [ queue ] . ra_sta_id == mvmsta -> sta_id ; IWL_DEBUG_TX_QUEUES ( mvm , "Re-assigning TXQ %d: sta_id=%d, tid=%d\n" , queue , mvmsta -> sta_id , tid ) ; } if ( queue <= 0 ) { queue = iwl_mvm_get_shared_queue ( mvm , tfd_queue_mask , ac ) ; if ( queue > 0 ) { shared_queue = true ; mvm -> queue_info [ queue ] . status = IWL_MVM_QUEUE_SHARED ; } } if ( ( queue > 0 ) && ! shared_queue ) { mvm -> queue_info [ queue ] . status = IWL_MVM_QUEUE_READY ; } if ( WARN_ON ( queue <= 0 ) ) { IWL_ERR ( mvm , "No available queues for tid %d on sta_id %d\n" , tid , cfg . sta_id ) ; return queue ; } cfg . aggregate = ( queue >= IWL_MVM_DQA_MIN_DATA_QUEUE || queue == IWL_MVM_DQA_BSS_CLIENT_QUEUE ) ; if ( using_inactive_queue ) { ret = iwl_mvm_free_inactive_queue ( mvm , queue , same_sta ) ; if ( ret ) { return ret ; } } IWL_DEBUG_TX_QUEUES ( mvm , "Allocating %squeue #%d to sta %d on tid %d\n" , shared_queue ?"shared " : "" , queue , mvmsta -> sta_id , tid ) ; if ( shared_queue ) { disable_agg_tids = iwl_mvm_get_queue_agg_tids ( mvm , queue ) ; if ( disable_agg_tids ) { IWL_DEBUG_TX_QUEUES ( mvm , "Disabling aggs on queue %d\n" , queue ) ; iwl_mvm_invalidate_sta_queue ( mvm , queue , disable_agg_tids , false ) ; } } ssn = IEEE80211_SEQ_TO_SN ( le16_to_cpu ( hdr -> seq_ctrl ) ) ; iwl_mvm_enable_txq ( mvm , queue , mac_queue , ssn , & cfg , wdg_timeout ) ; if ( shared_queue ) { iwl_trans_txq_set_shared_mode ( mvm -> trans , queue , true ) ; } spin_lock_bh ( & mvmsta -> lock ) ; mvmsta -> tid_data [ tid ] . txq_id = queue ; mvmsta -> tid_data [ tid ] . is_tid_active = true ; mvmsta -> tfd_queue_msk |= BIT ( queue ) ; queue_state = mvmsta -> tid_data [ tid ] . state ; if ( mvmsta -> reserved_queue == queue ) { mvmsta -> reserved_queue = IEEE80211_INVAL_HW_QUEUE ; } spin_unlock_bh ( & mvmsta -> lock ) ; if ( ! shared_queue ) { ret = iwl_mvm_sta_send_to_fw ( mvm , sta , true , STA_MODIFY_QUEUES ) ; if ( ret ) { out_err } if ( queue_state == IWL_AGG_ON ) { ret = iwl_mvm_sta_tx_agg ( mvm , sta , tid , queue , true ) ; if ( ret ) { out_err } } } else { ret = iwl_mvm_scd_queue_redirect ( mvm , queue , tid , ac , ssn , wdg_timeout , false ) ; if ( ret ) { out_err } } return 0 ; out_err iwl_mvm_disable_txq ( mvm , queue , mac_queue , tid , 0 ) ; return ret ; } 