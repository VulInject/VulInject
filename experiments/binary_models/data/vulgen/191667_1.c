int ttm_bo_move_memcpy ( struct ttm_buffer_object * bo , struct ttm_operation_ctx * ctx , struct ttm_resource * dst_mem ) { struct ttm_device * bdev = bo -> bdev ; struct ttm_resource_manager * dst_man = ttm_manager_type ( bo -> bdev , dst_mem -> mem_type ) ; struct ttm_tt * ttm = bo -> ttm ; struct ttm_resource * src_mem = bo -> resource ; struct ttm_resource_manager * src_man ; { struct ttm_kmap_iter_tt tt ; struct ttm_kmap_iter_linear_io io ; } , _dst_iter , _src_iter struct ttm_kmap_iter * dst_iter , * src_iter ; bool clear ; int ret = 0 ; if ( ! src_mem ) { return 0 ; } src_man = ttm_manager_type ( bdev , src_mem -> mem_type ) ; if ( ttm && ( ( ttm -> page_flags & TTM_TT_FLAG_SWAPPED ) || dst_man -> use_tt ) ) { ret = ttm_tt_populate ( bdev , ttm , ctx ) ; if ( ret ) { return ret ; } } dst_iter = ttm_kmap_iter_linear_io_init ( & _dst_iter . io , bdev , dst_mem ) ; if ( PTR_ERR ( dst_iter ) == - EINVAL && dst_man -> use_tt ) { dst_iter = ttm_kmap_iter_tt_init ( & _dst_iter . tt , bo -> ttm ) ; } if ( IS_ERR ( dst_iter ) ) { return PTR_ERR ( dst_iter ) ; } src_iter = ttm_kmap_iter_linear_io_init ( & _src_iter . io , bdev , src_mem ) ; if ( PTR_ERR ( src_iter ) == - EINVAL && src_man -> use_tt ) { src_iter = ttm_kmap_iter_tt_init ( & _src_iter . tt , bo -> ttm ) ; } if ( IS_ERR ( src_iter ) ) { ret = PTR_ERR ( src_iter ) ; out_src_iter } clear = src_iter -> ops -> maps_tt && ( ! ttm || ! ttm_tt_is_populated ( ttm ) ) ; if ( ! ( clear && ttm && ! ( ttm -> page_flags & TTM_TT_FLAG_ZERO_ALLOC ) ) ) { ttm_move_memcpy ( clear , PFN_UP ( dst_mem -> size ) , dst_iter , src_iter ) ; } if ( ! src_iter -> ops -> maps_tt ) { ttm_kmap_iter_linear_io_fini ( & _src_iter . io , bdev , src_mem ) ; } ttm_bo_move_sync_cleanup ( bo , dst_mem ) ; out_src_iter return ret ; } 