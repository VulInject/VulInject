static int bnx2fc_xmit ( struct fc_lport * lport , struct fc_frame * fp ) { struct ethhdr * eh ; struct fcoe_crc_eof * cp ; struct sk_buff * skb ; struct fc_frame_header * fh ; struct bnx2fc_interface * interface ; struct fcoe_ctlr * ctlr ; struct bnx2fc_hba * hba ; struct fcoe_port * port ; struct fcoe_hdr * hp ; struct bnx2fc_rport * tgt ; struct fc_stats * stats ; u8 sof , eof ; u32 crc ; unsigned int hlen , tlen , elen ; int wlen , rc = 0 ; port = ( fcoe_port * ) lport_priv ( lport ) ; interface = port -> priv ; ctlr = bnx2fc_to_ctlr ( interface ) ; hba = interface -> hba ; fh = fc_frame_header_get ( fp ) ; skb = fp_skb ( fp ) ; if ( ! lport -> link_up ) { BNX2FC_HBA_DBG ( lport , "bnx2fc_xmit link down\n" ) ; return 0 ; } if ( unlikely ( fh -> fh_r_ctl == FC_RCTL_ELS_REQ ) ) { if ( ! ctlr -> sel_fcf ) { BNX2FC_HBA_DBG ( lport , "FCF not selected yet!\n" ) ; kfree_skb ( skb ) ; return - EINVAL ; } if ( fcoe_ctlr_els_send ( ctlr , lport , skb ) ) { return 0 ; } } sof = fr_sof ( fp ) ; eof = fr_eof ( fp ) ; spin_lock_bh ( & hba -> hba_lock ) ; tgt = bnx2fc_tgt_lookup ( port , ntoh24 ( fh -> fh_d_id ) ) ; if ( tgt && ( test_bit ( BNX2FC_FLAG_SESSION_READY , & tgt -> flags ) ) ) { BNX2FC_HBA_DBG ( lport , "xmit: Frame is for offloaded session " "port_id = 0x%x\n" , ntoh24 ( fh -> fh_d_id ) ) ; spin_unlock_bh ( & hba -> hba_lock ) ; rc = bnx2fc_xmit_l2_frame ( tgt , fp ) ; if ( rc != - ENODEV ) { kfree_skb ( skb ) ; return rc ; } } else { spin_unlock_bh ( & hba -> hba_lock ) ; } elen = sizeof ( ethhdr ) ; hlen = sizeof ( fcoe_hdr ) ; tlen = sizeof ( fcoe_crc_eof ) ; wlen = ( skb -> len - tlen + sizeof ( crc ) ) / FCOE_WORD_TO_BYTE ; skb -> ip_summed = CHECKSUM_NONE ; crc = fcoe_fc_crc ( fp ) ; if ( skb_is_nonlinear ( skb ) ) { skb_frag_t * frag ; if ( bnx2fc_get_paged_crc_eof ( skb , tlen ) ) { kfree_skb ( skb ) ; return - ENOMEM ; } frag = & skb_shinfo ( skb ) -> frags [ skb_shinfo ( skb ) -> nr_frags - 1 ] ; cp = kmap_atomic ( skb_frag_page ( frag ) ) + frag -> page_offset ; } else { cp = ( fcoe_crc_eof * ) skb_put ( skb , tlen ) ; } memset ( cp , 0 , sizeof ( * cp ) ) ; cp -> fcoe_eof = eof ; cp -> fcoe_crc32 = cpu_to_le32 ( ~ crc ) ; if ( skb_is_nonlinear ( skb ) ) { kunmap_atomic ( cp ) ; cp = NULL ; } skb_push ( skb , elen + hlen ) ; skb_reset_mac_header ( skb ) ; skb_reset_network_header ( skb ) ; skb -> mac_len = elen ; skb -> protocol = htons ( ETH_P_FCOE ) ; skb -> dev = interface -> netdev ; eh = eth_hdr ( skb ) ; eh -> h_proto = htons ( ETH_P_FCOE ) ; if ( ctlr -> map_dest ) { fc_fcoe_set_mac ( eh -> h_dest , fh -> fh_d_id ) ; } else { memcpy ( eh -> h_dest , ctlr -> dest_addr , ETH_ALEN ) ; } if ( unlikely ( ctlr -> flogi_oxid != FC_XID_UNKNOWN ) ) { memcpy ( eh -> h_source , ctlr -> ctl_src_addr , ETH_ALEN ) ; } else { memcpy ( eh -> h_source , port -> data_src_addr , ETH_ALEN ) ; } hp = ( fcoe_hdr * ) ( eh + 1 ) ; memset ( hp , 0 , sizeof ( * hp ) ) ; if ( FC_FCOE_VER ) { FC_FCOE_ENCAPS_VER ( hp , FC_FCOE_VER ) ; } hp -> fcoe_sof = sof ; if ( lport -> seq_offload && fr_max_payload ( fp ) ) { skb_shinfo ( skb ) -> gso_type = SKB_GSO_FCOE ; skb_shinfo ( skb ) -> gso_size = fr_max_payload ( fp ) ; } else { skb_shinfo ( skb ) -> gso_type = 0 ; skb_shinfo ( skb ) -> gso_size = 0 ; } stats = per_cpu_ptr ( lport -> stats , get_cpu ( ) ) ; stats -> TxFrames ++ ; stats -> TxWords += wlen ; put_cpu ( ) ; fr_dev ( fp ) = lport ; if ( port -> fcoe_pending_queue . qlen ) { fcoe_check_wait_queue ( lport , skb ) ; } if ( fcoe_start_io ( skb ) ) { fcoe_check_wait_queue ( lport , skb ) ; } return 0 ; } 