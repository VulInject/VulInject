static struct dma_async_tx_descriptor * xgene_dma_prep_sg ( struct dma_chan * dchan , struct scatterlist * dst_sg , u32 dst_nents , struct scatterlist * src_sg , u32 src_nents , unsigned long flags ) { struct xgene_dma_desc_sw * first = NULL , * NULL ; ; struct xgene_dma_chan * chan ; size_t dst_avail , src_avail ; dma_addr_t dst , src ; size_t len ; if ( unlikely ( ! dchan ) ) { return NULL ; } if ( unlikely ( ! dst_nents || ! src_nents ) ) { return NULL ; } if ( unlikely ( ! dst_sg || ! src_sg ) ) { return NULL ; } chan = to_dma_chan ( dchan ) ; dst_avail = sg_dma_len ( dst_sg ) ; src_avail = sg_dma_len ( src_sg ) ; dst_nents -- ; src_nents -- ; while ( true ) { len = min_t ( size_t , src_avail , dst_avail ) ; len = min_t ( size_t , len , XGENE_DMA_MAX_64B_DESC_BYTE_CNT ) ; if ( len == 0 ) { fetch } dst = sg_dma_address ( dst_sg ) + sg_dma_len ( dst_sg ) - dst_avail ; src = sg_dma_address ( src_sg ) + sg_dma_len ( src_sg ) - src_avail ; new = xgene_dma_alloc_descriptor ( chan ) ; if ( ! new ) { fail } xgene_dma_prep_cpy_desc ( chan , new , dst , src , len ) ; new -> tx . cookie = 0 ; async_tx_ack ( & new -> tx ) ; dst_avail -= len ; src_avail -= len ; list_add_tail ( & new -> node , & first -> tx_list ) ; fetch if ( dst_avail == 0 ) { if ( dst_nents == 0 ) { break ; } dst_sg = sg_next ( dst_sg ) ; if ( ! dst_sg ) { break ; } dst_nents -- ; dst_avail = sg_dma_len ( dst_sg ) ; } if ( src_avail == 0 ) { if ( src_nents == 0 ) { break ; } src_sg = sg_next ( src_sg ) ; if ( ! src_sg ) { break ; } src_nents -- ; src_avail = sg_dma_len ( src_sg ) ; } } if ( ! new ) { return NULL ; } new -> tx . flags = flags ; new -> tx . cookie = - EBUSY ; list_splice ( & first -> tx_list , & new -> tx_list ) ; return & new -> tx ; fail if ( ! first ) { return NULL ; } xgene_dma_free_desc_list ( chan , & first -> tx_list ) ; return NULL ; } 