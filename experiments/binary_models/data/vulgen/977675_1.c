static int userspace_flush ( struct dm_dirty_log * log ) { int r = 0 ; unsigned long flags ; struct log_c * lc = log -> context ; LIST_HEAD ( mark_list ) ; LIST_HEAD ( clear_list ) ; int mark_list_is_empty ; int clear_list_is_empty ; struct dm_dirty_log_flush_entry * fe , * tmp_fe ; mempool_t * flush_entry_pool = & lc -> flush_entry_pool ; spin_lock_irqsave ( & lc -> flush_lock , flags ) ; list_splice_init ( & lc -> mark_list , & mark_list ) ; list_splice_init ( & lc -> clear_list , & clear_list ) ; spin_unlock_irqrestore ( & lc -> flush_lock , flags ) ; mark_list_is_empty = list_empty ( & mark_list ) ; clear_list_is_empty = list_empty ( & clear_list ) ; r = flush_by_group ( lc , & clear_list , 0 ) ; if ( r ) { out } if ( ! lc -> integrated_flush ) { r = flush_by_group ( lc , & mark_list , 0 ) ; if ( r ) { out } r = userspace_do_request ( lc , lc -> uuid , DM_ULOG_FLUSH , NULL , 0 , NULL , NULL ) ; out } r = flush_by_group ( lc , & mark_list , 1 ) ; if ( r ) { out } if ( mark_list_is_empty && ! atomic_read ( & lc -> sched_flush ) ) { queue_delayed_work ( lc -> dmlog_wq , & lc -> flush_log_work , 3 * HZ ) ; atomic_set ( & lc -> sched_flush , 1 ) ; } else { cancel_delayed_work ( & lc -> flush_log_work ) ; atomic_set ( & lc -> sched_flush , 0 ) ; } out list_for_each_entry_safe ( , , , ) { list_del ( & fe -> list ) ; mempool_free ( fe , flush_entry_pool ) ; } list_for_each_entry_safe ( , , , ) { list_del ( & fe -> list ) ; mempool_free ( fe , flush_entry_pool ) ; } if ( r ) { dm_table_event ( lc -> ti -> table ) ; } return r ; } 