struct ib_umem * ib_alloc_odp_umem ( struct ib_ucontext * context , unsigned long addr , size_t size ) { struct ib_umem * umem ; struct ib_umem_odp * odp_data ; int pages = size >> PAGE_SHIFT ; int ret ; umem = kzalloc ( sizeof ( * umem ) , GFP_KERNEL ) ; if ( ! umem ) { return ERR_PTR ( - ENOMEM ) ; } umem -> context = context ; umem -> length = size ; umem -> address = addr ; umem -> page_shift = PAGE_SHIFT ; umem -> writable = 1 ; odp_data = kzalloc ( sizeof ( * odp_data ) , GFP_KERNEL ) ; if ( ! odp_data ) { ret = - ENOMEM ; out_umem } odp_data -> umem = umem ; init_completion ( & odp_data -> notifier_completion ) ; odp_data -> page_list = vzalloc ( pages * sizeof ( * odp_data -> page_list ) ) ; if ( ! odp_data -> page_list ) { ret = - ENOMEM ; out_odp_data } odp_data -> dma_list = vzalloc ( pages * sizeof ( * odp_data -> dma_list ) ) ; if ( ! odp_data -> dma_list ) { ret = - ENOMEM ; out_page_list } down_write ( & context -> umem_rwsem ) ; context -> odp_mrs_count ++ ; rbt_ib_umem_insert ( & odp_data -> interval_tree , & context -> umem_tree ) ; if ( likely ( ! atomic_read ( & context -> notifier_count ) ) ) { odp_data -> mn_counters_active = true ; } else { list_add ( & odp_data -> no_private_counters , & context -> no_private_counters ) ; } up_write ( & context -> umem_rwsem ) ; umem -> odp_data = odp_data ; return umem ; out_page_list vfree ( odp_data -> page_list ) ; out_odp_data kfree ( odp_data ) ; out_umem kfree ( umem ) ; return ERR_PTR ( ret ) ; } 