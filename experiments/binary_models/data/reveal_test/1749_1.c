static void mb_lpf_horizontal_edge_w_sse2_8 ( unsigned char * s , int p , const unsigned char * _blimit , const unsigned char * _limit , const unsigned char * _thresh ) {
 const __m128i zero = _mm_set1_epi16 ( 0 ) ;
 const __m128i one = _mm_set1_epi8 ( 1 ) ;
 const __m128i blimit = _mm_load_si128 ( ( const __m128i * ) _blimit ) ;
 const __m128i limit = _mm_load_si128 ( ( const __m128i * ) _limit ) ;
 const __m128i thresh = _mm_load_si128 ( ( const __m128i * ) _thresh ) ;
 __m128i mask , hev , flat , flat2 ;
 __m128i q7p7 , q6p6 , q5p5 , q4p4 , q3p3 , q2p2 , q1p1 , q0p0 , p0q0 , p1q1 ;
 __m128i abs_p1p0 ;
 q4p4 = _mm_loadl_epi64 ( ( __m128i * ) ( s - 5 * p ) ) ;
 q4p4 = _mm_castps_si128 ( _mm_loadh_pi ( _mm_castsi128_ps ( q4p4 ) , ( __m64 * ) ( s + 4 * p ) ) ) ;
 q3p3 = _mm_loadl_epi64 ( ( __m128i * ) ( s - 4 * p ) ) ;
 q3p3 = _mm_castps_si128 ( _mm_loadh_pi ( _mm_castsi128_ps ( q3p3 ) , ( __m64 * ) ( s + 3 * p ) ) ) ;
 q2p2 = _mm_loadl_epi64 ( ( __m128i * ) ( s - 3 * p ) ) ;
 q2p2 = _mm_castps_si128 ( _mm_loadh_pi ( _mm_castsi128_ps ( q2p2 ) , ( __m64 * ) ( s + 2 * p ) ) ) ;
 q1p1 = _mm_loadl_epi64 ( ( __m128i * ) ( s - 2 * p ) ) ;
 q1p1 = _mm_castps_si128 ( _mm_loadh_pi ( _mm_castsi128_ps ( q1p1 ) , ( __m64 * ) ( s + 1 * p ) ) ) ;
 p1q1 = _mm_shuffle_epi32 ( q1p1 , 78 ) ;
 q0p0 = _mm_loadl_epi64 ( ( __m128i * ) ( s - 1 * p ) ) ;
 q0p0 = _mm_castps_si128 ( _mm_loadh_pi ( _mm_castsi128_ps ( q0p0 ) , ( __m64 * ) ( s - 0 * p ) ) ) ;
 p0q0 = _mm_shuffle_epi32 ( q0p0 , 78 ) ;
 {
 __m128i abs_p1q1 , abs_p0q0 , abs_q1q0 , fe , ff , work ;
 abs_p1p0 = _mm_or_si128 ( _mm_subs_epu8 ( q1p1 , q0p0 ) , _mm_subs_epu8 ( q0p0 , q1p1 ) ) ;
 abs_q1q0 = _mm_srli_si128 ( abs_p1p0 , 8 ) ;
 fe = _mm_set1_epi8 ( 0xfe ) ;
 ff = _mm_cmpeq_epi8 ( abs_p1p0 , abs_p1p0 ) ;
 abs_p0q0 = _mm_or_si128 ( _mm_subs_epu8 ( q0p0 , p0q0 ) , _mm_subs_epu8 ( p0q0 , q0p0 ) ) ;
 abs_p1q1 = _mm_or_si128 ( _mm_subs_epu8 ( q1p1 , p1q1 ) , _mm_subs_epu8 ( p1q1 , q1p1 ) ) ;
 flat = _mm_max_epu8 ( abs_p1p0 , abs_q1q0 ) ;
 hev = _mm_subs_epu8 ( flat , thresh ) ;
 hev = _mm_xor_si128 ( _mm_cmpeq_epi8 ( hev , zero ) , ff ) ;
 abs_p0q0 = _mm_adds_epu8 ( abs_p0q0 , abs_p0q0 ) ;
 abs_p1q1 = _mm_srli_epi16 ( _mm_and_si128 ( abs_p1q1 , fe ) , 1 ) ;
 mask = _mm_subs_epu8 ( _mm_adds_epu8 ( abs_p0q0 , abs_p1q1 ) , blimit ) ;
 mask = _mm_xor_si128 ( _mm_cmpeq_epi8 ( mask , zero ) , ff ) ;
 mask = _mm_max_epu8 ( abs_p1p0 , mask ) ;
 work = _mm_max_epu8 ( _mm_or_si128 ( _mm_subs_epu8 ( q2p2 , q1p1 ) , _mm_subs_epu8 ( q1p1 , q2p2 ) ) , _mm_or_si128 ( _mm_subs_epu8 ( q3p3 , q2p2 ) , _mm_subs_epu8 ( q2p2 , q3p3 ) ) ) ;
 mask = _mm_max_epu8 ( work , mask ) ;
 mask = _mm_max_epu8 ( mask , _mm_srli_si128 ( mask , 8 ) ) ;
 mask = _mm_subs_epu8 ( mask , limit ) ;
 mask = _mm_cmpeq_epi8 ( mask , zero ) ;
 }
 {
 const __m128i t4 = _mm_set1_epi8 ( 4 ) ;
 const __m128i t3 = _mm_set1_epi8 ( 3 ) ;
 const __m128i t80 = _mm_set1_epi8 ( 0x80 ) ;
 const __m128i t1 = _mm_set1_epi16 ( 0x1 ) ;
 __m128i qs1ps1 = _mm_xor_si128 ( q1p1 , t80 ) ;
 __m128i qs0ps0 = _mm_xor_si128 ( q0p0 , t80 ) ;
 __m128i qs0 = _mm_xor_si128 ( p0q0 , t80 ) ;
 __m128i qs1 = _mm_xor_si128 ( p1q1 , t80 ) ;
 __m128i filt ;
 __m128i work_a ;
 __m128i filter1 , filter2 ;
 __m128i flat2_q6p6 , flat2_q5p5 , flat2_q4p4 , flat2_q3p3 , flat2_q2p2 ;
 __m128i flat2_q1p1 , flat2_q0p0 , flat_q2p2 , flat_q1p1 , flat_q0p0 ;
 filt = _mm_and_si128 ( _mm_subs_epi8 ( qs1ps1 , qs1 ) , hev ) ;
 work_a = _mm_subs_epi8 ( qs0 , qs0ps0 ) ;
 filt = _mm_adds_epi8 ( filt , work_a ) ;
 filt = _mm_adds_epi8 ( filt , work_a ) ;
 filt = _mm_adds_epi8 ( filt , work_a ) ;
 filt = _mm_and_si128 ( filt , mask ) ;
 filter1 = _mm_adds_epi8 ( filt , t4 ) ;
 filter2 = _mm_adds_epi8 ( filt , t3 ) ;
 filter1 = _mm_unpacklo_epi8 ( zero , filter1 ) ;
 filter1 = _mm_srai_epi16 ( filter1 , 0xB ) ;
 filter2 = _mm_unpacklo_epi8 ( zero , filter2 ) ;
 filter2 = _mm_srai_epi16 ( filter2 , 0xB ) ;
 filt = _mm_packs_epi16 ( filter2 , _mm_subs_epi16 ( zero , filter1 ) ) ;
 qs0ps0 = _mm_xor_si128 ( _mm_adds_epi8 ( qs0ps0 , filt ) , t80 ) ;
 filt = _mm_adds_epi16 ( filter1 , t1 ) ;
 filt = _mm_srai_epi16 ( filt , 1 ) ;
 filt = _mm_andnot_si128 ( _mm_srai_epi16 ( _mm_unpacklo_epi8 ( zero , hev ) , 0x8 ) , filt ) ;
 filt = _mm_packs_epi16 ( filt , _mm_subs_epi16 ( zero , filt ) ) ;
 qs1ps1 = _mm_xor_si128 ( _mm_adds_epi8 ( qs1ps1 , filt ) , t80 ) ;
 {
 __m128i work ;
 flat = _mm_max_epu8 ( _mm_or_si128 ( _mm_subs_epu8 ( q2p2 , q0p0 ) , _mm_subs_epu8 ( q0p0 , q2p2 ) ) , _mm_or_si128 ( _mm_subs_epu8 ( q3p3 , q0p0 ) , _mm_subs_epu8 ( q0p0 , q3p3 ) ) ) ;
 flat = _mm_max_epu8 ( abs_p1p0 , flat ) ;
 flat = _mm_max_epu8 ( flat , _mm_srli_si128 ( flat , 8 ) ) ;
 flat = _mm_subs_epu8 ( flat , one ) ;
 flat = _mm_cmpeq_epi8 ( flat , zero ) ;
 flat = _mm_and_si128 ( flat , mask ) ;
 q5p5 = _mm_loadl_epi64 ( ( __m128i * ) ( s - 6 * p ) ) ;
 q5p5 = _mm_castps_si128 ( _mm_loadh_pi ( _mm_castsi128_ps ( q5p5 ) , ( __m64 * ) ( s + 5 * p ) ) ) ;
 q6p6 = _mm_loadl_epi64 ( ( __m128i * ) ( s - 7 * p ) ) ;
 q6p6 = _mm_castps_si128 ( _mm_loadh_pi ( _mm_castsi128_ps ( q6p6 ) , ( __m64 * ) ( s + 6 * p ) ) ) ;
 flat2 = _mm_max_epu8 ( _mm_or_si128 ( _mm_subs_epu8 ( q4p4 , q0p0 ) , _mm_subs_epu8 ( q0p0 , q4p4 ) ) , _mm_or_si128 ( _mm_subs_epu8 ( q5p5 , q0p0 ) , _mm_subs_epu8 ( q0p0 , q5p5 ) ) ) ;
 q7p7 = _mm_loadl_epi64 ( ( __m128i * ) ( s - 8 * p ) ) ;
 q7p7 = _mm_castps_si128 ( _mm_loadh_pi ( _mm_castsi128_ps ( q7p7 ) , ( __m64 * ) ( s + 7 * p ) ) ) ;
 work = _mm_max_epu8 ( _mm_or_si128 ( _mm_subs_epu8 ( q6p6 , q0p0 ) , _mm_subs_epu8 ( q0p0 , q6p6 ) ) , _mm_or_si128 ( _mm_subs_epu8 ( q7p7 , q0p0 ) , _mm_subs_epu8 ( q0p0 , q7p7 ) ) ) ;
 flat2 = _mm_max_epu8 ( work , flat2 ) ;
 flat2 = _mm_max_epu8 ( flat2 , _mm_srli_si128 ( flat2 , 8 ) ) ;
 flat2 = _mm_subs_epu8 ( flat2 , one ) ;
 flat2 = _mm_cmpeq_epi8 ( flat2 , zero ) ;
 flat2 = _mm_and_si128 ( flat2 , flat ) ;
 }
 {
 const __m128i eight = _mm_set1_epi16 ( 8 ) ;
 const __m128i four = _mm_set1_epi16 ( 4 ) ;
 __m128i p7_16 , p6_16 , p5_16 , p4_16 , p3_16 , p2_16 , p1_16 , p0_16 ;
 __m128i q7_16 , q6_16 , q5_16 , q4_16 , q3_16 , q2_16 , q1_16 , q0_16 ;
 __m128i pixelFilter_p , pixelFilter_q ;
 __m128i pixetFilter_p2p1p0 , pixetFilter_q2q1q0 ;
 __m128i sum_p7 , sum_q7 , sum_p3 , sum_q3 , res_p , res_q ;
 p7_16 = _mm_unpacklo_epi8 ( q7p7 , zero ) ;
 ;
 p6_16 = _mm_unpacklo_epi8 ( q6p6 , zero ) ;
 p5_16 = _mm_unpacklo_epi8 ( q5p5 , zero ) ;
 p4_16 = _mm_unpacklo_epi8 ( q4p4 , zero ) ;
 p3_16 = _mm_unpacklo_epi8 ( q3p3 , zero ) ;
 p2_16 = _mm_unpacklo_epi8 ( q2p2 , zero ) ;
 p1_16 = _mm_unpacklo_epi8 ( q1p1 , zero ) ;
 p0_16 = _mm_unpacklo_epi8 ( q0p0 , zero ) ;
 q0_16 = _mm_unpackhi_epi8 ( q0p0 , zero ) ;
 q1_16 = _mm_unpackhi_epi8 ( q1p1 , zero ) ;
 q2_16 = _mm_unpackhi_epi8 ( q2p2 , zero ) ;
 q3_16 = _mm_unpackhi_epi8 ( q3p3 , zero ) ;
 q4_16 = _mm_unpackhi_epi8 ( q4p4 , zero ) ;
 q5_16 = _mm_unpackhi_epi8 ( q5p5 , zero ) ;
 q6_16 = _mm_unpackhi_epi8 ( q6p6 , zero ) ;
 q7_16 = _mm_unpackhi_epi8 ( q7p7 , zero ) ;
 pixelFilter_p = _mm_add_epi16 ( _mm_add_epi16 ( p6_16 , p5_16 ) , _mm_add_epi16 ( p4_16 , p3_16 ) ) ;
 pixelFilter_q = _mm_add_epi16 ( _mm_add_epi16 ( q6_16 , q5_16 ) , _mm_add_epi16 ( q4_16 , q3_16 ) ) ;
 pixetFilter_p2p1p0 = _mm_add_epi16 ( p0_16 , _mm_add_epi16 ( p2_16 , p1_16 ) ) ;
 pixelFilter_p = _mm_add_epi16 ( pixelFilter_p , pixetFilter_p2p1p0 ) ;
 pixetFilter_q2q1q0 = _mm_add_epi16 ( q0_16 , _mm_add_epi16 ( q2_16 , q1_16 ) ) ;
 pixelFilter_q = _mm_add_epi16 ( pixelFilter_q , pixetFilter_q2q1q0 ) ;
 pixelFilter_p = _mm_add_epi16 ( eight , _mm_add_epi16 ( pixelFilter_p , pixelFilter_q ) ) ;
 pixetFilter_p2p1p0 = _mm_add_epi16 ( four , _mm_add_epi16 ( pixetFilter_p2p1p0 , pixetFilter_q2q1q0 ) ) ;
 res_p = _mm_srli_epi16 ( _mm_add_epi16 ( pixelFilter_p , _mm_add_epi16 ( p7_16 , p0_16 ) ) , 4 ) ;
 res_q = _mm_srli_epi16 ( _mm_add_epi16 ( pixelFilter_p , _mm_add_epi16 ( q7_16 , q0_16 ) ) , 4 ) ;
 flat2_q0p0 = _mm_packus_epi16 ( res_p , res_q ) ;
 res_p = _mm_srli_epi16 ( _mm_add_epi16 ( pixetFilter_p2p1p0 , _mm_add_epi16 ( p3_16 , p0_16 ) ) , 3 ) ;
 res_q = _mm_srli_epi16 ( _mm_add_epi16 ( pixetFilter_p2p1p0 , _mm_add_epi16 ( q3_16 , q0_16 ) ) , 3 ) ;
 flat_q0p0 = _mm_packus_epi16 ( res_p , res_q ) ;
 sum_p7 = _mm_add_epi16 ( p7_16 , p7_16 ) ;
 sum_q7 = _mm_add_epi16 ( q7_16 , q7_16 ) ;
 sum_p3 = _mm_add_epi16 ( p3_16 , p3_16 ) ;
 sum_q3 = _mm_add_epi16 ( q3_16 , q3_16 ) ;
 pixelFilter_q = _mm_sub_epi16 ( pixelFilter_p , p6_16 ) ;
 pixelFilter_p = _mm_sub_epi16 ( pixelFilter_p , q6_16 ) ;
 res_p = _mm_srli_epi16 ( _mm_add_epi16 ( pixelFilter_p , _mm_add_epi16 ( sum_p7 , p1_16 ) ) , 4 ) ;
 res_q = _mm_srli_epi16 ( _mm_add_epi16 ( pixelFilter_q , _mm_add_epi16 ( sum_q7 , q1_16 ) ) , 4 ) ;
 flat2_q1p1 = _mm_packus_epi16 ( res_p , res_q ) ;
 pixetFilter_q2q1q0 = _mm_sub_epi16 ( pixetFilter_p2p1p0 , p2_16 ) ;
 pixetFilter_p2p1p0 = _mm_sub_epi16 ( pixetFilter_p2p1p0 , q2_16 ) ;
 res_p = _mm_srli_epi16 ( _mm_add_epi16 ( pixetFilter_p2p1p0 , _mm_add_epi16 ( sum_p3 , p1_16 ) ) , 3 ) ;
 res_q = _mm_srli_epi16 ( _mm_add_epi16 ( pixetFilter_q2q1q0 , _mm_add_epi16 ( sum_q3 , q1_16 ) ) , 3 ) ;
 flat_q1p1 = _mm_packus_epi16 ( res_p , res_q ) ;
 sum_p7 = _mm_add_epi16 ( sum_p7 , p7_16 ) ;
 sum_q7 = _mm_add_epi16 ( sum_q7 , q7_16 ) ;
 sum_p3 = _mm_add_epi16 ( sum_p3 , p3_16 ) ;
 sum_q3 = _mm_add_epi16 ( sum_q3 , q3_16 ) ;
 pixelFilter_p = _mm_sub_epi16 ( pixelFilter_p , q5_16 ) ;
 pixelFilter_q = _mm_sub_epi16 ( pixelFilter_q , p5_16 ) ;
 res_p = _mm_srli_epi16 ( _mm_add_epi16 ( pixelFilter_p , _mm_add_epi16 ( sum_p7 , p2_16 ) ) , 4 ) ;
 res_q = _mm_srli_epi16 ( _mm_add_epi16 ( pixelFilter_q , _mm_add_epi16 ( sum_q7 , q2_16 ) ) , 4 ) ;
 flat2_q2p2 = _mm_packus_epi16 ( res_p , res_q ) ;
 pixetFilter_p2p1p0 = _mm_sub_epi16 ( pixetFilter_p2p1p0 , q1_16 ) ;
 pixetFilter_q2q1q0 = _mm_sub_epi16 ( pixetFilter_q2q1q0 , p1_16 ) ;
 res_p = _mm_srli_epi16 ( _mm_add_epi16 ( pixetFilter_p2p1p0 , _mm_add_epi16 ( sum_p3 , p2_16 ) ) , 3 ) ;
 res_q = _mm_srli_epi16 ( _mm_add_epi16 ( pixetFilter_q2q1q0 , _mm_add_epi16 ( sum_q3 , q2_16 ) ) , 3 ) ;
 flat_q2p2 = _mm_packus_epi16 ( res_p , res_q ) ;
 sum_p7 = _mm_add_epi16 ( sum_p7 , p7_16 ) ;
 sum_q7 = _mm_add_epi16 ( sum_q7 , q7_16 ) ;
 pixelFilter_p = _mm_sub_epi16 ( pixelFilter_p , q4_16 ) ;
 pixelFilter_q = _mm_sub_epi16 ( pixelFilter_q , p4_16 ) ;
 res_p = _mm_srli_epi16 ( _mm_add_epi16 ( pixelFilter_p , _mm_add_epi16 ( sum_p7 , p3_16 ) ) , 4 ) ;
 res_q = _mm_srli_epi16 ( _mm_add_epi16 ( pixelFilter_q , _mm_add_epi16 ( sum_q7 , q3_16 ) ) , 4 ) ;
 flat2_q3p3 = _mm_packus_epi16 ( res_p , res_q ) ;
 sum_p7 = _mm_add_epi16 ( sum_p7 , p7_16 ) ;
 sum_q7 = _mm_add_epi16 ( sum_q7 , q7_16 ) ;
 pixelFilter_p = _mm_sub_epi16 ( pixelFilter_p , q3_16 ) ;
 pixelFilter_q = _mm_sub_epi16 ( pixelFilter_q , p3_16 ) ;
 res_p = _mm_srli_epi16 ( _mm_add_epi16 ( pixelFilter_p , _mm_add_epi16 ( sum_p7 , p4_16 ) ) , 4 ) ;
 res_q = _mm_srli_epi16 ( _mm_add_epi16 ( pixelFilter_q , _mm_add_epi16 ( sum_q7 , q4_16 ) ) , 4 ) ;
 flat2_q4p4 = _mm_packus_epi16 ( res_p , res_q ) ;
 sum_p7 = _mm_add_epi16 ( sum_p7 , p7_16 ) ;
 sum_q7 = _mm_add_epi16 ( sum_q7 , q7_16 ) ;
 pixelFilter_p = _mm_sub_epi16 ( pixelFilter_p , q2_16 ) ;
 pixelFilter_q = _mm_sub_epi16 ( pixelFilter_q , p2_16 ) ;
 res_p = _mm_srli_epi16 ( _mm_add_epi16 ( pixelFilter_p , _mm_add_epi16 ( sum_p7 , p5_16 ) ) , 4 ) ;
 res_q = _mm_srli_epi16 ( _mm_add_epi16 ( pixelFilter_q , _mm_add_epi16 ( sum_q7 , q5_16 ) ) , 4 ) ;
 flat2_q5p5 = _mm_packus_epi16 ( res_p , res_q ) ;
 sum_p7 = _mm_add_epi16 ( sum_p7 , p7_16 ) ;
 sum_q7 = _mm_add_epi16 ( sum_q7 , q7_16 ) ;
 pixelFilter_p = _mm_sub_epi16 ( pixelFilter_p , q1_16 ) ;
 pixelFilter_q = _mm_sub_epi16 ( pixelFilter_q , p1_16 ) ;
 res_p = _mm_srli_epi16 ( _mm_add_epi16 ( pixelFilter_p , _mm_add_epi16 ( sum_p7 , p6_16 ) ) , 4 ) ;
 res_q = _mm_srli_epi16 ( _mm_add_epi16 ( pixelFilter_q , _mm_add_epi16 ( sum_q7 , q6_16 ) ) , 4 ) ;
 flat2_q6p6 = _mm_packus_epi16 ( res_p , res_q ) ;
 }
 flat = _mm_shuffle_epi32 ( flat , 68 ) ;
 flat2 = _mm_shuffle_epi32 ( flat2 , 68 ) ;
 q2p2 = _mm_andnot_si128 ( flat , q2p2 ) ;
 flat_q2p2 = _mm_and_si128 ( flat , flat_q2p2 ) ;
 q2p2 = _mm_or_si128 ( q2p2 , flat_q2p2 ) ;
 qs1ps1 = _mm_andnot_si128 ( flat , qs1ps1 ) ;
 flat_q1p1 = _mm_and_si128 ( flat , flat_q1p1 ) ;
 q1p1 = _mm_or_si128 ( qs1ps1 , flat_q1p1 ) ;
 qs0ps0 = _mm_andnot_si128 ( flat , qs0ps0 ) ;
 flat_q0p0 = _mm_and_si128 ( flat , flat_q0p0 ) ;
 q0p0 = _mm_or_si128 ( qs0ps0 , flat_q0p0 ) ;
 q6p6 = _mm_andnot_si128 ( flat2 , q6p6 ) ;
 flat2_q6p6 = _mm_and_si128 ( flat2 , flat2_q6p6 ) ;
 q6p6 = _mm_or_si128 ( q6p6 , flat2_q6p6 ) ;
 _mm_storel_epi64 ( ( __m128i * ) ( s - 7 * p ) , q6p6 ) ;
 _mm_storeh_pi ( ( __m64 * ) ( s + 6 * p ) , _mm_castsi128_ps ( q6p6 ) ) ;
 q5p5 = _mm_andnot_si128 ( flat2 , q5p5 ) ;
 flat2_q5p5 = _mm_and_si128 ( flat2 , flat2_q5p5 ) ;
 q5p5 = _mm_or_si128 ( q5p5 , flat2_q5p5 ) ;
 _mm_storel_epi64 ( ( __m128i * ) ( s - 6 * p ) , q5p5 ) ;
 _mm_storeh_pi ( ( __m64 * ) ( s + 5 * p ) , _mm_castsi128_ps ( q5p5 ) ) ;
 q4p4 = _mm_andnot_si128 ( flat2 , q4p4 ) ;
 flat2_q4p4 = _mm_and_si128 ( flat2 , flat2_q4p4 ) ;
 q4p4 = _mm_or_si128 ( q4p4 , flat2_q4p4 ) ;
 _mm_storel_epi64 ( ( __m128i * ) ( s - 5 * p ) , q4p4 ) ;
 _mm_storeh_pi ( ( __m64 * ) ( s + 4 * p ) , _mm_castsi128_ps ( q4p4 ) ) ;
 q3p3 = _mm_andnot_si128 ( flat2 , q3p3 ) ;
 flat2_q3p3 = _mm_and_si128 ( flat2 , flat2_q3p3 ) ;
 q3p3 = _mm_or_si128 ( q3p3 , flat2_q3p3 ) ;
 _mm_storel_epi64 ( ( __m128i * ) ( s - 4 * p ) , q3p3 ) ;
 _mm_storeh_pi ( ( __m64 * ) ( s + 3 * p ) , _mm_castsi128_ps ( q3p3 ) ) ;
 q2p2 = _mm_andnot_si128 ( flat2 , q2p2 ) ;
 flat2_q2p2 = _mm_and_si128 ( flat2 , flat2_q2p2 ) ;
 q2p2 = _mm_or_si128 ( q2p2 , flat2_q2p2 ) ;
 _mm_storel_epi64 ( ( __m128i * ) ( s - 3 * p ) , q2p2 ) ;
 _mm_storeh_pi ( ( __m64 * ) ( s + 2 * p ) , _mm_castsi128_ps ( q2p2 ) ) ;
 q1p1 = _mm_andnot_si128 ( flat2 , q1p1 ) ;
 flat2_q1p1 = _mm_and_si128 ( flat2 , flat2_q1p1 ) ;
 q1p1 = _mm_or_si128 ( q1p1 , flat2_q1p1 ) ;
 _mm_storel_epi64 ( ( __m128i * ) ( s - 2 * p ) , q1p1 ) ;
 _mm_storeh_pi ( ( __m64 * ) ( s + 1 * p ) , _mm_castsi128_ps ( q1p1 ) ) ;
 q0p0 = _mm_andnot_si128 ( flat2 , q0p0 ) ;
 flat2_q0p0 = _mm_and_si128 ( flat2 , flat2_q0p0 ) ;
 q0p0 = _mm_or_si128 ( q0p0 , flat2_q0p0 ) ;
 _mm_storel_epi64 ( ( __m128i * ) ( s - 1 * p ) , q0p0 ) ;
 _mm_storeh_pi ( ( __m64 * ) ( s - 0 * p ) , _mm_castsi128_ps ( q0p0 ) ) ;
 }
 }